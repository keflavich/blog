<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Adam Ginsburg's blog - Adam (adam.g.ginsburg@gmail.com)</title><link href="https://keflavich.github.io/blog/" rel="alternate"></link><link href="https://keflavich.github.io/blog/feeds/adam-adamgginsburggmailcom.atom.xml" rel="self"></link><id>https://keflavich.github.io/blog/</id><updated>2015-05-07T12:00:00-06:00</updated><entry><title>My python + ipython + vim debugging workflow</title><link href="https://keflavich.github.io/blog/my-python-ipython-vim-debugging-workflow.html" rel="alternate"></link><published>2015-05-07T12:00:00-06:00</published><updated>2015-05-07T12:00:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2015-05-07:/blog/my-python-ipython-vim-debugging-workflow.html</id><summary type="html">&lt;p&gt;My &lt;a class="reference external" href="http://www.eso.org/~eemselle/CV.html"&gt;boss&lt;/a&gt; asked a great question at our first weekly &lt;a class="reference external" href="https://github.com/ESO-python/ESOPythonTutorials"&gt;ESO-python tutorial&lt;/a&gt;
session: What does a good ipython debugging workflow look like?&lt;/p&gt;
&lt;p&gt;The one advantage I had found in IDL was that &lt;em&gt;everything&lt;/em&gt; is a script, which
means that &lt;em&gt;everything&lt;/em&gt; can be debugged in the same way: add a stop â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;My &lt;a class="reference external" href="http://www.eso.org/~eemselle/CV.html"&gt;boss&lt;/a&gt; asked a great question at our first weekly &lt;a class="reference external" href="https://github.com/ESO-python/ESOPythonTutorials"&gt;ESO-python tutorial&lt;/a&gt;
session: What does a good ipython debugging workflow look like?&lt;/p&gt;
&lt;p&gt;The one advantage I had found in IDL was that &lt;em&gt;everything&lt;/em&gt; is a script, which
means that &lt;em&gt;everything&lt;/em&gt; can be debugged in the same way: add a stop statement
at the relevant line of code.  Of course, that debugging model breaks apart
badly once you start writing complex programs and using things like common
blocks.&lt;/p&gt;
&lt;p&gt;In ipython, there is a beautiful debugger that is far more feature-rich than
the IDL equivalent.  It can be activated simply:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;pdb&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;will toggle the interactive ipython debugger.  Then, if you run into a code
crash, you will be dumped out at an &lt;cite&gt;ipdb&amp;gt;&lt;/cite&gt; prompt, with access to a
fully-functional python prompt in the local namespace / environment of the
crash point.  You can also move up and down the function hierarchy with the &lt;tt class="docutils literal"&gt;u&lt;/tt&gt;
and &lt;tt class="docutils literal"&gt;d&lt;/tt&gt; commands.&lt;/p&gt;
&lt;p&gt;The existence of the ipdb debugger suggests a natural approach for those
familiar with IDL debugging: simply add a &lt;tt class="docutils literal"&gt;raise&lt;/tt&gt; statement wherever you would
normally have put a &lt;tt class="docutils literal"&gt;stop&lt;/tt&gt; statement.  There are a few key differences,
however: in IDL, you could just &lt;tt class="docutils literal"&gt;.continue&lt;/tt&gt; to run the rest of the code as if
no stop occurred; in python the same is not possible with the default ipdb.&lt;/p&gt;
&lt;p&gt;However, the &lt;a class="reference external" href="https://pypi.python.org/pypi/ipdb"&gt;ipdb&lt;/a&gt; package allows the insertion of breakpoints just like in IDL:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;ipdb&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;ipdb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_trace&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From within one of these breakpoints, the &lt;tt class="docutils literal"&gt;.continue&lt;/tt&gt; command will continue on
to the next breakpoint, as you might expect.  The &lt;tt class="docutils literal"&gt;n&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;s&lt;/tt&gt; commands will go
to the next line in the code, while &lt;tt class="docutils literal"&gt;s&lt;/tt&gt; will allow you to drop into called functions (how?)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://scipy-lectures.github.io/advanced/debugging/#using-the-python-debugger"&gt;Postmortem debugging&lt;/a&gt; is also awesome.  If you have run a command and gotten a traceback,
you can retroactively enter the debugger:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;but as with the normal traceback debugger, one cannot &lt;tt class="docutils literal"&gt;continue&lt;/tt&gt; afterward.&lt;/p&gt;
&lt;div class="section" id="reloading-code"&gt;
&lt;h2&gt;Reloading Code&lt;/h2&gt;
&lt;p&gt;Python code is typically distributed in packages managed with a &lt;tt class="docutils literal"&gt;setup.py&lt;/tt&gt;
script.  These are the most convenient way to install, use, and distribute
code, but they are not ideal for debugging.&lt;/p&gt;
&lt;p&gt;When debugging a normal script, something you could run by invoking&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python&lt;span class="w"&gt; &lt;/span&gt;myfile.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="n"&gt;myfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;span class="c1"&gt;# in the local namespace&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;myfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;span class="c1"&gt;# with the python debugger active:&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="n"&gt;myfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;can easily be debugged by running it line-by-line.  The &lt;a class="reference external" href="http://ipython.org/ipython-doc/dev/interactive/tutorial.html#running-and-editing"&gt;documentation&lt;/a&gt;
can be accessed via the &lt;tt class="docutils literal"&gt;%magic&lt;/tt&gt; command.&lt;/p&gt;
&lt;p&gt;For debugging &amp;quot;compiled&amp;quot; packages, though, more thought is needed.&lt;/p&gt;
&lt;p&gt;If you are working on your own package, you can use &lt;a class="reference external" href="https://pythonhosted.org/setuptools/setuptools.html#develop-deploy-the-project-source-in-development-mode"&gt;setuptools&lt;/a&gt; to enable the
&lt;tt class="docutils literal"&gt;python setup.py develop&lt;/tt&gt; command, which installs a symbolic link to the
source code directory - meaning any changes you make are immediately reflected
in the python source path.  This does &lt;em&gt;not&lt;/em&gt; mean that any changes are
recognized in the local python environment, though!&lt;/p&gt;
&lt;p&gt;If you are in an active &lt;tt class="docutils literal"&gt;ipython&lt;/tt&gt; session, you need to &lt;tt class="docutils literal"&gt;reload&lt;/tt&gt; packages to
see their results.  As far as I know, you can &lt;em&gt;never&lt;/em&gt; &amp;quot;reload&amp;quot; the source code
underlying an already-instantiated class, so you have to remake any class
instances you want to examine.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;reload&lt;/tt&gt; command is tricky to use.  You will only see changes to the source code
if you import the exact package in which the code is stored.  For example, if you have a file structure like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mypackage/
&lt;span class="w"&gt;    &lt;/span&gt;__init__.py
&lt;span class="w"&gt;    &lt;/span&gt;core.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and you do &lt;tt class="docutils literal"&gt;reload(mypackage)&lt;/tt&gt;, that will effectively reload only the source
code in &lt;tt class="docutils literal"&gt;__init__.py&lt;/tt&gt;.  If the code you want to use is called &lt;tt class="docutils literal"&gt;myfunction&lt;/tt&gt;
and it lives in &lt;tt class="docutils literal"&gt;core.py&lt;/tt&gt;, you can reload that source code by doing
&lt;tt class="docutils literal"&gt;reload(mypackage.core)&lt;/tt&gt;.  Reloading &lt;tt class="docutils literal"&gt;mypackage&lt;/tt&gt; may have no effect.  So
the key for developing packages is finding the right module to reload!&lt;/p&gt;
&lt;p&gt;IPython has a &lt;a class="reference external" href="http://ipython.org/ipython-doc/dev/interactive/reference.html#dreload"&gt;deepreload package&lt;/a&gt;
intended to recursively reload functions; it may work but I had trouble in the
past.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tests"&gt;
&lt;h2&gt;Tests&lt;/h2&gt;
&lt;p&gt;It's generally much better to have a test suite enabled with unit tests for
each component of your code.  This is the approach adopted by most open-source
projects and many industrial code developers.&lt;/p&gt;
&lt;p&gt;Tests are invoked with the command &lt;tt class="docutils literal"&gt;py.test&lt;/tt&gt; with a variety of command
options.  Among my favorites are &lt;tt class="docutils literal"&gt;py.test &lt;span class="pre"&gt;--tb=short&lt;/span&gt;&lt;/tt&gt;, which gives a much
less verbose traceback, &lt;tt class="docutils literal"&gt;py.test &lt;span class="pre"&gt;--pastebin=failed&lt;/span&gt;&lt;/tt&gt;, which posts any failure
results to pastebin for easy sharing, &lt;tt class="docutils literal"&gt;py.test &lt;span class="pre"&gt;-p&lt;/span&gt; packagename&lt;/tt&gt; (or &lt;tt class="docutils literal"&gt;python
setup.py test &lt;span class="pre"&gt;-P&lt;/span&gt; packagename&lt;/tt&gt; in astropy) to select tests for a specific
package.  A great deal more options can be found in the &lt;a class="reference external" href="http://pytest.org/latest/"&gt;pytest docs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A test suite, if properly constructed, can also be run from with in ipython:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;astroquery&lt;/span&gt;
&lt;span class="n"&gt;astroquery&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;eso&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="postscript"&gt;
&lt;h2&gt;Postscript&lt;/h2&gt;
&lt;p&gt;Some useful related links:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://stackoverflow.com/questions/1623039/python-debugging-tips"&gt;http://stackoverflow.com/questions/1623039/python-debugging-tips&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pypi.python.org/pypi/pudb"&gt;https://pypi.python.org/pypi/pudb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;!-- great picture: http://commons.wikimedia.org/wiki/File:Richard_Hook_and_Eric_Emsellem_at_the_ESO_50th_Anniversary_Gala_Event.jpg --&gt;
&lt;/div&gt;
</content><category term="misc"></category><category term="python"></category><category term="workflow"></category><category term="debugging"></category><category term="ipython"></category><category term="vim"></category></entry><entry><title>Catalog vs Image shift? A possible solution to the ATLASGAL issue</title><link href="https://keflavich.github.io/blog/catalog-vs-image-shift-a-possible-solution-to-the-atlasgal-issue.html" rel="alternate"></link><published>2012-12-26T23:02:00-07:00</published><updated>2012-12-26T23:02:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-12-26:/blog/catalog-vs-image-shift-a-possible-solution-to-the-atlasgal-issue.html</id><summary type="html">&lt;p&gt;In the &lt;a class="reference external" href="http://bolocam.blogspot.com/2012/12/pointing-cross-correlation-yet-again.html"&gt;previous post&lt;/a&gt;, I came up with a final plot showing the
pointing offset was, on average, not significant, even in the ATLASGAL
overlap zone.
So why did the ATLASGAL group infer a net pointing offset?
The problem is probably one or two fields with a slight pointing offset â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the &lt;a class="reference external" href="http://bolocam.blogspot.com/2012/12/pointing-cross-correlation-yet-again.html"&gt;previous post&lt;/a&gt;, I came up with a final plot showing the
pointing offset was, on average, not significant, even in the ATLASGAL
overlap zone.
So why did the ATLASGAL group infer a net pointing offset?
The problem is probably one or two fields with a slight pointing offset,
but a huge number of source. &amp;nbsp;l=1 has an offset of the right sign and is
the single most source-rich degree in the survey, with 368 sources.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-ONF7C_v8rNk/UNpmXIEe6HI/AAAAAAAAHUI/kdf3pmUKyE0/s320/l001_catalog_image_compare.png" /&gt;
&lt;p&gt;This figure shows the v1 vs v2 source locations in grey, their average
and standard deviation in green, and the cross-correlation offset in
red. &amp;nbsp;The plot is somewhat difficult to interpret, but it appears that
the v1 point sources are systematically more shifted to negative
longitudes than v2, and the point sources more than the maps themselves.
&amp;nbsp;There may have been some reason sources were systematically selected at
more negative longitudes in the v1 catalog; around Sgr B2 there's a lot
of structure that had to be decomposed somehow but was not necessarily
&amp;quot;source&amp;quot;.
One thing to note is the reversal in left-right (in pixel space) vs the
positive/negativeness in longitude. &amp;nbsp;The above plot is correct (negative
longitudes, as shown on the plot, are &amp;quot;right&amp;quot; in images), but most of my
other plots have the X-axis flipped.
In the end, after spending two weeks hammering my head against this, I
find no clear evidence for an offset &amp;nbsp;between the BGPS and Herschel or
v1/v2 data overall or in the ATLASGAL fields. &amp;nbsp;In any individual field,
that statement is not necessarily true.
Despite the strong statistical evidence, it is really hard to be really
sure about sub-pixel offsets, since the &amp;quot;model&amp;quot; image is never perfect.
&amp;nbsp;I think we can safely state the ~1/2 pixel offsets (~3&amp;quot;) but I just
don't feel confident about numbers below that range for ALL fields.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Idea: Multispectral Eigenimage decomposition...</title><link href="https://keflavich.github.io/blog/idea-multispectral-eigenimage-decomposition.html" rel="alternate"></link><published>2012-12-22T02:53:00-07:00</published><updated>2012-12-22T02:53:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-12-22:/blog/idea-multispectral-eigenimage-decomposition.html</id><content type="html">&lt;p&gt;Can use BGPS + HiGal to look for correlated (thermal) components and
decorrelated (free-free) components. &amp;nbsp;Obviously needs to be tried in GC
first.
Also, need to figure out a method to mitigate negative bowls in
unsharp-masking for herschel-bolocam comparison&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Pointing &amp; Cross-Correlation yet again</title><link href="https://keflavich.github.io/blog/pointing-cross-correlation-yet-again.html" rel="alternate"></link><published>2012-12-15T03:21:00-07:00</published><updated>2012-12-15T03:21:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-12-15:/blog/pointing-cross-correlation-yet-again.html</id><summary type="html">&lt;p&gt;Prompted in part by a &lt;a class="reference external" href="http://arxiv.org/abs/1211.0741"&gt;recent ATLASGAL paper&lt;/a&gt;&amp;nbsp;identifying pointing
offsets of about 3&amp;quot; in the BGPS, we revisit the BGPS pointing.
The ATLASGAL team compared the source locations in their catalog to
source locations in the Bolocam catalog by doing &amp;quot;nearest-match&amp;quot;
searches within a 40&amp;quot; radius (see their Figure â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Prompted in part by a &lt;a class="reference external" href="http://arxiv.org/abs/1211.0741"&gt;recent ATLASGAL paper&lt;/a&gt;&amp;nbsp;identifying pointing
offsets of about 3&amp;quot; in the BGPS, we revisit the BGPS pointing.
The ATLASGAL team compared the source locations in their catalog to
source locations in the Bolocam catalog by doing &amp;quot;nearest-match&amp;quot;
searches within a 40&amp;quot; radius (see their Figure 8, reproduced here)&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-UJVCzHbaDCI/UMYpeAoulVI/AAAAAAAAHR4/cy5SIqL_HFQ/s320/ATLASGALvsBolocam.png" /&gt;
&lt;p&gt;Their comparison was over the range -10 &amp;lt; l &amp;lt; 21, so it only covered a
small fraction of the BGPS. &amp;nbsp;It covered 13 fields with independent
pointing solutions, so it's possible that they have actually discovered
an offset only in some of our fields.&lt;/p&gt;
&lt;p&gt;The catalog comparison, while interesting, is potentially quite flawed.
&amp;nbsp;There's no guarantee that a source extraction algorithm will measure
source centers accurately when a &amp;quot;source&amp;quot; is just a local overdensity on
a complex background. &amp;nbsp;Using source comparison will also lead to a bias
towards the most source-rich fields, e.g. l000 and l001, so an offset in
one of those fields would drastically affect the catalog offset.&lt;/p&gt;
&lt;p&gt;There is a better way to compare pointing between two images that are
expected to be (nearly) identical. &amp;nbsp;It is well-known that
cross-correlation is an effective technique for determining the offsets
between two identical images; I'll briefly summarize some of the
literature here.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://adsabs.harvard.edu/abs/2005A%26A...443..357G"&gt;Gratadour et al 2005&lt;/a&gt;&amp;nbsp;used a maximum likelihood estimator approach to
determine the &amp;quot;best-fit&amp;quot; offset between two images. &amp;nbsp;This approach is
comparable to &lt;a class="reference external" href="http://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=5&amp;amp;cad=rja&amp;amp;ved=0CF0QFjAE&amp;amp;url=http%3A%2F%2Fwww.optics.rochester.edu%2Fworkgroups%2Ffienup%2FPUBLICATIONS%2FMGS_OL08_EffRegistration.pdf&amp;amp;ei=rC3GUJC9CcSA2AX3wYCIAg&amp;amp;usg=AFQjCNHdUm0v8qYzNbvrqFRqByR_3svlSA&amp;amp;sig2=GQztgkfvoQzAzQ7kzCJU2w"&gt;Guizar et al (2008)&lt;/a&gt;, who &lt;a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/18401-efficient-subpixel-image-registration-by-cross-correlation"&gt;implemented&lt;/a&gt; a fast solution
for (highly) sub-pixel image registration in matlab. &amp;nbsp;In order for the
image registration to be fast, it must operate in fourier space, but to
get sub-pixel registration in fourier space, you need to either pad
(which is slow, and increases memory use drastically) or fit some
functional form around the peak of the cross-correlation image. &amp;nbsp;The
alternative approach implemented by Guizar utilizes the &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Fourier_transform#Basic_properties"&gt;Fourier scaling
theorem&lt;/a&gt;&amp;nbsp;to create a zoomed-in image of the peak pixel, which allows
you to get much higher precision for a much lower computational cost.
My innovation is to use the minimum $\chi^2$ estimator to determine the
goodness of fit and therefore error bars on the best-fit offset.&lt;/p&gt;
&lt;p&gt;Because the $\chi^2$ value for each offset is simply determined by
sums and multiplication ($\chi^2 = \sum
\frac{x_i-\mu_x}{\sigma_{x_i}^2}$), we can compute each term that
goes in to the $\chi^2$ value independently with fourier transforms,
then create goodness-of-fit contours around the $\chi^2$ minimum. &amp;nbsp;The
statistical requirement for this approach to make sense is that the
errors on the data are gaussian distributed, which is an assumption we
inevitably make for astronomical images. &amp;nbsp;I believe there is also a
requirement that the errors are independent, which may be more difficult
to satisfy, but in the Bolocam images it is satisfied, especially when
multiple independent observations are combined.&lt;/p&gt;
&lt;p&gt;Strictly, this approach can only be used when the model data have the
same multiplicative scale as the fitted data. &amp;nbsp;The peak will never be
wrong using this method, but the errors could be incorrect if the model
and data are multiplicatively offset. &amp;nbsp;In principle, this can be
resolved in the future using a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Mellin_transform"&gt;Mellin transform&lt;/a&gt;&amp;nbsp;[see &lt;a class="reference external" href="http://ecocodespace.wordpress.com/category/matlab/image-matching/fourier-mellin-transform/"&gt;this site&lt;/a&gt;&amp;nbsp;or
&lt;a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/authors/7667"&gt;this&lt;/a&gt; for
a matlab approach and &lt;a class="reference external" href="http://www.fresnel.fr/perso/derrode/publi/Cviu01.pdf"&gt;this&lt;/a&gt; for an academic paper
on it].&lt;/p&gt;
&lt;p&gt;This is the approach I have implemented
at&amp;nbsp; &lt;a class="reference external" href="http://image-registration.rtfd.org/"&gt;image-registration.rtfd.org&lt;/a&gt;. &amp;nbsp;I used simulated test cases to
demonstrate that it is, indeed, effective and accurate. &amp;nbsp;I used this
method to measure the offsets between the v2 data and the v1 data (which
should, in principle, be the same as the offsets between ATLASGAL and
v1) and the v2 vs Herschel Hi-Gal data (which should be zero).
There are actually a few methods implemented in image-registration, and
I compared those. &amp;nbsp;There's a &amp;quot;dft&amp;quot; and a &amp;quot;$\chi^2$&amp;quot; approach, which are
the same (except $\chi^2$ includes realistic errors), a method where a
2D gaussian is fit to the peak of the cross-correlation image, and a
method where a 2nd-order Taylor expansion is performed around the peak
of the cross-correlation image. &amp;nbsp;The latter two are &lt;em&gt;biased&lt;/em&gt;. &amp;nbsp;An
example comparison plot looks like this:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-LtA6owJr_vc/UMZBLK394HI/AAAAAAAAHSI/tR4F0BnFSVs/s320/l000_catalog_image_compare_chi2contours.png" /&gt;
&lt;p&gt;The grey dots are catalog centroid positions offsets measured between v1
and v2. &amp;nbsp;The green cross represents the mean and standard deviation of
the grey points. &amp;nbsp;The other data points, as labeled, show the offsets
between the l000 images in v1 and v2 as measured by the method shown.
They all have errorbars plotted, but the errorbars are generally smaller
than the points. &amp;nbsp;The dark spot seen behind the purple point shows the
$\chi^2$ contours out to 8-$\sigma$: the error in the offset is tiny,
sub-arcsecond. &amp;nbsp;In this case, the offsets nearly agree:&lt;/p&gt;
&lt;p&gt;l000 catalog dx: &amp;nbsp;-0.31 +/- 0.68 &amp;nbsp; dy: 1.48 +/- 0.64&lt;/p&gt;
&lt;p&gt;l000 $\chi^2$ dx: &amp;nbsp; 1.74 +/- 0.03 &amp;nbsp;dy: 1.41 +/- 0.03&lt;/p&gt;
&lt;p&gt;This field agreed nicely between v1 and v2.&lt;/p&gt;
&lt;p&gt;The comparison to Hi-Gal is perhaps more important; HiGal's pointing is
calibrated based on multi-wavelength observations, some of which include
actual stars. &amp;nbsp;It's a space-based mission, so its pointing is more
stable. &amp;nbsp;And finally, being a space mission, there's a large dedicated
team instead of a single, part-time individual working on the data.
Our offsets from Hi-Gal are pretty small in general, though not
trivially small.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-JyMtqE536LY/UMaEqOYBRxI/AAAAAAAAHSY/85nEo6rEc9k/s320/Offsets_XYplot.png" /&gt;
&lt;p&gt;And it turns out, the region that overlaps with ATLASGAL had more
serious pointing errors than the rest of the survey:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-iXI7TUl1y9I/UMaHHXwN2oI/AAAAAAAAHSg/z3g51NHD0zk/s320/Offsets_XYplot_ATLASGALoverlap.png" /&gt;
&lt;p&gt;(note: both of the above plots are missing L=359 because I forgot it.
&amp;nbsp;Fixing that now...)&lt;/p&gt;
&lt;p&gt;The clearest problem field is l=15, with a longitude offset of -6&amp;quot;
between v2 and HiGal.... that's not the question, though. &amp;nbsp;Somehow I've
lost the code that did the v1-HiGal offsets; I'll have to re-write that
tomorrow and let it run...&lt;/p&gt;
&lt;p&gt;Update 12/13: &amp;nbsp;I've spent the last couple days clearing up some issues
with the offsets. &amp;nbsp;The error bars should be MUCH smaller than in the
above plots. &amp;nbsp;The means are pretty similar, though.
Short story: the offsets between v1 and Hi-Gal are greater in the
ATLASGAL overlap regions than elsewhere, and in the right general
direction, but not quite as serious as they claimed. &amp;nbsp;In v2, the
ATLASGAL overlap fields and the rest of the survey have the same mean
offsets, and those offsets are small (-0.5&amp;quot; in l, -1&amp;quot; in b).
The problem now is the table. &amp;nbsp;If everything made sense,
(v1-v2)+(v2-higal)+(higal-v1) = 0. &amp;nbsp;But that clearly isn't the case,
which implies an error in the method, which sucks since I'm claiming
this method is superior to alternatives. &amp;nbsp;It's possible that I'm
actually underestimating the errors against Hi-Gal - that can be fixed
relatively easily - but the magnitude of the error won't affect the
centroid measurements. &amp;nbsp;So I probably need to investigate one case very
carefully. &amp;nbsp;l050 is a big problem case, with vector sums &amp;gt;1 pixel in
both directions. &amp;nbsp;That will be my next line of investigation.
The approach will be:
-crop identical fields within l050 from v1, v2, herschel
-perform pointing comparison between them
-check that vector sum &amp;lt; sum of errors
I think - and hope - the trouble is just that I'm using inconsistent
sub-fields to compare Herschel with the two different Bolocam versions,
which is possible because of the way I selected these sub-fields. &amp;nbsp;I'll
do more careful cropping, and probably re-do this analysis
degree-by-degree (with $512^2$ fields, in the hope that it speeds up the
FTs).
Update 12/14:
I've now cropped identical sections in each of the survey, 1 square
degree (512 pixels) each - which is great for speed. &amp;nbsp;As a sidenote, a
little line profiling revealed that the make_cross_plots
&amp;nbsp;code was the slow point in the process, and it is dominated by savefig
calls, not ffts.
I've run a careful examination of self consistency on the l=0 field,
with positive results: the offsets agree to well within the errorbars
(though there is some residual error at the 0.5&amp;quot; level).&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/--3Q9h0Q1jA4/UMuUjQ33dCI/AAAAAAAAHS4/zSD3H26r5dA/s320/circular_selfconsistency.png" /&gt;
&lt;p&gt;However, a similar inspection of l=50 resulted in a major failure:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-wlwvC26eTEk/UMuYZHU179I/AAAAAAAAHTI/Csf3mBSdbGI/s320/circular_selfconsistency.png" /&gt;
&lt;p&gt;In this case, the problem is caused by W51 being exactly on the field
edge, leading to huge cross-correlation power at dx=0, but spread over a
large y range. &amp;nbsp;My first thought is to try to downweight the edges,
which can be achieved by &amp;quot;zero-padding&amp;quot; the noise image, but with high
values instead of zero... or alternatively, by setting the edge region
to zero smoothly.&lt;/p&gt;
&lt;p&gt;OK, first thought: Bad idea. &amp;nbsp;Increasing the noise along the edges
drastically increases the small-shift autocorrelation for the noise,
which in turn ends up ruling out the small shifts as a fit possibility.
&amp;nbsp;I don't think this really makes sense mathematically, but each step
does. &amp;nbsp;Why would increasing the noise along the edges make the $\chi^2$
fit worse?&lt;/p&gt;
&lt;p&gt;This revealed a serious bug in the code that, luckily, only affected
non-uniform error maps. &amp;nbsp;Basically, I had decomposed the $\chi^2$
equation wrong (which is as bad as it sounds).&lt;/p&gt;
&lt;p&gt;That total mess has been resolved now. &amp;nbsp;The image edges are downweighted
with a gaussian of 12 pixels, error=100 outside and weight=0 outside
(with weight^2 inside... best to just view the source if you really want
to know the details). &amp;nbsp;The new versions of the above diagrams:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-mjPyO7LkbGc/UMuxVgSxwZI/AAAAAAAAHTY/ilRnJRaAiOQ/s320/circular_selfconsistency.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-rMiHxucSQuo/UMuxZSH63fI/AAAAAAAAHTg/W_IzmhcFCzo/s320/circular_selfconsistency.png" /&gt;
&lt;p&gt;Less than spectacular for l=50, but acceptable given the errors, which
are indeed significantly larger, as you might expect given the lower
total signal in l=50. Now I need to re-run the fits on every field.&lt;/p&gt;
&lt;p&gt;OK, cool, last thing accomplished today (...by 8pm): offset comparison
by square degree for all fields. &amp;nbsp;Again, I don't reproduce the magnitude
of the ATLASGAL-measured offsets, but the ATLASGAL fields are, on
average, more offset in longitude (to the negative) than the overall
average.&lt;/p&gt;
&lt;p&gt;Curiously, for both v1 and v2, there appears to be a -1.5 deg shift in
latitude from Hi-Gal.&lt;/p&gt;
&lt;p&gt;The vector sums are mostly sub-arcsecond, with most exceptions at l&amp;gt;50.
&amp;nbsp;l=59,64, and 65 are particularly bad - but l=50 isn't so bad. &amp;nbsp;So I
should do the &amp;quot;deep&amp;quot; examination of one or two of those fields... who
knows what new errors I'll turn up?&lt;/p&gt;
&lt;p&gt;Here's the new v1-ATLASGAL offset plot:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-iv_FsACT958/UMvsyr90haI/AAAAAAAAHTw/g56hcK6hMCw/s320/Offsets_XYplot_v1-Hi-Gal_ATLASGALoverlap.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Cross-Correlation Offsets Revisited</title><link href="https://keflavich.github.io/blog/cross-correlation-offsets-revisited.html" rel="alternate"></link><published>2012-09-08T08:06:00-06:00</published><updated>2012-09-08T08:06:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-09-08:/blog/cross-correlation-offsets-revisited.html</id><summary type="html">&lt;p&gt;Since last time (&lt;a class="reference external" href="http://bolocam.blogspot.com/2009/03/43-relative-alignment-and-mosaicing.html"&gt;Taylor Expansion &amp;amp; Cross
Correlation&lt;/a&gt;&lt;a class="reference external" href="http://bolocam.blogspot.com/2012/03/new-coalignment-code.html"&gt;,&lt;/a&gt;&lt;a class="reference external" href="http://bolocam.blogspot.com/2012/03/new-coalignment-code.html"&gt;Coalignment Code&lt;/a&gt;), I have attempted to re-do the
cross-correlation with an added component: error estimates.
It turns out, there is a better method than the Taylor-expansion around
the cross-correlation peak. &amp;nbsp;Fourier upsampling can be used to
efficiently determine precise sub-pixel offsets (&lt;a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/18401-efficient-subpixel-image-registration-by-cross-correlation/content/html/efficient_subpixel_registration.html"&gt;matlab version â€¦&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Since last time (&lt;a class="reference external" href="http://bolocam.blogspot.com/2009/03/43-relative-alignment-and-mosaicing.html"&gt;Taylor Expansion &amp;amp; Cross
Correlation&lt;/a&gt;&lt;a class="reference external" href="http://bolocam.blogspot.com/2012/03/new-coalignment-code.html"&gt;,&lt;/a&gt;&lt;a class="reference external" href="http://bolocam.blogspot.com/2012/03/new-coalignment-code.html"&gt;Coalignment Code&lt;/a&gt;), I have attempted to re-do the
cross-correlation with an added component: error estimates.
It turns out, there is a better method than the Taylor-expansion around
the cross-correlation peak. &amp;nbsp;Fourier upsampling can be used to
efficiently determine precise sub-pixel offsets (&lt;a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/18401-efficient-subpixel-image-registration-by-cross-correlation/content/html/efficient_subpixel_registration.html"&gt;matlab version&lt;/a&gt;,
&lt;a class="reference external" href="http://people.web.psi.ch/guizar_m/main/"&gt;Manuel Guizar, author&lt;/a&gt;, &lt;a class="reference external" href="http://www.opticsinfobase.org/view_article.cfm?gotourl=http%3A%2F%2Fwww%2Eopticsinfobase%2Eorg%2FDirectPDFAccess%2F6C566DF3-B5C5-B342-97F01180999C7632_148843%2Fol-33-2-156%2Epdf%3Fda%3D1%26id%3D148843%26seq%3D0%26mobile%3Dno&amp;amp;org=University%20of%20Colorado%20at%20Boulder%20Library"&gt;refereed article&lt;/a&gt;).
However, in the published methods just cited, there is no way to
determine the error - those algorithms are designed to measure offsets
between identical images corrupted by noise but still strongly dominated
by signal.
We're more interested in the case where individual pixels may well be
noise-dominated, but the overall signal in the map is still large.
So, I've developed a python translation of the above codes and then
some.
&lt;a class="reference external" href="https://github.com/keflavich/image_registration"&gt;Image Registration on github&lt;/a&gt;
The docstrings are pretty solid, but there is no overall documentation.
However, there's a pretty good demo of the simulation AND fitting code
here:
&lt;a class="reference external" href="https://github.com/keflavich/image_registration/blob/master/doc/CrossCorrelationSimulation.pdf?raw=true"&gt;Tests and Examples&lt;/a&gt;
The results for the Bolocam data are here (only applied to v2-Herschel
offsets):&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-PMJx-wX23w8/UErt7G3PqfI/AAAAAAAAHOQ/-5xD6ReBRGs/s320/Offsets_XYplot.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="alignment"></category><category term="pointing"></category></entry><entry><title>How does Bolocam data improve greybody fits?</title><link href="https://keflavich.github.io/blog/how-does-bolocam-data-improve-greybody-fits.html" rel="alternate"></link><published>2012-06-23T09:11:00-06:00</published><updated>2012-06-23T09:11:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-06-23:/blog/how-does-bolocam-data-improve-greybody-fits.html</id><content type="html">&lt;img alt="" src="http://3.bp.blogspot.com/-c_JUkbALzlE/T-WIDgFQgpI/AAAAAAAAHM0/wQIBvsgQtQU/s320/longwav500_sn10_Herschelsn50_bb_test.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-CZHBZFtEpC8/T-WIExxu5uI/AAAAAAAAHM8/wxR_0xFujm8/s320/longwav500_sn20_Herschelsn50_bb_test.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-58ayoSrqcjU/T-WIF4NEwHI/AAAAAAAAHNA/ivNPdPGm5iY/s320/longwav500_sn5_Herschelsn50_bb_test.png" /&gt;
&lt;p&gt;Long wavelength data can be very useful for constraining the value of
beta in a greybody fit.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Bolocat V1 vs V2</title><link href="https://keflavich.github.io/blog/bolocat-v1-vs-v2.html" rel="alternate"></link><published>2012-05-24T17:59:00-06:00</published><updated>2012-05-24T17:59:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-05-24:/blog/bolocat-v1-vs-v2.html</id><summary type="html">&lt;p&gt;I've done some very extensive comparison of v1 and v2. The plots below
are included in the current BGPS draft, but I'll go into more excessive
detail here. ALL plots below show Version 1 fluxes versus Version 2
fluxes using Bolocat V1 apertures. This means there are only two
possible â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've done some very extensive comparison of v1 and v2. The plots below
are included in the current BGPS draft, but I'll go into more excessive
detail here. ALL plots below show Version 1 fluxes versus Version 2
fluxes using Bolocat V1 apertures. This means there are only two
possible effects in play:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Different fluxes in the v1 and v2 maps&lt;/li&gt;
&lt;li&gt;Pointing (spatial) offsets between the v1 and v2 maps
[see&amp;nbsp;&lt;a class="reference external" href="http://bolocam.blogspot.com/2012/05/bgps-v2-pointing.html"&gt;http://bolocam.blogspot.com/2012/05/bgps-v2-pointing.html&lt;/a&gt;]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Therefore, the plots below are just different ways of visualizing the
same information. This holds true despite the fact that different
&amp;quot;correction factors&amp;quot; appear in different plots.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-gGL8rEcNr20/T75tzRC4dJI/AAAAAAAAHHM/A8KeWkBtfmc/s320/total_ratiohistograms.png" /&gt;
&lt;p&gt;Ratios of v2 fluxes to v1 fluxes in the listed apertures. The curves
represent best-fit gaussian distributions to the data after excluding
outliers using a &lt;a class="reference external" href="http://scikit-learn.org/dev/modules/generated/sklearn.covariance.MinCovDet.html"&gt;minimum covariance determinant&lt;/a&gt; method&lt;/p&gt;
&lt;p&gt;v1 vs v2 with a background subtracted around the source equal to the source
area (this was not reported in Bolocat v1, but is a tool Erik implemented so I
used it)&lt;/p&gt;
&lt;p&gt;v1 vs v2 in 40&amp;quot; apertures, as stated. &amp;nbsp;There are y=x and y=1.5x lines plotted:
these are NOT fits to the data! &amp;nbsp;The green line is a Total Least Squares linear
fit to the data weighted by the measured errors.&lt;/p&gt;
&lt;p&gt;Source Mask &amp;quot;aperture&amp;quot;:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-YS2Jtvz4Yy0/T75pixKkYsI/AAAAAAAAHFs/iEJHrsKsBk0/s320/total_v1v2_sourcemask_bg_fit_compare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-g-ZbEUUWEpY/T75pjj26FeI/AAAAAAAAHGE/rtdSRgoMQpo/s320/total_v1v2_sourcemask_fit_compare.png" /&gt;
&lt;p&gt;Same as above, but the best fit slope is steeper. The best explanation
for the steeper slope (i.e., v2 &amp;gt; 1.5(v1)) is that more extended flux is
recovered in v2 around bright sources, therefore in the larger source
masks, there is greater flux than would be recovered if a simple 1.5x
corrective factor was applied.
80&amp;quot; apertures&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-WKtlvnFbUF4/T75piyh8tVI/AAAAAAAAHF4/FROq508X6pU/s320/total_v1v2_80arcsec_fit_compare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-EHGNHIarslc/T75yqG_AmFI/AAAAAAAAHJg/ToAicG9ynmk/s320/total_v1v2_80_nobgarcsec_fit_compare.png" /&gt;
&lt;p&gt;Same for 120&amp;quot; apertures:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-ymBFW1Y5OhY/T75piwFYrJI/AAAAAAAAHFw/07ujRFCd_Ts/s320/total_v1v2_120arcsec_fit_compare.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-PMkvtoJKNVs/T75yqPe16PI/AAAAAAAAHJk/QF041ok8yQ0/s320/total_v1v2_120_nobgarcsec_fit_compare.png" /&gt;
&lt;p&gt;For all 3 of the 40, 80 and 120&amp;quot; apertures both, the 1.5x correction
factor is nearly perfect (agrees to &amp;lt;5%). &amp;nbsp;The background subtraction
seems to have different effects depending on aperture size. &amp;nbsp;I welcome
Erik to comment on this, but I do not think it is particularly
important.
The figures below require some explanation. &amp;nbsp;NONE of the circular
apertures use background subtraction in this comparison (i.e., compare
to the RIGHT column above).
These figures are histograms of the flux ratio within a given aperture
as a function of flux in the v1 aperture. &amp;nbsp;From bottom to top, the flux
in the v1 aperture goes from 0.1 to 10 Jy. &amp;nbsp;The X-axis shows the ratio
of the v2 flux to the v1 flux. &amp;nbsp;The black dots with error bars represent
the best-fit gaussian distribution to each flux bin. &amp;nbsp;The colorbar shows
the log of the number of sources; the most in any bin is about
10&lt;sup&gt;2.5&lt;/sup&gt; ~ 300.
In short, there is some sign that the ratio of v2/v1 flux varies with v1
flux. &amp;nbsp;This effect could be seen in the figures above since a linear fit
is imperfect. &amp;nbsp;The effect is not very strong. &amp;nbsp;Again, I believe the
explanation here is the changed spatial transfer function in v2.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-bfrjMd2veR0/T75pzxm5_xI/AAAAAAAAHGs/SQ1LDR8_EoM/s320/ratio_twodhist_40.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-unXyfhsIL1g/T75pkN6kWkI/AAAAAAAAHGQ/axiiWsEMO0M/s320/ratio_twodhist_80.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-kJEMLqkaQak/T75pkNu78XI/AAAAAAAAHGM/Dh2T4m0cD-8/s320/ratio_twodhist_120.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-ExDpIxfHO74/T75pkjjeKAI/AAAAAAAAHGk/pU3mE5uzcgM/s320/ratio_twodhist_sourcemask_nobg.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-Pru74WRl-Hg/T75pkOL1YWI/AAAAAAAAHGU/qtrMl-w59SA/s320/ratio_twodhist_sourcemask.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>BGPS V2 pointing</title><link href="https://keflavich.github.io/blog/bgps-v2-pointing.html" rel="alternate"></link><published>2012-05-23T23:59:00-06:00</published><updated>2012-05-23T23:59:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-05-23:/blog/bgps-v2-pointing.html</id><summary type="html">&lt;p&gt;BGPS V2.0 pointing offsets relative to V1 and Herschel:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-41YC6GZJR-0/T715bELMplI/AAAAAAAAHE0/Fzk41wW8ysM/s320/Offsets_CDF.png" /&gt;
&lt;p&gt;Cumulative Distribution Function of the total offsets.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-9zPWRdGI0jY/T715bmcgVnI/AAAAAAAAHFA/K0XKvlJdO_8/s320/Offsets_Histogram.png" /&gt;
&lt;p&gt;Histograms of the total offsets.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-3hkzLY1D4KY/T715b0VfMxI/AAAAAAAAHFM/DDBXKCGu8ng/s320/Offsets_XYplot.png" /&gt;
&lt;p&gt;X-offsets vs Y-offsets (X and Y are GLON and GLAT). The ellipses are
centered at the mean of the X/Y offsets and have major and minor axes â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;BGPS V2.0 pointing offsets relative to V1 and Herschel:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-41YC6GZJR-0/T715bELMplI/AAAAAAAAHE0/Fzk41wW8ysM/s320/Offsets_CDF.png" /&gt;
&lt;p&gt;Cumulative Distribution Function of the total offsets.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-9zPWRdGI0jY/T715bmcgVnI/AAAAAAAAHFA/K0XKvlJdO_8/s320/Offsets_Histogram.png" /&gt;
&lt;p&gt;Histograms of the total offsets.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-3hkzLY1D4KY/T715b0VfMxI/AAAAAAAAHFM/DDBXKCGu8ng/s320/Offsets_XYplot.png" /&gt;
&lt;p&gt;X-offsets vs Y-offsets (X and Y are GLON and GLAT). The ellipses are
centered at the mean of the X/Y offsets and have major and minor axes
corresponding to the standard deviations.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="v2.0"></category><category term="pointing"></category><category term="version comparison"></category></entry><entry><title>Getting rid of haloes</title><link href="https://keflavich.github.io/blog/getting-rid-of-haloes.html" rel="alternate"></link><published>2012-03-31T00:28:00-06:00</published><updated>2012-03-31T00:28:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-03-31:/blog/getting-rid-of-haloes.html</id><content type="html">&lt;p&gt;Haloes are when images look like this:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-Hwwiewo9FyU/T3Yhs6TpYcI/AAAAAAAAG0k/uKSTBCn95FY/s320/Screen%2Bshot%2B2012-03-30%2Bat%2B3.09.54%2BPM.png" /&gt;
&lt;p&gt;instead of this, as they should:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-t5jVccq9Dtc/T3Yhs-hcY5I/AAAAAAAAG0s/EZ4x0zdSgxw/s320/Screen%2Bshot%2B2012-03-30%2Bat%2B3.09.58%2BPM.png" /&gt;
&lt;p&gt;Things to try:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Pass &lt;tt class="docutils literal"&gt;/return_deconv&lt;/tt&gt; to deconv_map&lt;/li&gt;
&lt;li&gt;Pass &lt;tt class="docutils literal"&gt;/linear&lt;/tt&gt; to deconv_map&lt;/li&gt;
&lt;li&gt;Disable deconvolve - deconvolve=0&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In l123 &amp;amp; l169, at least, &lt;tt class="docutils literal"&gt;/return_deconv&lt;/tt&gt; worked&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="artifacts"></category><category term="deconvolution"></category><category term="mapping"></category></entry><entry><title>New coalignment code</title><link href="https://keflavich.github.io/blog/new-coalignment-code.html" rel="alternate"></link><published>2012-03-20T15:06:00-06:00</published><updated>2012-03-20T15:06:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-03-20:/blog/new-coalignment-code.html</id><summary type="html">&lt;p&gt;pixshift has been giving me issues for a long, long time. It finally
came to a head, though, when nothing I did could make l001 &amp;quot;work&amp;quot;. It
turns out, when you do cross-correlation analysis, you're really only
interested in the most correlated pixel, NOT the junk around it - the
junk â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;pixshift has been giving me issues for a long, long time. It finally
came to a head, though, when nothing I did could make l001 &amp;quot;work&amp;quot;. It
turns out, when you do cross-correlation analysis, you're really only
interested in the most correlated pixel, NOT the junk around it - the
junk around it only provides a second-order correction.
Well, &lt;a class="reference external" href="http://solarmuri.ssl.berkeley.edu/~welsch/public/software/cross_cor_taylor.pro"&gt;cross_cor_taylor.pro&lt;/a&gt;, a tool from the solar physics
community, does exactly that. And it works far, far better than my
hacked-together pixshift code. A lesson I should always take to heart:
don't rewrite code if it's out there. Of course, if I'd known it was out
there, I wouldn't have rewritten it....&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Major Error</title><link href="https://keflavich.github.io/blog/major-error.html" rel="alternate"></link><published>2012-01-06T23:29:00-07:00</published><updated>2012-01-06T23:29:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2012-01-06:/blog/major-error.html</id><content type="html">&lt;p&gt;This was a big problem:
&lt;tt class="docutils literal"&gt;Rev 472, by ginsbura, &lt;span class="pre"&gt;2009-12-15&lt;/span&gt; 14:43readall_pc wasn't getting passed mvperjy&lt;/tt&gt;&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Flow Charts</title><link href="https://keflavich.github.io/blog/flow-charts.html" rel="alternate"></link><published>2011-12-31T02:53:00-07:00</published><updated>2011-12-31T02:53:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-12-31:/blog/flow-charts.html</id><content type="html">&lt;p&gt;Made with &lt;a class="reference external" href="http://code.google.com/p/bgpspipeline/source/browse/bgps_pipeline/documentation/wrap_pipeline_and_log.py"&gt;this code&lt;/a&gt; and &lt;a class="reference external" href="www.graphviz.org"&gt;graphviz&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-rbeS36D6fek/Tv55L9HSfVI/AAAAAAAAGrE/VArJAV60nys/s320/pipeline_v1.0.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-lI_OWOGIVko/Tv55MIfhcdI/AAAAAAAAGrU/MUiQuiBLqrA/s320/pipeline_v2.0.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Calibration: As good as it's gonna get</title><link href="https://keflavich.github.io/blog/calibration-as-good-as-its-gonna-get.html" rel="alternate"></link><published>2011-12-02T23:25:00-07:00</published><updated>2011-12-02T23:25:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-12-02:/blog/calibration-as-good-as-its-gonna-get.html</id><content type="html">&lt;img alt="" src="http://2.bp.blogspot.com/-JLIm1-8V9pc/TtlaRJP2EoI/AAAAAAAAGoA/-gwCmjybJxs/s320/newmottecygx2_bgps_iram_comp_linefits_cross.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-FkotaRfI_hk/TtlaR5VW_PI/AAAAAAAAGoM/Hd9yvKq66lU/s320/newmottecygx2_bgpsv2_iram_comp_linefits_cross.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-9xlFisqEq38/TtlaSXvv3ZI/AAAAAAAAGoY/uWvlhTeriuY/s320/newmottecygx2_bgps_iram_comp_linefits_cross_dr21.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-MGx4yVQpxfU/TtlaS9OB3AI/AAAAAAAAGok/aMz1NHI2G9k/s320/newmottecygx2_bgpsv2_iram_comp_linefits_cross_dr21.png" /&gt;
&lt;p&gt;BGPS vs BGPSv2 in Cyg X&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-JMPVYUkw0nc/Ttla0-Fqn9I/AAAAAAAAGow/9c0IhC4_qlg/s320/newirdc1_bgps_iram_comp_linefits_cross.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-knIt9Yw8FJU/Ttla1XeTfmI/AAAAAAAAGo8/d4bNvhfPf6U/s320/newirdc1_bgpsv2_iram_comp_linefits_cross.png" /&gt;
&lt;p&gt;BGPS vs BGPSv2 in IRDC1 (Rathborne)&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-Uw9lPIsA758/TtlbgMzryZI/AAAAAAAAGpI/3OcrHYS-8KA/s320/testregl44_bgps_s1200_comp_linefits_1.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-ikkojUChsfY/Ttlbg4BnvJI/AAAAAAAAGpU/-SrRpX1GvMw/s320/testregl44_bgpsv2_s1200_comp_linefits_1.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-G6PzOBzHmtc/TtlbhbgsEQI/AAAAAAAAGpg/1K630s21FpQ/s320/testregl44_bgps_s1200_comp_linefits_2.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-NEnpDAiVatM/Ttlbh7_cTdI/AAAAAAAAGps/FDDMbzdHbBw/s320/testregl44_bgpsv2_s1200_comp_linefits_2.png" /&gt;
&lt;p&gt;BGPS vs BGPSv2 in l=44 (comparison is SIMBA, not MAMBO)&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-J27n1Y5t4Ug/TtleWSaYxoI/AAAAAAAAGp4/LuPMX5Iv8E0/s320/l44_regions.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>Check to make sure original fits were/were not for...</title><link href="https://keflavich.github.io/blog/check-to-make-sure-original-fits-werewere-not-for.html" rel="alternate"></link><published>2011-11-17T22:57:00-07:00</published><updated>2011-11-17T22:57:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-11-17:/blog/check-to-make-sure-original-fits-werewere-not-for.html</id><content type="html">&lt;p&gt;Check to make sure original fits were/were not forced through 0,0&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>Calibration Offsets Revisited</title><link href="https://keflavich.github.io/blog/calibration-offsets-revisited.html" rel="alternate"></link><published>2011-11-16T01:05:00-07:00</published><updated>2011-11-16T01:05:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-11-16:/blog/calibration-offsets-revisited.html</id><summary type="html">&lt;p&gt;The agreement with Motte et al 2007 is now perfect with a vertical
ADDITIVE offset instead of the annoying multiplicative offset. An
additive offset can trivially be accounted for by a spatial transfer
function. As is evident in the difference images, the MAMBO data appears
to sit on a plateau â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The agreement with Motte et al 2007 is now perfect with a vertical
ADDITIVE offset instead of the annoying multiplicative offset. An
additive offset can trivially be accounted for by a spatial transfer
function. As is evident in the difference images, the MAMBO data appears
to sit on a plateau.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-dCeUkoHiAPs/TrwYlSZ2I6I/AAAAAAAAGj8/2FpasBudxPc/s320/newtestregl44_bgps_s1200_comp_linefits_point.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-XWWisYSwoiw/TrwYl-E4uQI/AAAAAAAAGkI/Gu5MxohyxZY/s320/newtestregl44_bgpsv2_s1200_comp_linefits_point.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-flBRCavDJKM/TrwYmZLzifI/AAAAAAAAGkU/D7K7-aG_ZZE/s320/testregl44_bgps_s1200_comp_origimages_scales1200peak_1.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-0i_9U9v37Wc/TrwYm3Ctx4I/AAAAAAAAGkg/xj1xWYI4eLo/s320/testregl44_bgpsv2_s1200_comp_origimages_scales1200peak_1.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-Wnys8tmpdnI/TsMFsi04CZI/AAAAAAAAGlc/sXKhoMMDRUM/s320/newirdc1_bgps_iram_comp_linefits_cross.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-XWRv2iQr_yM/TsMFtHzCWUI/AAAAAAAAGlo/MVvzvsJEv8s/s320/irdc1_bgps_iram_comp_origimages_scaleirampeak.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-2VT-44snbic/TsMFthQNCzI/AAAAAAAAGl0/XJmjYJWlT0A/s320/newirdc1_bgpsv2_iram_comp_linefits_cross.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-76VOl5ASlas/TsMFuS2tU7I/AAAAAAAAGmA/1GY0DwzsToo/s320/irdc1_bgpsv2_iram_comp_origimages_scaleirampeak.png" /&gt;
&lt;p&gt;Cygnus X:
BGPSV1:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-Ul21t0ucmOs/TsMGdaRI50I/AAAAAAAAGmM/UhJ_mCKRZ4A/s320/newmottecygx2_bgps_iram_comp_linefits_cross.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-d_XSGb63vtk/TsMGd7cMs1I/AAAAAAAAGmY/MTL7mFfH9_I/s320/newmottecygx2_bgps_iram_comp_linefits_cross_2.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-CKArUxnvfXc/TsMGeY4yP7I/AAAAAAAAGmk/iaRcDy28-8w/s320/newmottecygx2_bgps_iram_comp_linefits_cross_3.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-cNgOGbIFhzc/TsMGe3d7kZI/AAAAAAAAGmw/kn3Y0M18flM/s320/newmottecygx2_bgps_iram_comp_linefits_cross_dr21.png" /&gt;
&lt;p&gt;BGPSV2:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-cIZHQxLW7t0/TsMGrpLUTcI/AAAAAAAAGm8/PJfhh_Z1Y44/s320/newmottecygx2_bgpsv2_iram_comp_linefits_cross.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-55051oTEK34/TsMGrzJL3eI/AAAAAAAAGnI/pd468xeLBxQ/s320/newmottecygx2_bgpsv2_iram_comp_linefits_cross_2.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-f2BTCfMG5Ao/TsMGsTy98yI/AAAAAAAAGnU/6m30n1cgwgQ/s320/newmottecygx2_bgpsv2_iram_comp_linefits_cross_3.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-ND8KA8OqHpc/TsMGs5pAo0I/AAAAAAAAGng/kkucv9xfINk/s320/newmottecygx2_bgpsv2_iram_comp_linefits_cross_dr21.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-8ovlXgU6EIU/TsMMT0wfZ-I/AAAAAAAAGns/dq5Es6kDmE0/s320/sections.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>Bolocat v1-v2 comparison with new calibration</title><link href="https://keflavich.github.io/blog/bolocat-v1-v2-comparison-with-new-calibration.html" rel="alternate"></link><published>2011-08-30T21:04:00-06:00</published><updated>2011-08-30T21:04:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-08-30:/blog/bolocat-v1-v2-comparison-with-new-calibration.html</id><summary type="html">&lt;img alt="" src="http://2.bp.blogspot.com/-c3_0Rlbv2qM/Tl1P5FhWC8I/AAAAAAAAGdc/oiFxmO7vrUU/s320/total_v1v2_40arcsec_ratio_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-Gk60vlSPkWk/Tl1P5c4THoI/AAAAAAAAGdk/E7zdIwtyD3w/s320/total_v1v2_40arcsec_fit_compare.png" /&gt;
&lt;p&gt;I re-examined the Bolocat data on l351 after re-running the pipeline
with the new calibration curve. The change wasn't all that great. See
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/08/bolocat-v1-v2-comparison.html"&gt;this post&lt;/a&gt; for a brief description of the procedure.
In the data below, I've fit the residuals as a function of v1.0.2 flux
density in â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://2.bp.blogspot.com/-c3_0Rlbv2qM/Tl1P5FhWC8I/AAAAAAAAGdc/oiFxmO7vrUU/s320/total_v1v2_40arcsec_ratio_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-Gk60vlSPkWk/Tl1P5c4THoI/AAAAAAAAGdk/E7zdIwtyD3w/s320/total_v1v2_40arcsec_fit_compare.png" /&gt;
&lt;p&gt;I re-examined the Bolocat data on l351 after re-running the pipeline
with the new calibration curve. The change wasn't all that great. See
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/08/bolocat-v1-v2-comparison.html"&gt;this post&lt;/a&gt; for a brief description of the procedure.
In the data below, I've fit the residuals as a function of v1.0.2 flux
density in an aperture (source mask) with a line. The slope of the line
should ideally be zero - that would indicate a multiplicative offset is
an acceptable correction.
Nicely, in the 40&amp;quot; aperture case, I see no reason to exclude the m=0
case. For the most reliable data - the 13pca - the slope is rather small
and the &amp;quot;correction factor&amp;quot; is disturbingly close to what we recommended
(1.5). We have no right to be that lucky...&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-W08ZvMS3M90/TlwhPW62NQI/AAAAAAAAGc8/8YRm6iyDPO8/s320/l351_40arcsec_residualfit.png" /&gt;
&lt;p&gt;...and so perhaps wer are not. The source mask includes more area and
therefore is more sensitive to extended flux recovery. The slopes are
not consistent with 0 - just look at the data above and below 2 Jy to
see that there is a difference. The multiplicative correction of 1.5 is
decent for a pretty wide range of flux densities, but is inadequate for
the brightest sources. This is somewhat interesting... it implies that
the brightest sources also lie on the highest backgrounds.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-GQBE_MjAxt8/TlwhPveClUI/AAAAAAAAGdE/lohBYlJuHwM/s320/l351_sourcemask_residualfit.png" /&gt;
&lt;p&gt;You might note that the brightest source has a smaller correction factor
in both apertures. It's not clear why that is the case, but I don't
think it's enough to call it a trend yet - wait for the full 8000-source
comparison first.
Why is there so much scatter? Not entirely clear, but the scatter is
primarily at low S/N.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-GPKbsfs9Y8k/Tl1OJE43J3I/AAAAAAAAGdM/pVUx9SClgtc/s320/l351_40arcsec_fit_compare_monochrome.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-snhh3Bamwc4/Tl1OJXzOYNI/AAAAAAAAGdU/n-rPxs-ZCtI/s320/l351_40arcsec_ratio_compare_monochrome.png" /&gt;
&lt;p&gt;Here are the same for all of the data reduced up to this point:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-oUewyjZc9wU/Tl1QaGPeURI/AAAAAAAAGds/CHx3BtnT9sA/s320/total_v1v2_sourcemask_fit_compare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-n27ucFd82VI/Tl1Qab1kbUI/AAAAAAAAGd0/kwWAceGqo5c/s320/total_v1v2_sourcemask_ratio_compare.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="bolocat"></category><category term="version comparison"></category></entry><entry><title>Final calibration curves (yeah... sure)</title><link href="https://keflavich.github.io/blog/final-calibration-curves-yeah-sure.html" rel="alternate"></link><published>2011-08-26T17:26:00-06:00</published><updated>2011-08-26T17:26:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-08-26:/blog/final-calibration-curves-yeah-sure.html</id><content type="html">&lt;p&gt;I've finished rederiving the calibration curves self-consistently. These
will now be applied to the data....&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-Px-hpKGeiK0/TlfXKrZw3mI/AAAAAAAAGcc/mJH4Yes9K1I/s320/planet_dcfluxes_05_v2.0_13pca_ds2_defaults_map20.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-n2uTCyFEiqQ/TlfXLCd3twI/AAAAAAAAGck/iDls4F3YpKs/s320/planet_dcfluxes_06_v2.0_13pca_ds2_defaults_map20.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-361ND0Pcic0/TlfXLiczcRI/AAAAAAAAGcs/_RnBjVjrsGY/s320/planet_dcfluxes_07_v2.0_13pca_ds2_defaults_map20.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-Ui00rWxnoiE/TlfXL-jQw_I/AAAAAAAAGc0/9WZG7srlDok/s320/planet_dcfluxes_09_v2.0_13pca_ds2_defaults_map20.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>V1 vs V2: Calibration Curves</title><link href="https://keflavich.github.io/blog/v1-vs-v2-calibration-curves.html" rel="alternate"></link><published>2011-08-25T17:09:00-06:00</published><updated>2011-08-25T17:09:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-08-25:/blog/v1-vs-v2-calibration-curves.html</id><summary type="html">&lt;p&gt;Why did we find a factor ~1.8 in &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/08/bolocat-v1-v2-comparison.html"&gt;the previous post&lt;/a&gt;? Well, for
starters we used a calibration curve that was based off of 'masking' and
other tricky techniques.
The calibration curves below are the first ever produced
self-consistently, i.e. using the EXACT same pipeline with the EXACT â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Why did we find a factor ~1.8 in &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/08/bolocat-v1-v2-comparison.html"&gt;the previous post&lt;/a&gt;? Well, for
starters we used a calibration curve that was based off of 'masking' and
other tricky techniques.
The calibration curves below are the first ever produced
self-consistently, i.e. using the EXACT same pipeline with the EXACT
same parameters as the science data. No hacks were needed to produce
these&lt;a class="reference external" href="#asterisk&amp;quot;"&gt;*&lt;/a&gt;. The recovered Volts/Jy are substantially higher than
BGPSv1 and ALSO higher than the curve used about a year ago in an
attempt to explain the v1 flux discrepancy.
Remember that a higher calibration curve means a LOWER recovered flux. I
haven't finished the check, but odds are pretty good that applying these
self-consistent cal curves will reduce the v2 data to be about 1.5.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-PRU4LQ5f-C4/TlZ9wpeFBeI/AAAAAAAAGb8/jKdJHtIqV40/s320/planet_dcfluxes_05_defaults_ds2_v2.0_13pca_map20.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-AIzsETyl69g/TlZ9w50DjBI/AAAAAAAAGcE/h5ggKhH3dO4/s320/planet_dcfluxes_06_defaults_ds2_v2.0_13pca_map20.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-BNWD4QQ21Ac/TlZ9xZ5eTkI/AAAAAAAAGcM/QOVbum2jXIo/s320/planet_dcfluxes_07_defaults_ds2_v2.0_13pca_map20.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-OucWo74b8VY/TlZ9yFIJYQI/AAAAAAAAGcU/IBMs5YLMlYU/s320/planet_dcfluxes_09_defaults_ds2_v2.0_13pca_map20.png" /&gt;
&lt;p&gt;While no hacks were needed to produce these plots, there were abundant
problems. There are far fewer data points than there should be. The
problems are manifold, but mostly have to do with the PCA scaling (I
think).
In some cases, the first scan in an observation was wildly variable.
There looked to be an exponential or similar decay (as has been observed
in scan turnarounds) at the observation start that took ~3 scans to
decay to bring all of the bolometers onto a scaleable curve. This is a
HUGE problem, because the assumption that the dominant signal is
atmosphere is badly violated in this situation - the signal becomes
electronics-dominated. The first PCA component is then an ugly
step-function. With these first scans flagged out, the whole problem
goes away, but that's a painful manual process. Automating it MAY be
possible, but also risky.
In other cases, particularly September 4th 2007, the atmosphere appeared
to be negligible! While the atmospheric optical depth probably was not,
if it was extraordinarily stable over the course of ~10 minutes, again
we experience severe problems. A stable atmosphere means no atmospheric
variation, which means that ACBOLOS is just noise (plus Uranus signal).
Ironically, this is very bad for calibration - it means there is no
common signal on which we can calibrate the bolos' relative
sensitivities. This problem doesn't seem to affect science data,
probably because there's no such thing as 45-minute stable atmosphere
(especially when you're following rising/setting sources). If I REALLY
need that data, I could snag the relative scalings from a science field
and apply them to the cal data... honestly that's not a bad idea in
general... hmm... Well, we'll explore that later if I have time, that
will take days to implement.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category><category term="version comparison"></category></entry><entry><title>Bolocat v1-v2 comparison</title><link href="https://keflavich.github.io/blog/bolocat-v1-v2-comparison.html" rel="alternate"></link><published>2011-08-23T04:39:00-06:00</published><updated>2011-08-23T04:39:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-08-23:/blog/bolocat-v1-v2-comparison.html</id><summary type="html">&lt;p&gt;For this experiment, I ran Bolocat on all of the v1 and v2 images using
the source masks Erik derived for v1. I then compared the derived fluxes
using both aperture photometry (as defined in bolocat) and the mask
sums.&lt;/p&gt;
&lt;p&gt;First, note that the object_photometry code Erik wrote does â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;For this experiment, I ran Bolocat on all of the v1 and v2 images using
the source masks Erik derived for v1. I then compared the derived fluxes
using both aperture photometry (as defined in bolocat) and the mask
sums.&lt;/p&gt;
&lt;p&gt;First, note that the object_photometry code Erik wrote does NOT do
background subtraction - this is important for understanding
non-multiplicative offsets between v1 and v2.&lt;/p&gt;
&lt;p&gt;I fit a 2-parameter model (a line) to the v2 vs v1 plots using two
methods. The simple linear-least-squares method is one we're all
familiar with, and it gives semi-reasonable results, but is NOT
statistically robust when there are errors on both axes. The other fit
method used was Total Least Squares, which is approximately equivalent
to Principle Component Analysis with 2 vectors. It uses components of
the singular-value-decomposition to determine the best fit. The fits
returned by TLS should be more robust, though the additive offsets need
not be.&lt;/p&gt;
&lt;p&gt;Conclusion: Our factor of 1.5 looks like it was pretty accurate. For 40&amp;quot;
apertures, the best fit is ~1.56, which is easily within the error bars.
Luckily, for 40&amp;quot; apertures, there is no apparent need for an additive
offset (I'm pretty sure the uncertainty on the measured offset is larger
than the offset, though statistically that is not the case), which would
complicate things.&lt;/p&gt;
&lt;p&gt;However, for the source mask, there is a greater scaling factor and a
very substantial offset. This implies that the peaks in v2 are brighter
by a large factor, but the backgrounds in v2 are actually lower than in
v1 (though please do check my reasoning here). I'm really not sure what
to make of the difference between source mask and aperture yet,
though... there's probably something significant in the source mask
being forced to pick positive pixels. (and peppered pickles)&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-9a-O_TQx3Ek/TlMr1f-nmKI/AAAAAAAAGbs/Tp6UY_vwl_s/s320/total_v1v2_40arcsec_fit_compare.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-zhLxvflZ-30/TlMr1mWy6kI/AAAAAAAAGb0/GH7xSizIjnk/s320/total_v1v2_sourcemask_fit_compare.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="bolocat"></category><category term="version comparison"></category></entry><entry><title>v1-v2 comparison</title><link href="https://keflavich.github.io/blog/v1-v2-comparison.html" rel="alternate"></link><published>2011-08-23T04:25:00-06:00</published><updated>2011-08-23T04:25:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-08-23:/blog/v1-v2-comparison.html</id><summary type="html">&lt;p&gt;Some positive results.
v2 is uniformly higher than v1, but at nearly 1.8, not 1.5. Some of this
could be because of a different calibration curve (which is worth
checking on; I'll do that later).&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-OJ0dGhlukDI/TkrJp3xJ3CI/AAAAAAAAGaM/2wljUfSwwiM/s320/v1.0.2_compare_to_v2.0_ds2_deconv_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-JuJNBoV9AFw/TkrJqtQVgYI/AAAAAAAAGaU/SMlGuh16ETs/s320/v1.0.2_compare_to_v2.0_ds2_deconv_deline_compare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-HIMECvNyofo/TkrJrFOgCeI/AAAAAAAAGac/6T6TTJMx0cM/s320/v1.0.2_compare_to_v2.0_ds2_deconv_madflag3_compare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-wYf-dSk8NXY/TkrJsINgC7I/AAAAAAAAGak/k6Kn6WbgxWM/s320/v1.0.2_compare_to_v2.0_ds2_deline_compare.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-cMEqPyhfKDM/TkrJsmmMEpI/AAAAAAAAGas/ZgwSeLos5QQ/s320/v1.0.2_compare_to_v2.0_ds2_inversescaleweight_compare.png" /&gt;
&lt;p&gt;While the pixel-to-pixel comparison yields values ~1.75, the aperture
photometry is perhaps â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some positive results.
v2 is uniformly higher than v1, but at nearly 1.8, not 1.5. Some of this
could be because of a different calibration curve (which is worth
checking on; I'll do that later).&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-OJ0dGhlukDI/TkrJp3xJ3CI/AAAAAAAAGaM/2wljUfSwwiM/s320/v1.0.2_compare_to_v2.0_ds2_deconv_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-JuJNBoV9AFw/TkrJqtQVgYI/AAAAAAAAGaU/SMlGuh16ETs/s320/v1.0.2_compare_to_v2.0_ds2_deconv_deline_compare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-HIMECvNyofo/TkrJrFOgCeI/AAAAAAAAGac/6T6TTJMx0cM/s320/v1.0.2_compare_to_v2.0_ds2_deconv_madflag3_compare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-wYf-dSk8NXY/TkrJsINgC7I/AAAAAAAAGak/k6Kn6WbgxWM/s320/v1.0.2_compare_to_v2.0_ds2_deline_compare.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-cMEqPyhfKDM/TkrJsmmMEpI/AAAAAAAAGas/ZgwSeLos5QQ/s320/v1.0.2_compare_to_v2.0_ds2_inversescaleweight_compare.png" /&gt;
&lt;p&gt;While the pixel-to-pixel comparison yields values ~1.75, the aperture
photometry is perhaps even more severe:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-2kmy7UjYx-U/TkrX2i9j3KI/AAAAAAAAGbU/WTPdP7p6nHY/s320/v1.0.2_compare_to_v2.0_ds2_reconv_point.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-Uhcyj_rCPrY/TkrX2-k72nI/AAAAAAAAGbc/yePgRQO3RCU/s320/v1.0.2_compare_to_v2.0_ds2_reconv_point2.png" /&gt;
&lt;p&gt;Those are a difference of a factor of 2.5, which is rather enormous.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="version comparison"></category></entry><entry><title>Spatial Transfer Function vs. nPCA</title><link href="https://keflavich.github.io/blog/spatial-transfer-function-vs-npca.html" rel="alternate"></link><published>2011-08-10T16:29:00-06:00</published><updated>2011-08-10T16:29:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-08-10:/blog/spatial-transfer-function-vs-npca.html</id><summary type="html">&lt;p&gt;A demonstration that the spatial transfer function can be improved to
~80% at ~300 arcseconds by reducing the number of PCA components
subtracted. However, image fidelity and noise backgrounds suffer, so
these sorts of maps are probably less ideal for point source extraction.
Below:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
0 PCA
3 PCA
10 PCA â€¦&lt;/pre&gt;</summary><content type="html">&lt;p&gt;A demonstration that the spatial transfer function can be improved to
~80% at ~300 arcseconds by reducing the number of PCA components
subtracted. However, image fidelity and noise backgrounds suffer, so
these sorts of maps are probably less ideal for point source extraction.
Below:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
0 PCA
3 PCA
10 PCA
15 PCA
&lt;/pre&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-CPZck7lZils/TkKxcMIgsoI/AAAAAAAAGZg/HeZJfzaSewk/s320/exp15_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_smooth_00pca_median_psds.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-ew7CSdNfc3M/TkKxcZb3qDI/AAAAAAAAGZo/_mSPtt6TgG4/s320/exp15_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_smooth_03pca_psds.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-NG2yqqzPucM/TkKxcxoM6pI/AAAAAAAAGZw/zocHKlKAO3Q/s320/exp15_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_smooth_10pca_psds.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-Y_rIZ33S8QE/TkKxdOlcTAI/AAAAAAAAGZ4/J6kkz5PDasA/s320/exp15_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_smooth_15pca_psds.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category></entry><entry><title>Spatial Transfer Functions, revisit 4</title><link href="https://keflavich.github.io/blog/spatial-transfer-functions-revisit-4.html" rel="alternate"></link><published>2011-08-05T18:56:00-06:00</published><updated>2011-08-05T18:56:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-08-05:/blog/spatial-transfer-functions-revisit-4.html</id><summary type="html">&lt;p&gt;Last report was a bit of a fiasco. There were problems all over the
place I didn't understand. I still don't but I've fixed them. My best
guess at this point is that a pass-by-reference led to an unacceptable
modification of an image. That doesn't even make sense - there was â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last report was a bit of a fiasco. There were problems all over the
place I didn't understand. I still don't but I've fixed them. My best
guess at this point is that a pass-by-reference led to an unacceptable
modification of an image. That doesn't even make sense - there was no
place it could have happened - but, there you have it.
So, going through the process step by step.
This is the effect of smoothing an image:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-3TabjiWVKm4/Tjs03gqxkxI/AAAAAAAAGXk/BQOH5FvG3CM/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky02_seed00_peak010.00_SMvsNOSM_input_psds.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-AWglr2CHB-0/Tjs04fniKDI/AAAAAAAAGXs/MM3RCNu6x10/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky02_seed00_peak010.00_SMvsNOSM_input_compare.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-5yFhvF1iOeY/Tjs1ES7HeuI/AAAAAAAAGX0/T44kJArWn2o/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky02_seed00_peak010.00_SMvsNOSM_input_stf.png" /&gt;
&lt;p&gt;Note from the 3rd figure that 100% recovery isn't reached until ~700
arcseconds.
Next question: What is happening at large spatial scales in the
flat-spectrum simulations?&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-Fi2EBFsPFK4/TjtLzkxRxRI/AAAAAAAAGX8/4GoYEwSaaKc/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky07_seed00_peak100.00_smooth_compare.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-P3TEAHevkEY/TjtL0BG8BbI/AAAAAAAAGYE/oC71ZTFTz3k/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky06_seed00_peak100.00_smooth_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-g0m5hEHx8QY/TjtL00D3USI/AAAAAAAAGYM/687cgIORovk/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky05_seed00_peak100.00_smooth_compare.png" /&gt;
&lt;p&gt;No obvious problems there.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-DwXSkiyw2kE/TjtNt7XadiI/AAAAAAAAGYU/trzLma37DgM/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky05_seed00_peak100.00_smooth_psds.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-Q9ItTP7uQDs/TjtNuILPfLI/AAAAAAAAGYc/w67japCoUpo/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky06_seed00_peak100.00_smooth_psds.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-mgWHY8CT3tQ/TjtNuv1jZ-I/AAAAAAAAGYk/Iddg_I2UKjo/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky07_seed00_peak100.00_smooth_psds.png" /&gt;
&lt;p&gt;Hmm, no apparent problem here either, though one might ask why the two
curves approach each other in sky05 (alpha=-0.5).
So it appears that the reason for the bump up at low frequencies (long
wavelengths) must be because of edge effects. After much hassle, I've
addressed that by cropping images.
Finally, the averaged results:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-26KmVHKU_QY/Tjw8VVYnkkI/AAAAAAAAGY4/-R-e3mwVwZc/s320/stfs_bestmodel_fits.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-lPtvV465aLg/Tjw8VhQZXXI/AAAAAAAAGZA/Rib4AX6z75E/s320/stfs_bestmodels.png" /&gt;
&lt;p&gt;So we've got an Official Spatial Transfer Function.
However, of course, we must note that there is a dependence on the
atmosphere amplitude to source amplitude ratio: it appears that
large-scale structure is *easier* to recover when the atmosphere is at
higher amplitude. This makes sense: it is easier to distinguish faint
astrophysical signal from bright atmosphere in this case. The reason I
didn't run simulations to test this more is that the S/N ratio on small
scales becomes poor for the low astrophysical amplitudes.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category><category term="testing"></category><category term="simulation"></category><category term="pipeline"></category></entry><entry><title>STF measurement attempts, round 3?</title><link href="https://keflavich.github.io/blog/stf-measurement-attempts-round-3.html" rel="alternate"></link><published>2011-08-03T02:51:00-06:00</published><updated>2011-08-03T02:51:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-08-03:/blog/stf-measurement-attempts-round-3.html</id><summary type="html">&lt;p&gt;Below are plots of the spatial transfer function for a variety of
simulation parameters. Each line represents the median (i.e., mean of
the center 2 of 4) spatial transfer function of 4 realizations of the
listed parameters.&lt;/p&gt;
&lt;img alt="alt" src="http://3.bp.blogspot.com/-qAq4e3xotf8/TjJCwJb6knI/AAAAAAAAGXA/mv7hs-uKudI/s320/stfs_atmo01_peak010_smooth.png" /&gt;
&lt;img alt="alt" src="http://2.bp.blogspot.com/-lTKFbV1Zxno/TjJCwluvOXI/AAAAAAAAGXI/fK7qPWDF0Qw/s320/stfs_atmo10_peak010_smooth.png" /&gt;
&lt;img alt="alt" src="http://1.bp.blogspot.com/-HNLrsuXSrvA/TjJCwx9xEBI/AAAAAAAAGXQ/a0l3Qljyp04/s320/stfs_atmo10_peak100_smooth.png" /&gt;
&lt;p&gt;A few unfortunate details are apparent:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The STF is background dependent, though â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;Below are plots of the spatial transfer function for a variety of
simulation parameters. Each line represents the median (i.e., mean of
the center 2 of 4) spatial transfer function of 4 realizations of the
listed parameters.&lt;/p&gt;
&lt;img alt="alt" src="http://3.bp.blogspot.com/-qAq4e3xotf8/TjJCwJb6knI/AAAAAAAAGXA/mv7hs-uKudI/s320/stfs_atmo01_peak010_smooth.png" /&gt;
&lt;img alt="alt" src="http://2.bp.blogspot.com/-lTKFbV1Zxno/TjJCwluvOXI/AAAAAAAAGXI/fK7qPWDF0Qw/s320/stfs_atmo10_peak010_smooth.png" /&gt;
&lt;img alt="alt" src="http://1.bp.blogspot.com/-HNLrsuXSrvA/TjJCwx9xEBI/AAAAAAAAGXQ/a0l3Qljyp04/s320/stfs_atmo10_peak100_smooth.png" /&gt;
&lt;p&gt;A few unfortunate details are apparent:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The STF is background dependent, though not strongly&lt;/li&gt;
&lt;li&gt;The STF appears to never exceed 85%, and be more typically 75%. If
this is not matched by point-source PSDs, an explanation for the flux
discrepancy becomes possible&lt;/li&gt;
&lt;li&gt;The 50% recovery point is much closer in than previously stated, at
closer to 150&amp;quot; than 300&amp;quot;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note for comparison that the recovery fraction for point sources is much
more nearly 1, at least in the calibrator type maps. We need to wait for
Jared's simulations with point sources in a full size map to confirm
this, but it seems pretty likely that the STF is different for point
sources and extended structures.&lt;/p&gt;
&lt;img alt="alt" src="http://4.bp.blogspot.com/-n0mH8DTSc80/Tji3c0tOffI/AAAAAAAAGXc/_Xd-AQMo4QU/s320/psf_ds1_reconv_arrang45_atmotest_noise%252B6.3E-04varyrelscale_amp1.0E%252B00_psds.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="discrepancy"></category><category term="simulation"></category></entry><entry><title>Examining bolocat</title><link href="https://keflavich.github.io/blog/examining-bolocat.html" rel="alternate"></link><published>2011-07-27T22:51:00-06:00</published><updated>2011-07-27T22:51:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-27:/blog/examining-bolocat.html</id><summary type="html">&lt;p&gt;Just in case we were wondering, the V1 bolocat is completely
inconsistent with a lognormal distribution, but is perfectly consistent
(or... at least reasonably consistent...) with a power law distribution.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-kKaOXdf9hW4/TjBRmgiNmqI/AAAAAAAAGUI/4H0KJk70F_o/s320/bolocat_flux_cdf.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-3T9mrt5U39E/TjBRm5p7inI/AAAAAAAAGUQ/ARP6EKQDYo0/s320/bolocat_flux40_cdf.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-ytrgQo5XYEg/TjBRndOQqOI/AAAAAAAAGUY/9g--hpa5X0Y/s320/bolocat_flux80_cdf.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-TqVY1B1uGLw/TjBRnt6uLEI/AAAAAAAAGUg/FhXct0wpEio/s320/bolocat_flux120_cdf.png" /&gt;
&lt;p&gt;These plots show power-law fits (red) and lognormal fits (blue) to the
data (black). It's pretty obvious that the lognormal â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Just in case we were wondering, the V1 bolocat is completely
inconsistent with a lognormal distribution, but is perfectly consistent
(or... at least reasonably consistent...) with a power law distribution.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-kKaOXdf9hW4/TjBRmgiNmqI/AAAAAAAAGUI/4H0KJk70F_o/s320/bolocat_flux_cdf.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-3T9mrt5U39E/TjBRm5p7inI/AAAAAAAAGUQ/ARP6EKQDYo0/s320/bolocat_flux40_cdf.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-ytrgQo5XYEg/TjBRndOQqOI/AAAAAAAAGUY/9g--hpa5X0Y/s320/bolocat_flux80_cdf.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-TqVY1B1uGLw/TjBRnt6uLEI/AAAAAAAAGUg/FhXct0wpEio/s320/bolocat_flux120_cdf.png" /&gt;
&lt;p&gt;These plots show power-law fits (red) and lognormal fits (blue) to the
data (black). It's pretty obvious that the lognormal is a bad fit, but
in case you're unconvinced, the ks test for the &amp;quot;source flux&amp;quot; has a
probability 1.6e-7, and it is the highest likelihood by 17 orders of
magnitude out of the 4 flux types.
By contrast, the simulations are on average (though not uniformly) more
consistent with lognormal than powerlaw distributions:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-lpOaHHV3e3Q/TjCTzm9RwFI/AAAAAAAAGWI/o57oH5SfdqE/s320/simulations_ksvalues_lognormvspowerlaw.png" /&gt;
&lt;p&gt;Even in those examples where the KS test is slightly more favorable for
the powerlaw distribution, the lognormal is a pretty good fit, and the
failure points for the two distributions are in about the same place.
The smoothness of the lognormal distribution is required to reproduce
the observed distribution.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-8_WCGM_8AjM/TjB2tW_JZeI/AAAAAAAAGU4/SDR1guNcNq0/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky07_seed00_peak100.00_smooth_bolocat_cdf.png" /&gt;
&lt;p&gt;Note that the first 4 plots are for the whole BGPS survey. What about an
individual field? For obvious reasons, I choose l30 again.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-vHQoJtAe-vU/TjCIiVcRHsI/AAAAAAAAGVo/04fA4WSCnlA/s320/bolocat_flux40_L30_cdf.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-kIpe2v9_YpQ/TjCIimC8K2I/AAAAAAAAGVw/-o5GZ7DoLOw/s320/bolocat_flux80_L30_cdf.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-Shg66Vp6sUI/TjCIi2HEe4I/AAAAAAAAGV4/na0n21atNsI/s320/bolocat_flux120_L30_cdf.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-R2zq58aXXyI/TjCIjeTdjHI/AAAAAAAAGWA/D3xEDRAgY7M/s320/bolocat_flux_L30_cdf.png" /&gt;
&lt;p&gt;This gets to be a little more interesting - apparently the &amp;quot;source flux&amp;quot;
has a tendency to pick up the power-law distributed background
structure, since it is consistent with a lognormal (but note that it is
also consistent with a powerlaw! The ks test doesn't really say
definitively which is better). Although the fits look bad at high flux,
note that this is a log-log plot and therefore the difference in
probability is rather small.
What does this all indicate? It's not entirely clear whether individual
fields are genuinely more lognormally-distributed or whether the number
statistics are just worse. However, even the source flux is consistent
with a power-law, while many realizations of the simulations are not.
Therefore, we should perform the next logical test - add point sources
drawn from a power-law distribution (and a log-normal distribution?) and
see what bolocat retrieves. We can at least say now that the point
source contribution cannot be ignored, since there is no power-law
distribution that can reproduce the observed bolocat flux distribution.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="bolocat"></category><category term="analysis"></category><category term="simulation"></category></entry><entry><title>Bolocat examination part 1</title><link href="https://keflavich.github.io/blog/bolocat-examination-part-1.html" rel="alternate"></link><published>2011-07-18T22:59:00-06:00</published><updated>2011-07-18T22:59:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-18:/blog/bolocat-examination-part-1.html</id><summary type="html">&lt;img alt="" src="http://2.bp.blogspot.com/-RTBSwnk-CX0/TiS6VA5P39I/AAAAAAAAGT0/kB4v_Krbkm0/s320/bolocatrecovery_inputfiltered.png" /&gt;
&lt;p&gt;This figure shows the flux recovery of bolocat. The Y axis shows the
Input flux (green) and the Filtered flux (blue/cyan/purple) with a few
different large-scale filters. The red line is the 1-1 line. Obviously,
bolocat doesn't recover everything that was there - we removed a lot of
flux â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://2.bp.blogspot.com/-RTBSwnk-CX0/TiS6VA5P39I/AAAAAAAAGT0/kB4v_Krbkm0/s320/bolocatrecovery_inputfiltered.png" /&gt;
&lt;p&gt;This figure shows the flux recovery of bolocat. The Y axis shows the
Input flux (green) and the Filtered flux (blue/cyan/purple) with a few
different large-scale filters. The red line is the 1-1 line. Obviously,
bolocat doesn't recover everything that was there - we removed a lot of
flux, so recovery fractions are in the few % range. However, bolocat
does a much better job than the simple filter at recovering positive
fluxes. Therefore, the filter function still isn't good enough.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category><category term="simulation"></category></entry><entry><title>when things go really really bad</title><link href="https://keflavich.github.io/blog/when-things-go-really-really-bad.html" rel="alternate"></link><published>2011-07-17T23:30:00-06:00</published><updated>2011-07-17T23:30:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-17:/blog/when-things-go-really-really-bad.html</id><content type="html">&lt;img alt="" src="http://4.bp.blogspot.com/-YX2VAOPAHso/TiNwkZ3l1MI/AAAAAAAAGTs/JsOe6JIxpuQ/s320/whoatrippy.png" /&gt;
&lt;p&gt;that's all.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Open Questions I'm trying to answer</title><link href="https://keflavich.github.io/blog/open-questions-im-trying-to-answer.html" rel="alternate"></link><published>2011-07-17T22:58:00-06:00</published><updated>2011-07-17T22:58:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-17:/blog/open-questions-im-trying-to-answer.html</id><summary type="html">&lt;p&gt;I still haven't dealt with
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/07/additional-problems.html"&gt;http://bolocam.blogspot.com/2011/07/additional-problems.html&lt;/a&gt;, or
essentiall any of
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/07/minor-ongoing-problems.html"&gt;http://bolocam.blogspot.com/2011/07/minor-ongoing-problems.html&lt;/a&gt;.
However, they're probably related to this problem:
&lt;tt class="docutils literal"&gt;% CLEAN_ITER_STRUCT: There were&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 1 bolometers with high weights:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 13.5047 indices:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 142 or flagged indices&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 142 â€¦&lt;/tt&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I still haven't dealt with
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/07/additional-problems.html"&gt;http://bolocam.blogspot.com/2011/07/additional-problems.html&lt;/a&gt;, or
essentiall any of
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/07/minor-ongoing-problems.html"&gt;http://bolocam.blogspot.com/2011/07/minor-ongoing-problems.html&lt;/a&gt;.
However, they're probably related to this problem:
&lt;tt class="docutils literal"&gt;% CLEAN_ITER_STRUCT: There were&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 1 bolometers with high weights:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 13.5047 indices:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 142 or flagged indices&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 142&lt;/tt&gt;
which indicates that in a simulation in which there can be no outliers
(in terms of weight/scale), there is one being rejected as an outlier.
That indicates that weights are being computed incorrectly, despite the
fact that scales look right (so far):
&lt;tt class="docutils literal"&gt;Relsens calibration: Scaled to bolometer #&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0% RELSENS_CAL_PCA: There were&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0 NAN scales and&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0 very low scales% RELSENS_CAL_PCA: Scale Median/Mad:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="pre"&gt;1.0005510+/-&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.010990833 led to&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0 scales set to zero for a total of&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0 bad bolos% RELSENS_CAL_PCA: Scales &lt;span class="pre"&gt;avg+/-std&lt;/span&gt; =&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="pre"&gt;1.0007304355062783+/-&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.0103252880998329Relsens calibration: Scaled to bolometer #&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0% RELSENS_CAL_PCA: There were&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0 NAN scales and&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0 very low scales% RELSENS_CAL_PCA: Scale Median/Mad:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="pre"&gt;0.99955294+/-&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.0093122063 led to&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0 scales set to zero for a total of&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0 bad bolos% RELSENS_CAL_PCA: Scales &lt;span class="pre"&gt;avg+/-std&lt;/span&gt; =&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="pre"&gt;0.9990063123041220+/-&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.0096663438876613&lt;/tt&gt;&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Fourier transforms are not commutative or distributive</title><link href="https://keflavich.github.io/blog/fourier-transforms-are-not-commutative-or-distributive.html" rel="alternate"></link><published>2011-07-15T20:09:00-06:00</published><updated>2011-07-15T20:09:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-15:/blog/fourier-transforms-are-not-commutative-or-distributive.html</id><summary type="html">&lt;p&gt;Problem with yesterday's work:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
A*B = IFT(FT(A)*FT(B))A*B - A*C != IFT(FT(A)*(FT(B)-FT(C)))
&lt;/pre&gt;
&lt;p&gt;If instead of yesterday's &amp;quot;bandpass filter&amp;quot; you use the convolution -
convolution 'filter', the agreement in real space and most of fourier
space is much better:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-dXT8RIHG6iI/TiCeMHu2bBI/AAAAAAAAGTc/NjQaTyJb4cc/s320/exp12_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_nosmooth_map20filtercompare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-m0DeYyvE0Xg/TiCeM6b_LOI/AAAAAAAAGTk/MwwIbLjhY4Q/s320/exp12_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_nosmooth_map20filterpsds.png" /&gt;
&lt;p&gt;though map20 clearly â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Problem with yesterday's work:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
A*B = IFT(FT(A)*FT(B))A*B - A*C != IFT(FT(A)*(FT(B)-FT(C)))
&lt;/pre&gt;
&lt;p&gt;If instead of yesterday's &amp;quot;bandpass filter&amp;quot; you use the convolution -
convolution 'filter', the agreement in real space and most of fourier
space is much better:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-dXT8RIHG6iI/TiCeMHu2bBI/AAAAAAAAGTc/NjQaTyJb4cc/s320/exp12_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_nosmooth_map20filtercompare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-m0DeYyvE0Xg/TiCeM6b_LOI/AAAAAAAAGTk/MwwIbLjhY4Q/s320/exp12_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_nosmooth_map20filterpsds.png" /&gt;
&lt;p&gt;though map20 clearly reproduces some structures better (higher) but is
overall less powerful than the filtered map.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category></entry><entry><title>Testing out analytic filter functions</title><link href="https://keflavich.github.io/blog/testing-out-analytic-filter-functions.html" rel="alternate"></link><published>2011-07-15T03:03:00-06:00</published><updated>2011-07-15T03:03:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-15:/blog/testing-out-analytic-filter-functions.html</id><summary type="html">&lt;p&gt;I've attempted to model the spatial filter function as a gaussian (or
PSF) plus an inverse gaussian. i.e., the high-spatial-frequency
components are smoothed with the PSF, and the low spatial frequency
components are convolved with a (1-gaussian) high-pass filter.
First, the mildly good news: With a 300&amp;quot; FWHM large-scale â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've attempted to model the spatial filter function as a gaussian (or
PSF) plus an inverse gaussian. i.e., the high-spatial-frequency
components are smoothed with the PSF, and the low spatial frequency
components are convolved with a (1-gaussian) high-pass filter.
First, the mildly good news: With a 300&amp;quot; FWHM large-scale cutoff, the
filter PSD reasonably resembles the iterative map PSD:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-udANxY5rM98/Th-i7hx3qnI/AAAAAAAAGS0/kwoR30ZO5OI/s320/exp12_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_nosmooth_map20filterpsds.png" /&gt;
&lt;p&gt;Luckily, the double-filter goes a very long way in explaining the
scale-free flux loss. In the following diagram, I show the effect of the
filter compared to the input map.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-iZtSoQjlzJY/Th-jf6oatlI/AAAAAAAAGS8/p8ZcznsKGpI/s320/exp12_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_nosmooth_filterpsds.png" /&gt;
&lt;p&gt;The filter only recovers about 75% of the flux at ANY wavenumber. The
map does slightly worse at high frequencies, which I can't explain yet.
These show the recovery fraction of the iterative maps, a gaussian
smoothing function with FWHM=33&amp;quot;, and the mid-pass-filter. Map20 (no
smooth) has a lot of additional &amp;quot;noise power&amp;quot; at high spatial
frequencies; if it wasn't for the telescope filter function, we would
apparently have pretty good high-frequency recovery. Hmph.
Note that map20 is higher than the filter at some intermediate
frequencies, but quite a bit lower at higher frequencies. Also note the
moderately poor agreement between the 'smoothed' and 'smoothed (theory)'
lines.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-zhxfyI_XDNY/Th-qZmsMZaI/AAAAAAAAGTE/550ocw2kFx8/s320/filterfunctions_smoothedx2.png" /&gt;
&lt;p&gt;Finally, look at the comparison between map20 and fiiltered. The
agreement is not bad for positive points; filtered is apparently
slightly higher but that can be adjusted. The problem: the filter forces
some structures that are negative or zero to be positive. For example,
look at the feature at 210,300 that is negative in Map20 but positive in
Filtered. In the real (input) map, this feature is lower than its
surroundings - it is legitimately negative.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-zH98yuBL7lo/Th-tQIoKYCI/AAAAAAAAGTM/QNqslST6b2c/s320/exp12_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_nosmooth_map20filtercompare.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-bvlju06_ySU/Th-ttpCOuhI/AAAAAAAAGTU/3zoCyl5gCIY/s320/exp12_ds2_astrosky_arrang45_atmotest_amp5.0E%252B02_sky00_seed00_peak050.00_nosmooth_filtercompare.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category><category term="simulation"></category></entry><entry><title>Masked edge effects?</title><link href="https://keflavich.github.io/blog/masked-edge-effects.html" rel="alternate"></link><published>2011-07-13T20:28:00-06:00</published><updated>2011-07-13T20:28:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-13:/blog/masked-edge-effects.html</id><content type="html">&lt;p&gt;I raised the possibility that the ratty edges of a scan could affect the
power spectrum measurements, leading to a scale-free power loss. This
doesn't appear to happen... instead, the masking adds some small-scale
power and apparently a small amount of large-scale power.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-y7Bh9ngi7mY/Th3_sLpN0VI/AAAAAAAAGSc/4P67rBou5HE/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B00_sky03_seed00_peak010.00_nosmooth_test_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-cg1akcZbUek/Th3_sicaVmI/AAAAAAAAGSk/_4sALFui9kA/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B00_sky03_seed00_peak010.00_nosmooth_test_psds.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-y-9SbSCsPqw/Th3_tHJGc8I/AAAAAAAAGSs/suuiw8xvwpQ/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B00_sky03_seed00_peak010.00_nosmooth_test_stf.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category></entry><entry><title>Spatial Transfer Functions</title><link href="https://keflavich.github.io/blog/spatial-transfer-functions.html" rel="alternate"></link><published>2011-07-13T18:54:00-06:00</published><updated>2011-07-13T18:54:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-13:/blog/spatial-transfer-functions.html</id><summary type="html">&lt;p&gt;The majority of the past week has been dedicated to debugging; it looks
like cross-scanned simulations finally work.
The plot below is a derivation of the spatial transfer function for a
number of different intrinsic sky power-law power spectra.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-JyAPg0u9uQ8/Th3kuQh1fpI/AAAAAAAAGRs/pP7o3n9_wds/s320/Experiment10_AverageRecoveryFunction.png" /&gt;
&lt;p&gt;Justifying the above plot is essential.
First, the very steep power-laws â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The majority of the past week has been dedicated to debugging; it looks
like cross-scanned simulations finally work.
The plot below is a derivation of the spatial transfer function for a
number of different intrinsic sky power-law power spectra.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-JyAPg0u9uQ8/Th3kuQh1fpI/AAAAAAAAGRs/pP7o3n9_wds/s320/Experiment10_AverageRecoveryFunction.png" /&gt;
&lt;p&gt;Justifying the above plot is essential.
First, the very steep power-laws [-3 in the example below] show a
recovery fraction &amp;gt;1. This is simply because their S/N was inadequate -
the output power spectrum is nearly flat, but at a level higher than the
sky.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-JPBjsLDfP5M/Th3lw5n1xTI/AAAAAAAAGR0/aDeOmMv5s8w/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky00_seed00_peak010.00_nosmooth_compare.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-LOCDmoLCcZs/Th3lxfnKVzI/AAAAAAAAGR8/9NCM3OroGoM/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky00_seed00_peak010.00_nosmooth_psds.png" /&gt;
&lt;p&gt;Second, the most plausible power-laws [-1.5 in the example below] show
pretty good recovery (90-95% over the relevant range):&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-MTZ8WGl3ZRc/Th3mMkvv2II/AAAAAAAAGSE/0OO4Te39fPI/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky03_seed00_peak010.00_nosmooth_compare.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-5IeTZW-ZTAw/Th3mNHPC8gI/AAAAAAAAGSM/WhIWClGWqbo/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky03_seed00_peak010.00_nosmooth_psds.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-O6ofm7GaxUI/Th3mNgf29AI/AAAAAAAAGSU/VzQ7aL-yd_E/s320/exp10_ds2_astrosky_arrang45_atmotest_amp1.0E%252B01_sky03_seed00_peak010.00_nosmooth_stf.png" /&gt;
&lt;p&gt;There are some &amp;quot;white&amp;quot; power losses, particularly in the flatter
power-spectra. My best guess is that this has something to do with the
relative scales being offset from a mean of 1, but so far all tests to
show that that is the cause have in fact shown no problems at all. What
else could cause a scale-independent power loss?
Also, the flat power spectrum (and inverted) aren't quite flat because I
impose a &amp;quot;galactic scale height&amp;quot; on them. Should I stop doing that?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category></entry><entry><title>additional problems</title><link href="https://keflavich.github.io/blog/additional-problems.html" rel="alternate"></link><published>2011-07-12T19:08:00-06:00</published><updated>2011-07-12T19:08:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-12:/blog/additional-problems.html</id><summary type="html">&lt;p&gt;There are a few cases in the L=30 field that look awful. 050706_o31
probably observed the inside of the dish. 070727_ob6 shows some
streaking that I can't easily explain... though it appears that there
are some bad bolos that need to get flagged out. I wonder if â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are a few cases in the L=30 field that look awful. 050706_o31
probably observed the inside of the dish. 070727_ob6 shows some
streaking that I can't easily explain... though it appears that there
are some bad bolos that need to get flagged out. I wonder if that's
systematic over 070727 observations....&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>[minor] Ongoing problems...</title><link href="https://keflavich.github.io/blog/minor-ongoing-problems.html" rel="alternate"></link><published>2011-07-10T19:41:00-06:00</published><updated>2011-07-10T19:41:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-07-10:/blog/minor-ongoing-problems.html</id><summary type="html">&lt;p&gt;Since I have many tasks running in parallel, I need to summarize them
sometimes...&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;There are many &amp;quot;bad&amp;quot; observations that haven't been placed in &amp;quot;bad&amp;quot;
directories. A list of the error messages generated is here: &lt;a class="reference external" href="http://code.google.com/p/bgpspipeline/wiki/MakingInfiles"&gt;Making
Infiles wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;There may be streaking in the BGPS ds2 images of l030 and â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;Since I have many tasks running in parallel, I need to summarize them
sometimes...&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;There are many &amp;quot;bad&amp;quot; observations that haven't been placed in &amp;quot;bad&amp;quot;
directories. A list of the error messages generated is here: &lt;a class="reference external" href="http://code.google.com/p/bgpspipeline/wiki/MakingInfiles"&gt;Making
Infiles wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;There may be streaking in the BGPS ds2 images of l030 and l032. Still
trying to re-run cleanly to find out&lt;/li&gt;
&lt;li&gt;There may be unflagged high-points in l030 and l032. Also under
examination&lt;/li&gt;
&lt;li&gt;Simulations have been generating bulk-offset outputs; my suspicion
was that the relative scales were being set incorrectly because astro
dominated atmo, so I bumped up the atmo scale. The tests have run but
I haven't examined the outputs&lt;/li&gt;
&lt;li&gt;V1 sims have shown streaking, possibly because of the previous
bullet, but certainly (in part) because cross-scans haven't worked&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="problems"></category><category term="pipeline"></category><category term="minor"></category></entry><entry><title>Direct comparison of column-density power spectra</title><link href="https://keflavich.github.io/blog/direct-comparison-of-column-density-power-spectra.html" rel="alternate"></link><published>2011-06-29T04:43:00-06:00</published><updated>2011-06-29T04:43:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-06-29:/blog/direct-comparison-of-column-density-power-spectra.html</id><summary type="html">&lt;p&gt;I've multiplied the 13CO integrated data cube, the Herschel 500
micron*, and the BGPS v1.0 and v2.0 by the appropriate conversion
factor to get the maps into units of column density assuming T=20K and
some opacity for the dust maps. BGPS v1 has been multiplied by the â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've multiplied the 13CO integrated data cube, the Herschel 500
micron*, and the BGPS v1.0 and v2.0 by the appropriate conversion
factor to get the maps into units of column density assuming T=20K and
some opacity for the dust maps. BGPS v1 has been multiplied by the 1.5
&amp;quot;correction&amp;quot; factor.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The Herschel maps are arbitrarily scaled; I didn't derive an actual
column conversion but just guess-and-checked once or twice until I got
something pretty close.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;The power spectra look pretty outstanding:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/--uPAgTvMjkk/TgqcjV9uvhI/AAAAAAAAGO4/cOe1iLuF-H0/s320/powerspectrum_comparison_512_0x1.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-1Lupi5MSVpk/TgqcjsPwKFI/AAAAAAAAGPA/D9oNXIHdRtE/s320/powerspectrum_comparison_512_1x1.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-P2pC9RDKUic/TgqckFwVQUI/AAAAAAAAGPI/FU8cUUZe7bc/s320/powerspectrum_comparison_512_2x1.png" /&gt;
&lt;p&gt;The bumps and wiggles in the 50-200&amp;quot; range are quite well-matched in
Herschel and Bolocam. Some map edge effects are visible in the Herschel
maps, resulting in multi-frequency bumps at small spatial scales. The
Herschel noise floor is also quite evidently lower. Also noteworthy is
that BGPS v1 (scaled up by 1.5) matches the others &amp;quot;pretty well&amp;quot; but is
a worse match, in general, to the Herschel data than is the BGPS v2.
Here are some zoomed-in plots on the inverse scale:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-ldoGiyzeb2w/TgqhYPqerHI/AAAAAAAAGPQ/E1BFNEhcadw/s320/powerspectrum_comparison_512_0x1.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-algBRWCXB9E/TgqhYgcwsPI/AAAAAAAAGPY/eSbDDcAYvCk/s320/powerspectrum_comparison_512_1x1.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-36H34cVnAPM/TgqhY7f4kAI/AAAAAAAAGPg/HUWvO9nZwuE/s320/powerspectrum_comparison_512_2x1.png" /&gt;
&lt;p&gt;And finally, the 13CO data is totally unrepresentative of the dust data.
There is very little agreement on any scale. This may imply that the
13CO and/or dust temperature is too high, as a decreased T_D or T_ex
will decrease 13CO column and increase dust column. However, it also
raises a question - on what scales should dust and CO agree?
This is getting into some real science, perhaps. The shapes of the CO
and dust power spectra disagree: the CO is pretty well-fit by a power
law, while the dust is not. What hypotheses can explain this?&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;There is a systematic temperature difference / preference in which CO
or dust is hotter on the largest scales.
-Dust is probably warmer on larger scales, however CO should be less
abundant / more readily dissociated on these largest, most diffuse
scales. CO shouldn't exist (or at least, should be underabundant) in
regions with high temperature. Maybe? This probably needs to be
quantified.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;There is a systematic dust opacity difference on large scales
resulting in lower dust emission.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;This is almost certainly true: the dust population increases in
opacity with age, following OH94. Dust on the largest spatial scales
should not have coagulated / collected ice, leading to a lower
opacity on the largest scales&lt;/li&gt;
&lt;li&gt;This may also be true even though CO is present: dust coagulation
is less efficient than CO formation at n~10^3-10^4 (I think - again,
off the cuff, but consistent with OH94)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;The CO overestimates all scales, either because of incorrect bulk
abundance or temperature considerations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;This is problematic..... if you drop the CO values at all scales, it
becomes deficient in the 50-200 arcsecond range, where the dust
measurements agree quite well&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;There is a preferred distance in both images&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It is not clear that the observed effects would occur because of
this&lt;/li&gt;
&lt;li&gt;It is also quite evident from other analyses that there IS a
preferred velocity, at least, and it completely dominates all others
and has the same shape as the integrated power spectrum. So a
distance effect is most likely ruled out.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category></entry><entry><title>Power Spectra of 13CO and Bolocam</title><link href="https://keflavich.github.io/blog/power-spectra-of-13co-and-bolocam.html" rel="alternate"></link><published>2011-06-22T18:14:00-06:00</published><updated>2011-06-22T18:14:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-06-22:/blog/power-spectra-of-13co-and-bolocam.html</id><content type="html"></content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Measuring preferred angles in the Herschel data on larger scales</title><link href="https://keflavich.github.io/blog/measuring-preferred-angles-in-the-herschel-data-on-larger-scales.html" rel="alternate"></link><published>2011-06-07T22:09:00-06:00</published><updated>2011-06-07T22:09:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-06-07:/blog/measuring-preferred-angles-in-the-herschel-data-on-larger-scales.html</id><summary type="html">&lt;p&gt;This is something of a repeat of yesterday's exercise, but for Herschel
data on larger scales, where filamentation is expected (at different
angles?) on a different scale than the Galactic plane.
First example: L030 500 microns&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-wtocYOxuJGo/Te6boI6cE7I/AAAAAAAAGNU/f9h0MXIPNh8/s320/bin_l30_plw_PSD.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-HlNCVZYyly4/Te6bob1mWLI/AAAAAAAAGNc/Jq6MTJnVyWE/s320/bin_l30_plw_azprofile.png" /&gt;
&lt;p&gt;There is evidently a preferred direction that is correlated down to the
resolution of â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is something of a repeat of yesterday's exercise, but for Herschel
data on larger scales, where filamentation is expected (at different
angles?) on a different scale than the Galactic plane.
First example: L030 500 microns&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-wtocYOxuJGo/Te6boI6cE7I/AAAAAAAAGNU/f9h0MXIPNh8/s320/bin_l30_plw_PSD.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-HlNCVZYyly4/Te6bob1mWLI/AAAAAAAAGNc/Jq6MTJnVyWE/s320/bin_l30_plw_azprofile.png" /&gt;
&lt;p&gt;There is evidently a preferred direction that is correlated down to the
resolution of the map, though the preference is smallest at the smallest
scales. This may simply be a statement that there are more sources along
the galactic plane, though, since there really isn't any particularly
obvious filamentation in the image.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-LfWovOR8nBk/Te6bpM-PNTI/AAAAAAAAGNk/T9il85L34p0/s320/bin_l59_plw_PSD.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-1_7ezH0S6tk/Te6bpokBuYI/AAAAAAAAGNs/AQL0U86N4gw/s320/bin_l59_plw_azprofile.png" /&gt;
&lt;p&gt;In L59, on the other hand, there is at most a very weak preference
except at the largest scales corresponding to the Galactic Plane. This
is somewhat interesting because there IS obvious filamentation in the
L59 image, but it does not have a preferred direction. Unfortunately, it
is not obvious whether or where filamentation shows up in fourier space
if it does not have a preferred direction. There is no excess at any
spatial scale that I can pick out.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category></entry><entry><title>Hunting for preferred directions</title><link href="https://keflavich.github.io/blog/hunting-for-preferred-directions.html" rel="alternate"></link><published>2011-06-06T03:58:00-06:00</published><updated>2011-06-06T03:58:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-06-06:/blog/hunting-for-preferred-directions.html</id><summary type="html">&lt;p&gt;In our last group meeting, we discussed simulations using filamentary
structures. I've been trying to determine how best to generate
random/artificial filamentary structures in images. The first step in
that direction is coming up with a way to measure asymmetries and
therefore preferred directions within a real map. In â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In our last group meeting, we discussed simulations using filamentary
structures. I've been trying to determine how best to generate
random/artificial filamentary structures in images. The first step in
that direction is coming up with a way to measure asymmetries and
therefore preferred directions within a real map. In order to do this,
I've had to develop a number of new tools in agpy for azimuthally binned
radial profiles and radially-averaged azimuthal profiles
(&lt;a class="reference external" href="http://code.google.com/p/agpy/source/browse/trunk/agpy/radialprofile.py"&gt;radialprofile.py&lt;/a&gt;).
Examining real maps is necessary because a simple sinusoidal dependence
of the power introduces filamentation along the same directions at ALL
scales, which is not obviously (or in some cases, obviously not) the
correct solution. Filaments are observed on large scales, but sometimes
there can be 'kinks' in opposite directions on small scales.
So, the map I picked to examine was one with the most flagrantly obvious
filamentary structure in it: the Motte DR 21 MAMBO map. It was also a
choice of convenience because I already had the data on my laptop....&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-ULjqyt_ofEI/TexIAK9ohhI/AAAAAAAAGM0/eCEys_tFOTA/s320/MAMBOmap.png" /&gt;
&lt;p&gt;The preferred direction is quite obvious in this map: there is a long
filament going up and down the map. Therefore, the DC component should
be substantially higher in one direction than the other.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-X7TY9wPUL7Y/TexIAZ7hH_I/AAAAAAAAGM8/IEkgX500_Os/s320/MAMBOpsd.png" /&gt;
&lt;p&gt;In the power-spectral-density image, it is quite clear that there is a
preferred direction, though it is not obvious that the fourier transform
is rotated 90 degrees from the image. My fourier intuition somewhat
fails me here.... I realize that a broad, smooth profile in real space
should be narrow and highly peaked in fourier space, but I don't fully
understand why it effectively spreads out in the perpendicular
direction, which I have confirmed that it does with a simple experiment.
I also don't know what the Shah function is, but it implies a periodic
dip in the image at every 1/5th of the image, or every 50 pixels.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-l4qWlj1G42k/TexIAufhjSI/AAAAAAAAGNE/UqagczdWzwA/s320/MAMBOpowerspectra.png" /&gt;
&lt;p&gt;These are the power spectra averaged over different angles as labeled.
-15 corresponds to -15 to +15, 15 corresponds to 15 to 45, etc. The
highly peaked 75-105 power spectrum shows the large-scale filamentary
profile. I think the difference in the DC component is actually an
artifact of the azimuthal binning process: each pixel can only be
assigned one angle, so the DC value isn't included in all of them...
I'll need to find a workaround for that because it's quite deceptive.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-qEWk2rRrwNI/TexIBKn59FI/AAAAAAAAGNM/MXdsiKagpW4/s320/MAMBOazspectra.png" /&gt;
&lt;p&gt;The more interesting way to view the data - and perhaps to analyze maps
- is to take &lt;em&gt;radial&lt;/em&gt; averages in some range of spatial scales and plot
the azimuthal dependence. There is a clear sinusoid at large scales. The
legend shows &amp;quot;spatial frequency&amp;quot; in 1/pixel units. The distribution
becomes more even with angle and even changes preferred direction at
smaller scales (higher frequencies).
Next step is testing different approaches. I think an added,
steeper-power-law component would probably be the best way to start.
Another suggestion, courtesy Bruce Elmegreen, is to attempt this sort of
asymmetric power law sampling in 3 dimensions (with only 1 or 2
dimensions asymmetric) and then projecting down onto two dimensions.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category></entry><entry><title>Updates for 6/1/2011 meeting</title><link href="https://keflavich.github.io/blog/updates-for-612011-meeting.html" rel="alternate"></link><published>2011-06-01T21:40:00-06:00</published><updated>2011-06-01T21:40:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-06-01:/blog/updates-for-612011-meeting.html</id><summary type="html">&lt;p&gt;This is going to be a mishmash of various things....
First, Jared has run the same simulations I e-mailed out through the
V1.0 pipeline. Unfortunately, the results are not good - there is
substantial streaking of a variety not seen in the real data in V1.
Second, here are the â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is going to be a mishmash of various things....
First, Jared has run the same simulations I e-mailed out through the
V1.0 pipeline. Unfortunately, the results are not good - there is
substantial streaking of a variety not seen in the real data in V1.
Second, here are the simulated images from V2:
&lt;a class="reference external" href="http://eta.colorado.edu/bgps/simulations/Experiment7_Simulation_Images.pdf"&gt;http://eta.colorado.edu/bgps/simulations/Experiment7_Simulation_Images.pdf&lt;/a&gt;
Unfortunately I can't present a direct comparison because something got
screwed up...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Recovery as a function of bolometer noise part 2</title><link href="https://keflavich.github.io/blog/recovery-as-a-function-of-bolometer-noise-part-2.html" rel="alternate"></link><published>2011-05-27T23:49:00-06:00</published><updated>2011-05-27T23:49:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-05-27:/blog/recovery-as-a-function-of-bolometer-noise-part-2.html</id><summary type="html">&lt;p&gt;In the Experiment 7 simulations I was running, I observed greater noise
than expected, causing me to question the results of the &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/05/recovery-as-function-of-bolometer-noise.html"&gt;previous
post&lt;/a&gt;. I therefore ran Experiment 8, which is the same as Experiment 6
from that post with a larger (320x320) map with a larger step size. The â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the Experiment 7 simulations I was running, I observed greater noise
than expected, causing me to question the results of the &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/05/recovery-as-function-of-bolometer-noise.html"&gt;previous
post&lt;/a&gt;. I therefore ran Experiment 8, which is the same as Experiment 6
from that post with a larger (320x320) map with a larger step size. The
noise recovery remains linear, but the scaling is quite different - a
factor of ~4 instead of ~12. The step size is the most likely culprit,
since an 8x larger step size should result in sqrt(8)~2.8 worse noise
per pixel.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-ubZ-9LXWmXQ/TeAdFoOUcZI/AAAAAAAAGMY/bSSwM2JuLyA/s320/exp8_measurednoise_vs_bolonoiseRMS.png" /&gt;
&lt;p&gt;There are some curious / worrisome artifacts that turn up and are
evident in the recovery fraction plot. For the low-noise cases, the
middle bolometers get totally flagged out because they are over-weighted
(by orders of magnitude).&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-0KKwo1wB6aI/TeAdFz6pTiI/AAAAAAAAGMg/yHGsx8j7WMM/s320/exp8_recovery_vs_bolonoiseRMS.png" /&gt;
&lt;p&gt;So I'm forced to explore via pyflagger. I will almost certainly need to
re-run all experiments after making a change to how weights are
computed.
Well, it turns out the problem is that those 28 bolos are scaled to
zero, even though there is nothing obvious (or even suggestive) in their
timestream plots. This is only true when varyrelscale is off. Apparently
varying the relative scales leads to a different problem.
AHA! The noise is so low that the relative scales are SO well correlated
that the signal is enough to cause problems! A plausible solution is
therefore no change to the pipeline, but to add minimal (nominal) noise
to the relative scales to increase the MAD so that the others don't get
flagged out.
So I added a 1% variation, which prevented flagging at the scale stage,
but there are still some disturbing artifacts in the map:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-TX2_8PsUgdM/TeA4Iu9T5FI/AAAAAAAAGMo/vfEjTGcSBp0/s320/psf_ds1_reconv_arrang45_atmotest_noise%252B1.0E-03_amp1.0E%252B00_compare.png" /&gt;
&lt;p&gt;Unfortunately, this problem requires further examination in detail. Exp
9/10 should probably be gaussians and airys on larger step-size maps,
but the solution will require something else, possibly even a change in
the pipeline. On the plus side, I think I can re-run experiment 7 with a
factor of 4 instead of 12 scaling for the noise and expect it to work.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category></entry><entry><title>Recovery as a function of bolometer noise</title><link href="https://keflavich.github.io/blog/recovery-as-a-function-of-bolometer-noise.html" rel="alternate"></link><published>2011-05-26T18:47:00-06:00</published><updated>2011-05-26T18:47:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-05-26:/blog/recovery-as-a-function-of-bolometer-noise.html</id><summary type="html">&lt;p&gt;One clear simulation result comes from varying the amplitude of the
gaussian noise added to each bolometer's timestream for a fixed
atmosphere amplitude. The atmosphere amplitude sets the &lt;em&gt;mean&lt;/em&gt; value of
the atmosphere timestream.
Increased bolometer noise results in decreased recovery of the outer
rings of the PSF. This is â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;One clear simulation result comes from varying the amplitude of the
gaussian noise added to each bolometer's timestream for a fixed
atmosphere amplitude. The atmosphere amplitude sets the &lt;em&gt;mean&lt;/em&gt; value of
the atmosphere timestream.
Increased bolometer noise results in decreased recovery of the outer
rings of the PSF. This is demonstrated in that the peak amplitudes
remain constant (as long as they are still recovered) while the aperture
sums (in 100&amp;quot; radius apertures) decrease.
The simulations were run on a logarithmic spacing from 1e-3 to 1e0. The
1e0 point is missing because the peak flux wasn't recovered by the
gaussian fitter. The model maps don't recover the source at all for this
run, which is worrisome, since it means there is no iterative process
There is a minor concern that some simulations over-recover the peak at
high noise, but the effect is at a &amp;lt;1% level so not very worrisome.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-H0j13RdCays/Td6QrP78qWI/AAAAAAAAGMI/X-74WUEgYFE/s320/exp6_recovery_vs_bolonoiseRMS.png" /&gt;
&lt;p&gt;From the same set of simulations, I derive the pixel RMS of the map (the
noise level) derived from a give individual bolometer noise. The
theoretical expectation would be
Measured Noise = Input Noise / N(bolometers)
&lt;em&gt;if&lt;/em&gt; the pixel sampling and the timestream sampling were the same (i.e.
there were exactly sqrt(nbolos) hits per pixel). This is not exactly the
case, and there are potential additional sources of noise. Nonetheless,
the naive theory appears to be good enough in this simulation:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-ar8f4tdXUkQ/Td6fecs1WoI/AAAAAAAAGMQ/f_PwoxFp4Fo/s320/exp6_measurednoise_vs_bolonoiseRMS.png" /&gt;
&lt;p&gt;You can ignore the green/blue points in this plot; they just show that
the std. dev. around the source is dominated by the source.
Additionally, there is a noise floor, probably set by an inability to
model the point source when the S/N gets to be ~500, preventing
convergence of the iterator at a level better than 0.2%.
In short, though, I'm going to use 1/sqrt(nbolos) to determine the
appropriate input noise level in the astro simulations.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category></entry><entry><title>Astrophysical Signal Modeling</title><link href="https://keflavich.github.io/blog/astrophysical-signal-modeling.html" rel="alternate"></link><published>2011-05-24T17:39:00-06:00</published><updated>2011-05-24T17:39:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-05-24:/blog/astrophysical-signal-modeling.html</id><summary type="html">&lt;p&gt;Here we finally get into the meat of the simulations. The goal is to
develop realistic - but arbitrary - astrophysical models to run through
simulations.
The first step is to figure out what a realistic sky looks like. To this
end, I use the HiGal SDP fields, looking only at their â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here we finally get into the meat of the simulations. The goal is to
develop realistic - but arbitrary - astrophysical models to run through
simulations.
The first step is to figure out what a realistic sky looks like. To this
end, I use the HiGal SDP fields, looking only at their power spectra.
They are well represented by a power law with Î± = 3 (shown in the dashed
black line below).&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-50R2lfaIGrY/TdvZi5tl5VI/AAAAAAAAGLQ/w45OC9dk3Rg/s320/sdp_psds_powerlaw.png" /&gt;
&lt;p&gt;Therefore, I've attempted to randomly sample from a similar power law
distribution using the following IDL code:&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;dimsize = 512&amp;nbsp;&amp;nbsp;&amp;nbsp; realpower = realpowers[ii]&amp;nbsp;&amp;nbsp;&amp;nbsp; imagpower = imagpowers[ii]&amp;nbsp;&amp;nbsp;&amp;nbsp; imagscale = imagscales[ii]&amp;nbsp;&amp;nbsp;&amp;nbsp; peakamp = 1.0&amp;nbsp;&amp;nbsp;&amp;nbsp; noise = 0.03&amp;nbsp;&amp;nbsp;&amp;nbsp; smoothscale = 2.0&amp;nbsp;&amp;nbsp;&amp;nbsp; smoothkernel = &lt;span class="pre"&gt;psf_gaussian(npix=512,ndim=2,fwhm=31.2/7.2/2.0,/normalize)&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; sigma_gp = 128.0 ; &lt;span class="pre"&gt;sigma-width&lt;/span&gt; of the Galactic Plane (can get more accurate value from Cara's paper)&amp;nbsp;&amp;nbsp;&amp;nbsp; xx = findgen(dimsize) #&amp;nbsp; replicate(1.0,dimsize)&amp;nbsp;&amp;nbsp;&amp;nbsp; yy = findgen(dimsize) ## replicate(1.0,dimsize)&amp;nbsp;&amp;nbsp;&amp;nbsp; rr = sqrt( &lt;span class="pre"&gt;(xx-255.5)^2&lt;/span&gt; + &lt;span class="pre"&gt;(yy-255.5)^2&lt;/span&gt; )&amp;nbsp;&amp;nbsp;&amp;nbsp; realpart = (rr^realpower) * &lt;span class="pre"&gt;randomn(seed1,[dimsize,dimsize])&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; imagpart = &lt;span class="pre"&gt;((rr*imagscale)^imagpower)&lt;/span&gt; * &lt;span class="pre"&gt;randomn(seed2,[dimsize,dimsize])*complex(0,1)&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; fakesky = abs(fft(shift(realpart + &lt;span class="pre"&gt;imagpart,0,0),1))&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; expweight = &lt;span class="pre"&gt;exp(-(yy-255.5)^2/(2.0*sigma_gp^2))&lt;/span&gt; ; most power is in the inner plane&amp;nbsp;&amp;nbsp;&amp;nbsp; fakesky *= peakamp/max(fakesky)&amp;nbsp;&amp;nbsp;&amp;nbsp; fakesky_sm = convolve(fakesky,smoothkernel)&amp;nbsp;&amp;nbsp;&amp;nbsp; fakesky_sm = fakesky_sm*expweight&amp;nbsp;&amp;nbsp;&amp;nbsp; fakesky_sm += &lt;span class="pre"&gt;randomn(seed3,[dimsize,dimsize])&lt;/span&gt; * noise&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;Since Power is the fourier-transform squared, I'm using a power-law of
Î±=1.5 for the &amp;quot;real&amp;quot; part of the sampling. The imaginary part follows a
shallower slope to reduce the amount of power in large structures, which
didn't look quite right (but maybe I should leave both slopes the
same?). With both the same, and without the imaginary part down-scaled,
the structure appears too &amp;quot;cloudy&amp;quot; and not &amp;quot;clumpy&amp;quot; enough. But back to
that later...&lt;/p&gt;
&lt;p&gt;The peak amplitude is set by re-scaling the map. Ideally, we'd like to
see this set by a point source, since that is true in most fields.
The noise level should not be included in simulations, but should be
used to show the difference between pipeline-leftover noise and gaussian
noise on the sky. i.e., what structures disappear when you just add
noise, and what structures are removed by the pipeline.&lt;/p&gt;
&lt;p&gt;The PSF is simply to smooth out signals that are removed by the
telescope beam. We can replace this with a &amp;quot;real&amp;quot; PSF if and when we've
come up with a believable one.&lt;/p&gt;
&lt;p&gt;The noise is added after the smoothing because it should be on a pixel
scale rather than a beam scale.&lt;/p&gt;
&lt;p&gt;Here are some example realizations with different power laws:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-vCy9Lx2RjWw/Tdvs_PO1u6I/AAAAAAAAGLw/cc7cIupQu0U/s320/exp7_fakesky_sm_realP-1.0_imagP-1.0_imagS01.0_seednum02.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-qpgg2U41r6U/Tdvs_RPxARI/AAAAAAAAGL4/v5exzhhqDew/s320/exp7_fakesky_sm_realP-1.5_imagP-1.5_imagS01.0_seednum02.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-2kUqO9aE8zM/Tdvs_maHaCI/AAAAAAAAGMA/u5bDCfiVuH0/s320/exp7_fakesky_sm_realP-2.0_imagP-2.0_imagS01.0_seednum02.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category><category term="pipeline"></category></entry><entry><title>PSF modeling</title><link href="https://keflavich.github.io/blog/psf-modeling.html" rel="alternate"></link><published>2011-05-22T01:19:00-06:00</published><updated>2011-05-22T01:19:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-05-22:/blog/psf-modeling.html</id><summary type="html">&lt;p&gt;There haven't been many posts recently because I've primarily been
writing up old results into the v2 paper.
The Airy and Gaussian simulations with and without atmosphere seem to
have yielded their results. There is a ~5% loss when mapping Airy-disk
point sources. This is fine as long as it's â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;There haven't been many posts recently because I've primarily been
writing up old results into the v2 paper.
The Airy and Gaussian simulations with and without atmosphere seem to
have yielded their results. There is a ~5% loss when mapping Airy-disk
point sources. This is fine as long as it's quantified; it just means
that when calibrating we need to know whether extended sources are
similarly truncated. If all sources lose 5% in the pipeline, there will
be no net offset.
However, the Airy is not necessarily representative of the CSO's PSF.
In order to come up with a more reasonable representation of the PSF,
I've attempted to fit the *measured* PSF (from James' paper) with an
Airy disk. The first sidelobe has a lot more amplitude and is closer to
the peak than in an Airy disk. It is also asymmetric, but I'm ignoring
that for the moment.
To better represent the first sidelobe, I've fitted a modified Airy
function. The &amp;quot;modification&amp;quot; is to fit two Airy functions, one to the
peak and one to the rest. This is accomplished by setting everything
outside the first null to zero in the first function, and everything
inside the first null to zero in the second. The centers are the same,
but the amplitudes and widths are independent.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-Vd8eey7FX4Q/TdhiEsk-FhI/AAAAAAAAGLA/ekzBJL8oNoE/s320/airy_modified_comparison.png" /&gt;
&lt;p&gt;The above image shows the best fit Airy and modified Airy, both in log
scale on an identical grid. The modeled PSF was then put through the
pipeline to see it recovers the pipeline-derived PSF. The radial profile
results are below, but note that this is only one particular realization
of the simulation + pipeline.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-sxL-QjhRxUE/TdhidbXuAKI/AAAAAAAAGLI/NX9LdWqu4nM/s320/PSF_fit_plot_pipelinecompare.png" /&gt;
&lt;p&gt;Note that the model matches the first sidelobe in the &amp;quot;observed&amp;quot; PSF
pretty well, but both before and after pipeline processing, overpredicts
the second sidelobe.
There are a few &amp;quot;action items&amp;quot; remaining for this task:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Re-derive the &amp;quot;observed&amp;quot; PSF using V2. Does it vary with epoch?
Source?&lt;/li&gt;
&lt;li&gt;Find a model that better recovers the observed PSF&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Any thoughts on better models to use? Does this seem like a good idea at
all?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category><category term="pipeline"></category></entry><entry><title>Azimuthal Averages</title><link href="https://keflavich.github.io/blog/azimuthal-averages.html" rel="alternate"></link><published>2011-04-27T19:45:00-06:00</published><updated>2011-04-27T19:45:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-27:/blog/azimuthal-averages.html</id><summary type="html">&lt;p&gt;We noted in discussion yesterday that the aperture sum in the (nearly
perfectly recovered) is lower than expected even for a gaussian fit of
an airy. A Gaussian approximation to an Airy should recover 93.5% of the
flux; 6.5% of the power is in the sidelobes of an â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;We noted in discussion yesterday that the aperture sum in the (nearly
perfectly recovered) is lower than expected even for a gaussian fit of
an airy. A Gaussian approximation to an Airy should recover 93.5% of the
flux; 6.5% of the power is in the sidelobes of an Airy disk. We recover
about 86-88% of the flux in the input point-source map, or about 5-7%
short, despite matching the peak to within 2-3%. This discrepancy is
partly - but not completely - explained by a slight negative bowl
effect: the Gaussian fit has a higher total flux than the aperture sum.
Using the gaussian fit value, the recovery is about 90%. A mere 3%
missing flux is not too much of a problem - it could still be that the
gaussian is uniformly reduced by bowl effects, or perhaps that some flux
is not reincorporated into the map (at a very low level) because it is
correlated enough to be PCA-cleaned.
In the figure, the top panel is the radial profile of the ds1 data
(black), the input data (red), and their gaussian fits (see legend). The
circles on the labeled images show the FWHM of the fitted gaussian,
indicating a good fit. The apertures used for summation are NOT
displayed. The sum aperture has a radius of 90&amp;quot; (6.25 pixels) and the
&amp;quot;Noise Aperture&amp;quot; has the same area as the sum aperture.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-nvXzUBHvsmE/TbhaQabluMI/AAAAAAAAGKc/Ks16AZ70fe0/s320/exp2_amp1.0E%252B01_map20_ds1inputcompare_point.png" /&gt;
&lt;p&gt;If we redo the analysis with a smaller aperture, the recovery is better:
95% in the central 45&amp;quot;. However, now the airy ring cannot account for
any lost flux, so it still looks like there's a 5% loss intrinsic in the
pipeline.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-mqisozGUA2c/Tbhx5wk04WI/AAAAAAAAGKk/AIxGRnDMZBM/s320/exp2_amp1.0E%252B01_map20_ds1inputcompare_point.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category><category term="pipeline"></category></entry><entry><title>ds1-ds5 comparisons</title><link href="https://keflavich.github.io/blog/ds1-ds5-comparisons.html" rel="alternate"></link><published>2011-04-26T21:54:00-06:00</published><updated>2011-04-26T21:54:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-26:/blog/ds1-ds5-comparisons.html</id><summary type="html">&lt;p&gt;I'm comparing simulated ds1-ds5 to real ds1-ds5 comparison tests.
In the simulated tests, I compare the recovered map after 20 iterations
with 13 pca components subtracted to the input map. There are figures
showing this comparison for ds1 and ds5 images in addition to one
showing the comparison between ds1 â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm comparing simulated ds1-ds5 to real ds1-ds5 comparison tests.
In the simulated tests, I compare the recovered map after 20 iterations
with 13 pca components subtracted to the input map. There are figures
showing this comparison for ds1 and ds5 images in addition to one
showing the comparison between ds1 and ds5. The agreement is pretty much
as good as you could ask for.
These simulations are the most realistic run yet. They include a
simulated atmosphere that is perfectly correlated between all bolometers
excepting gaussian noise, but the relative sensitivity of the bolometers
is varied.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-xZqAo2n84iE/TbcsrsLkkaI/AAAAAAAAGIM/J_4xWIOGoCQ/s320/exp2_varyrelscale_amp1.0E-01_map20_ds1ds5compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-G7ks6aygM8w/TbcssORKmqI/AAAAAAAAGIU/aFrSrgTEhc4/s320/airy_test_ds1_reconv_arrang45_atmotest_varyrelscale_amp1.0E-01_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-MemhZbvFgYw/Tbcssv4s06I/AAAAAAAAGIc/8aSHBsnKHuU/s320/airy_test_ds5_reconv_arrang45_atmotest_amp1.0E-01_compare.png" /&gt;
&lt;p&gt;This is what a 'real' ds1-ds5 comparison looks like. The image shown is
a &amp;quot;cross-linked&amp;quot; observation of Uranus with downsampling off and on.
Note that downsampling clearly and blatantly smears the source flux.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-UvoCV4PvBcM/TbcstPbA_5I/AAAAAAAAGIk/S1cPsnCGmvc/s320/091219_o15-6_ds5_uranus_indivtest_reconv_ds1ds5compare.png" /&gt;
&lt;p&gt;The same image with &amp;quot;beam location correction&amp;quot; looks no better.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-ab27Av_tJB4/Tbcu3Jp0x6I/AAAAAAAAGIs/xUjzxFEVYXI/s320/091219_o15-6_ds5_uranus_indivtest_reconvBL_ds1ds5compare.png" /&gt;
&lt;p&gt;The problem is essentially the same with the individual scan directions:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-WwNjh1U-xu0/TbcyTyab16I/AAAAAAAAGI0/oO1fOiY4Bow/s320/091219_o16_ds1_uranus_indivtest_reconv_ds1ds5compare.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-k2U0rWMtcH8/TbcyUxfGrfI/AAAAAAAAGI8/ErLepYPyYJE/s320/091219_o15_ds1_uranus_indivtest_reconv_ds1ds5compare.png" /&gt;
&lt;p&gt;What is causing this difference?&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;higher-order corrections to the atmosphere calculation?&lt;/li&gt;
&lt;li&gt;inadequate sampling of the model?&lt;/li&gt;
&lt;li&gt;&amp;quot;pointing&amp;quot; offsets between the model and the data (note that these
are NOT pointing offsets, but they may be &amp;quot;distortion map&amp;quot; offsets)?&lt;/li&gt;
&lt;li&gt;Other?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examining the weights and scales for two individual (real) observations,
ds1 followed by ds5, is not particularly telling; there is one
additional outlier bolometer flagged out in the ds1 observation, but
there is nothing obviously wrong with that bolometer (it may have much
lower high-frequency noise than others).&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-FQGo3OPClLw/Tbc5gVqn-1I/AAAAAAAAGJE/RSmGgDcDSK0/s320/091219_o15-6_ds1_uranus_indivtest_reconv091219_o15_raw_ds1.nc_indiv13pca_weights_iter10.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-M0u4dlKj5IM/Tbc5g7PQ5YI/AAAAAAAAGJM/njdiKaENlzI/s320/091219_o15-6_ds5_uranus_indivtest_reconv091219_o15_raw_ds5.nc_indiv13pca_weights_iter10.png" /&gt;
&lt;p&gt;The simulations actually have more discrepant weights, but that doesn't
seem to cause any problems:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-pL-VkELw7g4/Tbc7OrD5d6I/AAAAAAAAGJU/zCB9wyF09_g/s320/airy_test_ds1_reconv_arrang45_atmotest_varyrelscale_amp1.0E-01_weights_iter20.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-D0GDZ-wq0ZY/Tbc7PIM2pQI/AAAAAAAAGJc/38Edm0ufAs4/s320/airy_test_ds5_reconv_arrang45_atmotest_varyrelscale_amp1.0E-01_weights_iter20.png" /&gt;
&lt;p&gt;The timestreams both have similar artifacts:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-S_3X_HkqzF4/Tbc7v7rrs4I/AAAAAAAAGJk/y0Wkwo3JYhg/s320/091219_o15-6_ds1_uranus_indivtest_reconv091219_o15_raw_ds1.nc_indiv13pcatimestream004_plots_10_bolo12.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-lg_Z50_vocc/Tbc7wZXRUlI/AAAAAAAAGJs/fcuf9u241QE/s320/091219_o15-6_ds5_uranus_indivtest_reconv091219_o15_raw_ds5.nc_indiv13pcatimestream004_plots_10_bolo12.png" /&gt;
&lt;p&gt;while the simulated versions really don't:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-cG1uUEY_N9M/Tbc-ZJtPVzI/AAAAAAAAGJ0/VGcWV0JYtxQ/s320/airy_test_ds1_reconv_arrang45_atmotest_varyrelscale_amp1.0E-01timestream011_plots_20_bolo07.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-4KA5jSCQgsY/Tbc-ZhvL_lI/AAAAAAAAGJ8/brh-nGwSses/s320/airy_test_ds5_reconv_arrang45_atmotest_varyrelscale_amp1.0E-01timestream011_plots_20_bolo07.png" /&gt;
&lt;p&gt;This is true even when the relative strength of the atmosphere is
higher:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-2MZXbARZeWo/Tbc-xHG3bOI/AAAAAAAAGKE/yEiYQ8YqqkU/s320/airy_test_ds1_reconv_arrang45_atmotest_varyrelscale_amp1.0E%252B00timestream011_plots_20_bolo07.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-Lr1QqlLNc20/Tbc-xhLCH3I/AAAAAAAAGKM/N1GKh-hZZ-Q/s320/airy_test_ds5_reconv_arrang45_atmotest_varyrelscale_amp1.0E%252B00timestream011_plots_20_bolo07.png" /&gt;
&lt;p&gt;I think the most viable candidate is the 'pointing offset' idea, which
will take a little work to simulate properly...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="downsampling"></category><category term="pipeline"></category></entry><entry><title>It is somewhat clear that sampling isn&amp;#39;t causi...</title><link href="https://keflavich.github.io/blog/it-is-somewhat-clear-that-sampling-isnt-causi.html" rel="alternate"></link><published>2011-04-22T02:43:00-06:00</published><updated>2011-04-22T02:43:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-22:/blog/it-is-somewhat-clear-that-sampling-isnt-causi.html</id><content type="html">&lt;p&gt;It is somewhat clear that sampling isn't causing huge issues in the
sense I was imagining... the highest pixel ranges from 0.98 to 1.04
depending on how the PSF is made anyway, so 5% errors are totally
unavoidable.&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>Weighting and Scaling</title><link href="https://keflavich.github.io/blog/weighting-and-scaling.html" rel="alternate"></link><published>2011-04-19T23:08:00-06:00</published><updated>2011-04-19T23:08:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-19:/blog/weighting-and-scaling.html</id><content type="html">&lt;p&gt;The &amp;quot;simple&amp;quot; relative sensitivity calibration was causing serious
problems.
The assumed model for a &amp;quot;gain&amp;quot; $G$, timestream $S$, and reference
timestream $R$ is:
$S = G R$
Naively, one would assume that something like
$G = median(S/R)$
would work. However, it doesn't. The distribution of $G$ values looks
like:&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Sampling Causes Problems: Rd 2</title><link href="https://keflavich.github.io/blog/sampling-causes-problems-rd-2.html" rel="alternate"></link><published>2011-04-19T17:39:00-06:00</published><updated>2011-04-19T17:39:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-19:/blog/sampling-causes-problems-rd-2.html</id><summary type="html">&lt;p&gt;Proof that a well-sampled timestream / gaussian is recovered better than
a poorly sampled one:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-PVt1suBQt3s/Ta3EQqypzAI/AAAAAAAAGG4/ap-3_SKjigI/s320/airy_test_superres_ds1_smallpix_sn100timestream012_plots_16_bolo12.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-HMr4DXKBVMY/Ta3GE49GmcI/AAAAAAAAGHA/ULLRUq_IWn8/s320/airy_test_superres_ds1_sn100timestream012_plots_20_bolo12.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-ujL_h0j-Gms/Ta3GWwcEttI/AAAAAAAAGHI/4uVLXXXhtqc/s320/airy_test_superres_ds1_smallpix_sn100_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-r98h73qcMKY/Ta3GXBKAT3I/AAAAAAAAGHQ/k3y8j427TC0/s320/airy_test_superres_ds1_sn100_compare.png" /&gt;
&lt;p&gt;These aren't really the most convincing, since the flux loss is only
1-8% depending on how you count. The atmosphere-included ones have
larger flux loss, which is important to understand... WHY does the added
noise INCREASE â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Proof that a well-sampled timestream / gaussian is recovered better than
a poorly sampled one:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-PVt1suBQt3s/Ta3EQqypzAI/AAAAAAAAGG4/ap-3_SKjigI/s320/airy_test_superres_ds1_smallpix_sn100timestream012_plots_16_bolo12.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-HMr4DXKBVMY/Ta3GE49GmcI/AAAAAAAAGHA/ULLRUq_IWn8/s320/airy_test_superres_ds1_sn100timestream012_plots_20_bolo12.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-ujL_h0j-Gms/Ta3GWwcEttI/AAAAAAAAGHI/4uVLXXXhtqc/s320/airy_test_superres_ds1_smallpix_sn100_compare.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-r98h73qcMKY/Ta3GXBKAT3I/AAAAAAAAGHQ/k3y8j427TC0/s320/airy_test_superres_ds1_sn100_compare.png" /&gt;
&lt;p&gt;These aren't really the most convincing, since the flux loss is only
1-8% depending on how you count. The atmosphere-included ones have
larger flux loss, which is important to understand... WHY does the added
noise INCREASE the flux loss?
Ugh, unfortunately, there is a perfect counter-example. The first image
shows a timestream in which the input map is sampled by 7.2&amp;quot; pixels,
which is just shy of nyquist sampling the 1-sigma width of the gaussian
(but is fine for the FWHM of the gaussian). The second shows 3.6&amp;quot;
sampling of the same. No improvement. The third, very surprisingly,
shows significant improvement - but this was an experiment in which the
relative scales were allowed to vary.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-NIwHLJT2SOw/Ta3IAGQA4HI/AAAAAAAAGHY/N3Oju7RHhRE/s320/airy_test_ds1_reconv_arrang45_atmotest_amp1.0E-01timestream011_plots_20_bolo07.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-Qo8-kSCFMCc/Ta3IATO7P1I/AAAAAAAAGHg/Jx9ufNhabiE/s320/airy_test_ds1_reconv_arrang45_atmotest_smallpix_amp1.0E-01timestream011_plots_20_bolo07.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-6PlqmOsDRFY/Ta3IA00cfBI/AAAAAAAAGHo/t5b2jddw5Lw/s320/airy_test_ds1_reconv_arrang45_atmotest_varyrelscale_amp1.0E-01timestream011_plots_20_bolo07.png" /&gt;
&lt;p&gt;The first two each had one high-weight bolometer rejected, the last had
12 high-weight bolos rejected. So that's problably the problem....&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="downsampling"></category><category term="simulation"></category><category term="pipeline"></category></entry><entry><title>Sampling causes problems</title><link href="https://keflavich.github.io/blog/sampling-causes-problems.html" rel="alternate"></link><published>2011-04-18T23:39:00-06:00</published><updated>2011-04-18T23:39:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-18:/blog/sampling-causes-problems.html</id><summary type="html">&lt;p&gt;One of the simplest experiments that can be run is a point-source
observed in point-scan mode, i.e. with smaller step-sizes. I've done
this for an Airy disk with noise added in the image plan but not
atmosphere (some noise is necessary to avoid bizarre artifacts with
weighting when you â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of the simplest experiments that can be run is a point-source
observed in point-scan mode, i.e. with smaller step-sizes. I've done
this for an Airy disk with noise added in the image plan but not
atmosphere (some noise is necessary to avoid bizarre artifacts with
weighting when you have truly zero signal and zero noise). At a S/N of
500, the noise is pretty minimal, though.
It turns out for the 'noiseless' images, the PCA cleaning is the
issue... curiously, it varies significantly with iteration. Is it worth
trying to debug the PCA cleaning for noiseless timestreams? I mean...
they really shouldn't have any correlated information anyway.
There is still an outstanding issue where one bolometer gets scaled to
be higher than the rest without any apparent reason for doing so.
It is also clear that we do not nyquist-sample the pixels with the
timestream. However, that doesn't explain a deficiency observed in the
ds1 images. Also note that the sidelobes are not picked up at this S/N,
but that's not too surprising.
And here is the explanation: The peak is missed by about 10% because of
finite sampling? Somehow the sampled gaussian nearly uniformly
underestimates the gaussian... I think this violates theory a bit.....&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-L2CMkehyV2g/TazJvpj2jjI/AAAAAAAAGGg/_BM0_GgC_x4/s320/airy_test_ds1_reconv_arrang45_atmotest_amp1.0E-01timestream011_plots_20_bolo07.png" /&gt;
&lt;p&gt;Here's the problem shown again:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-vvY-1uleKmk/TazKE4Osm_I/AAAAAAAAGGo/n6Nadxi8UM4/s320/airy_test_ds1_reconv_arrang45_atmotest_amp1.0E-01_compare.png" /&gt;
&lt;p&gt;This is a comparison between the input image and a ds1-sampled image
with perfectly correlated atmospheric noise. So there is something in
the pipeline that is preventing the peaks from achieving the necessary
heights.... I wonder if resampling the deconvolved image onto a
higher-resolution grid, then downsampling afterwards, would fix this?
Also note that the flux loss increases from 7% to 20% from ds1 to ds5:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-hHQBTMME8Ow/TazKuf0gkuI/AAAAAAAAGGw/uQdJw4kc2U8/s320/airy_test_ds5_reconv_arrang45_atmotest_amp1.0E-01_compare.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="downsampling"></category><category term="pipeline"></category></entry><entry><title>Recovery for an Airy</title><link href="https://keflavich.github.io/blog/recovery-for-an-airy.html" rel="alternate"></link><published>2011-04-12T01:38:00-06:00</published><updated>2011-04-12T01:38:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-12:/blog/recovery-for-an-airy.html</id><content type="html">&lt;img alt="" src="http://3.bp.blogspot.com/-Qj43vct-3Hw/TaOsoVQAeTI/AAAAAAAAGGY/Ju9HpmnrvCc/s320/airy_sn100.png" /&gt;
&lt;p&gt;The recovery for an Airy function is not particularly good, since the
pipeline assumes a purely positive response....&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Definitive Testing</title><link href="https://keflavich.github.io/blog/definitive-testing.html" rel="alternate"></link><published>2011-04-11T19:09:00-06:00</published><updated>2011-04-11T19:09:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-11:/blog/definitive-testing.html</id><summary type="html">&lt;p&gt;It is now possible to make artificial timestreams!
First round of tests:
For pointing maps with ~21 scans in 15&amp;quot; steps, array angle is
approximately negligible.
deconv does NOT recover point sources, but reconv does (perfectly)
The algorithm starts to decay and produce weird ringey residuals at a
S/N â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;It is now possible to make artificial timestreams!
First round of tests:
For pointing maps with ~21 scans in 15&amp;quot; steps, array angle is
approximately negligible.
deconv does NOT recover point sources, but reconv does (perfectly)
The algorithm starts to decay and produce weird ringey residuals at a
S/N ~300. The residuals are only at the 1% level out to S/N ~1000.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="testing"></category><category term="pipeline"></category></entry><entry><title>Tests running</title><link href="https://keflavich.github.io/blog/tests-running.html" rel="alternate"></link><published>2011-04-08T17:48:00-06:00</published><updated>2011-04-08T17:48:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-08:/blog/tests-running.html</id><summary type="html">&lt;ul class="simple"&gt;
&lt;li&gt;Re-doing December 2010 calibration (remember to check &amp;amp; compare AFGL
4029)&lt;/li&gt;
&lt;li&gt;Mapping L351 with deconv, reconv, nodeconv&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ARGH something is wrong with l351 pointing! Is the pointing model
broken? What HAPPENED?!
OK, on to 4/8/2011 stuff:
I've done more work on the Memo from a few weeks ago, and â€¦&lt;/p&gt;</summary><content type="html">&lt;ul class="simple"&gt;
&lt;li&gt;Re-doing December 2010 calibration (remember to check &amp;amp; compare AFGL
4029)&lt;/li&gt;
&lt;li&gt;Mapping L351 with deconv, reconv, nodeconv&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ARGH something is wrong with l351 pointing! Is the pointing model
broken? What HAPPENED?!
OK, on to 4/8/2011 stuff:
I've done more work on the Memo from a few weeks ago, and now have a
concrete recommendation that we do some more observing in 2011. Why I
torture myself so, I do not know....
Examination of the 2009 tests shows that reconv is by far the superior
approach for pointing observations as previously noted. Since reconv
doesn't look bad, but definitely not best, for science, it might be the
compromise we have to make. nodeconv completely fails for ds5 data, but
the ds5 data in general are abominable. They drop by 15-20% compared to
ds1 for Mars. The problem with nodeconv appears to be extremely high
noise maps.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Examining deconvolution strategies</title><link href="https://keflavich.github.io/blog/examining-deconvolution-strategies.html" rel="alternate"></link><published>2011-04-07T22:05:00-06:00</published><updated>2011-04-07T22:05:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-07:/blog/examining-deconvolution-strategies.html</id><summary type="html">&lt;p&gt;This is a direct continuation of what I did yesterday (but only posted
today because I forgot to click post).
No-deconvolution doesn't work, at least not reliably. It recovers
structures that are too large to be believable. Perhaps a higher
threshold should be required to include signal in the model â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a direct continuation of what I did yesterday (but only posted
today because I forgot to click post).
No-deconvolution doesn't work, at least not reliably. It recovers
structures that are too large to be believable. Perhaps a higher
threshold should be required to include signal in the model? The noise
actually looks too high anyway. Also, the flagging doesn't look great.
Grr.
The agreement between the three is somewhat better, down to a 50%
increase of reconv over deconv:
[deconv, nodeconv, reconv]:
BMAJ: 0.00916667 BMIN: 0.00916667 PPBEAM: 23.8028 SUM/PPBEAM: 8.19765
Sum: 195.127 Mean: 1.04346 Median: 0.751545 RMS: 0.78342 NPIX: 187
BMAJ: 0.00916667 BMIN: 0.00916667 PPBEAM: 23.8028 SUM/PPBEAM: 10.1592
Sum: 241.816 Mean: 1.29314 Median: 1.04031 RMS: 0.778854 NPIX: 187
BMAJ: 0.00916667 BMIN: 0.00916667 PPBEAM: 23.8028 SUM/PPBEAM: 12.1694
Sum: 289.664 Mean: 1.54901 Median: 1.31107 RMS: 0.808915 NPIX: 187
But this time there is less indication of negative residuals than
previously.
I was very confused by negatives being included in the model for
nodeconv, then realized it's because of the grow_mask option.
sncut = 1 is now default for nodeconv. I think it makes sense.
(sncut = 1 drops the flux by &amp;lt;10%:
BMAJ: 0.00916667 BMIN: 0.00916667 PPBEAM: 23.8028 SUM/PPBEAM: 9.31507
Sum: 221.725 Mean: 1.18569 Median: 0.915137 RMS: 0.783316 NPIX: 187)
While reconv has produced reasonable results in some cases, a close look
at the maps shows that deconv ~ nodeconv &amp;lt;&amp;lt; reconv. There is something
wrong with reconv. It spreads out and increases the flux artificially.
So.... why did it work so damn well for point sources?
The new weighting scheme seems to flag a dangerous number of bolos as
'high weight'. It drops after iteration #1, but not all the way.
Need to remember to reprocess all December 2009 data with more flagged
bolos&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Deconvolve and Epochs</title><link href="https://keflavich.github.io/blog/deconvolve-and-epochs.html" rel="alternate"></link><published>2011-04-05T18:12:00-06:00</published><updated>2011-04-05T18:12:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-04-05:/blog/deconvolve-and-epochs.html</id><summary type="html">&lt;p&gt;I've spent a large portion of the last week working on the deconvolver.
I found &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html"&gt;previously&lt;/a&gt; that a reconvolved map does a better job of
restoring flux than the straight-up deconvolved map for point sources /
pointing observations.
However, the same update broke the regular mapping modes, leading to
horrible instability â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've spent a large portion of the last week working on the deconvolver.
I found &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html"&gt;previously&lt;/a&gt; that a reconvolved map does a better job of
restoring flux than the straight-up deconvolved map for point sources /
pointing observations.
However, the same update broke the regular mapping modes, leading to
horrible instability in the mapping routines for large maps such as W5.
Curiously, it seems that the aspect that breaks is the weighting;
somehow the noise drops precipitously in certain bolometers, leading to
extremely high weights. Perhaps they somehow dominate the PCA
subtraction and therefore have all their noise removed?
Either way, there are a few large-scale changes that need to be made:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Since Scaling and Weighting are now done on a whole-timestream basis,
we should only map single epochs at once and coadd them after the
fact. This approach will also help relieve RAM strain. Since it
appears that individual observations are now reasonably convergent
with the proper treatment of NANs in the deconvolution scheme, it
should be possible to take any individual map and coadd it in a
reasonable way.&lt;/li&gt;
&lt;li&gt;Bolometers with bad weights need to be thrown out. Alternatively, and
more appropriately, I need to discover WHY their weights are going
bad.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We also need to explore different weighting schemes.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;1/Variance over whole timestream (current default)&lt;/li&gt;
&lt;li&gt;1/Variance on a per-scan basis (previous default) [based on PSDs]&lt;/li&gt;
&lt;li&gt;Minimum Chi&lt;sup&gt;2&lt;/sup&gt; with Astrophysical Model (??)&lt;/li&gt;
&lt;li&gt;Min Chi&lt;sup&gt;2&lt;/sup&gt; on a per-scan basis?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Because of the extensive testing this will require, it is really
becoming essential that we develop an arbitrary map creation &amp;amp; testing
routine.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="distortion mapping"></category><category term="weighting"></category><category term="pipeline"></category></entry><entry><title>Weird problem</title><link href="https://keflavich.github.io/blog/weird-problem.html" rel="alternate"></link><published>2011-03-31T02:25:00-06:00</published><updated>2011-03-31T02:25:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-03-31:/blog/weird-problem.html</id><summary type="html">&lt;p&gt;I'm remapping everything, and there's a really strange situation in
ic1396... only one field has a source that doesn't have rotation
problems, every other observation is clearly improperly rotated. The
weird thing is that it's NOT the one you'd expect from the information
below:
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;readcol,'/Volumes/disk2/sliced/infiles/ic1396 â€¦&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm remapping everything, and there's a really strange situation in
ic1396... only one field has a source that doesn't have rotation
problems, every other observation is clearly improperly rotated. The
weird thing is that it's NOT the one you'd expect from the information
below:
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;readcol,'/Volumes/disk2/sliced/infiles/ic1396_infile.txt',filelist,format='A'for&lt;/span&gt; i=0,6 do begin &amp;amp; &lt;span class="pre"&gt;ncdf_varget_scale,filelist[i],'array_params',ap&lt;/span&gt; &amp;amp; &lt;span class="pre"&gt;print,filelist[i],ap&lt;/span&gt; &amp;amp; endfor/Volumes/disk2/sliced/ic1396/070911_o19_raw_ds5.nc&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 7.70000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 31.2000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 70.7000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000/Volumes/disk2/sliced/ic1396/070912_o26_raw_ds5.nc&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 7.70000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 31.2000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 84.0000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000/Volumes/disk2/sliced/ic1396_d/070913_o19_raw_ds5.nc&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 7.70000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 31.2000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 84.0000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000/Volumes/disk2/sliced/ic1396_l/070913_o17_raw_ds5.nc&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 7.70000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 31.2000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 84.0000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000/Volumes/disk2/sliced/ic1396_r/070913_o18_raw_ds5.nc&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 7.70000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 31.2000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 84.0000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000/Volumes/disk2/sliced/ic1396_u/070913_o20_raw_ds5.nc&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 7.70000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 31.2000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 84.0000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 0.00000&lt;/tt&gt;
One ofthese things is not like the others... but it's
070913_o18_raw_ds5.nc, not
/Volumes/disk2/sliced/ic1396/070911_o19_raw_ds5.nc&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="errors"></category></entry><entry><title>Progress, but still ds1-ds5 issues</title><link href="https://keflavich.github.io/blog/progress-but-still-ds1-ds5-issues.html" rel="alternate"></link><published>2011-03-30T02:47:00-06:00</published><updated>2011-03-30T02:47:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-03-30:/blog/progress-but-still-ds1-ds5-issues.html</id><summary type="html">&lt;p&gt;ds1 and ds5 agree pretty well with the recent upgrades to delining and
deconvolution. However, there are still counterexamples, e.g.
101208_o13, in which ds5 &amp;lt; ds1:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-fIJHF_x5mBI/TZI0cryJfbI/AAAAAAAAGDI/GsNfLRGNZAk/s200/101208_o13_raw_ds1.nc_indiv13pca.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-QRhiz8W9RDc/TZI0dGUR4UI/AAAAAAAAGDQ/WC8eLQd6_Z0/s200/101208_o13_raw_ds5.nc_indiv13pca.png" /&gt;
&lt;p&gt;The 'fitted' values agree better than the 'measured' values now that
NANs are treated properly.
Spent a few hours today trying to figure â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;ds1 and ds5 agree pretty well with the recent upgrades to delining and
deconvolution. However, there are still counterexamples, e.g.
101208_o13, in which ds5 &amp;lt; ds1:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-fIJHF_x5mBI/TZI0cryJfbI/AAAAAAAAGDI/GsNfLRGNZAk/s200/101208_o13_raw_ds1.nc_indiv13pca.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-QRhiz8W9RDc/TZI0dGUR4UI/AAAAAAAAGDQ/WC8eLQd6_Z0/s200/101208_o13_raw_ds5.nc_indiv13pca.png" /&gt;
&lt;p&gt;The 'fitted' values agree better than the 'measured' values now that
NANs are treated properly.
Spent a few hours today trying to figure out if weighting can explain
the difference between ds1 and ds5; it appears to make up for most of it
so I'm doing some more experiments. Why is there so much parameter
space? Why can't weighting just work? It doesn't....
also wasted a few hours trying to write a python drizzling algorithm,
which unfortunately is impossible so I had to resort to an inefficient
for loop.
Finally got some minor results. It really looks like there is a trend
pushing up the recovered flux (i.e. higher volts/Jy) for ds5 over ds1.
There is a discrepancy between map types for ds1 but not for ds5, which
is actually backwards from what I would have expected, since ds1 will
get better-sampled maps.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-ARaSL7ZdDmc/TZKRcE01DnI/AAAAAAAAGDY/YMZRpRo53Hw/s320/uranus_dcfluxes_dec2010_nomask_ds1_13pca_fits_map10.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-pWtggp0vSP4/TZKRcwZ_SrI/AAAAAAAAGDg/IqVHQSprkL8/s320/uranus_dcfluxes_dec2010_nomask_ds5_13pca_fits_map10.png" /&gt;
&lt;p&gt;Luckily, the difference between peak fitting and &amp;quot;measuring&amp;quot; results in
very small (insignificant) changes to the calibration curve (recall
fitting is direct gaussian fitting; 'measuring' is using the
gaussian-fit width and total flux in an ellipse to infer a peak assuming
a point source):&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-E-FDTTj-4Ik/TZKVyUA8zBI/AAAAAAAAGDo/9NGubgLWBvo/s320/uranus_dcfluxes_dec2010_nomask_ds5_13pca_fits_map10.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-GdyxFnmwQ7g/TZKVykSg57I/AAAAAAAAGDw/PPVXtfAxW0s/s320/uranus_dcfluxes_dec2010_nomask_ds5_13pca_map10.png" /&gt;
&lt;p&gt;Since this work has all been done for the 'bootstrapping' observations
that are supposed to tell us if different map sizes are compatible, I
have included the map sizes in the diagrams now. However, to really
understand the ds1/ds5 difference, there are much better data sets,
which I'm now reprocessing using the new and improved methods.
(the Whole BGPS is also processing with the new methods in the
background, though since the methods are being updated live there may be
more changes and it will have to be re-run.... initial looks at W5 are
BAD but L030 is GOOD (bordering on amazing))&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="downsampling"></category><category term="calibration"></category><category term="pipeline"></category></entry><entry><title>Careful comparison of ds1 and ds5</title><link href="https://keflavich.github.io/blog/careful-comparison-of-ds1-and-ds5.html" rel="alternate"></link><published>2011-03-29T15:23:00-06:00</published><updated>2011-03-29T15:23:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-03-29:/blog/careful-comparison-of-ds1-and-ds5.html</id><summary type="html">&lt;p&gt;I looked very closely at the timestream and maps of 101208_o11 and had
a pretty hard time figuring out why the data were different, but it
looked like the data really did differ on a point-by-point basis
(according to pyflagger). The only conclusion I was able to draw is â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I looked very closely at the timestream and maps of 101208_o11 and had
a pretty hard time figuring out why the data were different, but it
looked like the data really did differ on a point-by-point basis
(according to pyflagger). The only conclusion I was able to draw is that
the scaling must be off. I realized that the scaling was being done
before delining. I moved scaling from readall_pc to premap, and it
brought at least this one source into agreement. Time to run ds1-ds5
comparisons again!
(this means that ds1 data MUST have deline run on it, but ds5 data
doesn't really need it)
Here are examples of ds1 and ds5 timestreams, with and without scaling,
and ds1 with and without delining:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-KR_NYG31_O0/TZECtBAgqFI/AAAAAAAAGCg/1jC9Ys2r9Iw/s200/101208_o11_ds5_uranus_indivtesttimestream011_plots_20_bolo02.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-HbK-hAXjSDs/TZECtUNe8AI/AAAAAAAAGCo/i4fsH12Iw8Y/s200/101208_o11_ds1_uranus_indivtest_delinetimestream011_plots_20_bolo02.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-edXLnDrrt5o/TZECt0No8oI/AAAAAAAAGCw/QjHg1ScBHG0/s200/101208_o11_ds1_uranus_indivtesttimestream011_plots_20_bolo02.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-4NIxFxEQ1jU/TZECuDJ1fVI/AAAAAAAAGC4/tGE5tDH_168/s200/101208_o11_ds1_uranus_indivtest_deline_noscaleacbtimestream011_plots_20_bolo02.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/-DfIepZXXCFc/TZECuhm8lwI/AAAAAAAAGDA/Awp60ZuPGps/s200/101208_o11_ds5_uranus_indivtest_noscaleacbtimestream011_plots_20_bolo02.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category><category term="pipeline"></category></entry><entry><title>Trying to bootstrap</title><link href="https://keflavich.github.io/blog/trying-to-bootstrap.html" rel="alternate"></link><published>2011-03-28T02:01:00-06:00</published><updated>2011-03-28T02:01:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-03-28:/blog/trying-to-bootstrap.html</id><summary type="html">&lt;p&gt;I've concluded, based on previous posts
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/02/downsampling-why-is-dec-2010-different.html"&gt;http://bolocam.blogspot.com/2011/02/downsampling-why-is-dec-2010-different.html&lt;/a&gt;,
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/03/revisiting-calibration-yet-again.html"&gt;http://bolocam.blogspot.com/2011/03/revisiting-calibration-yet-again.html&lt;/a&gt;,
and
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html"&gt;http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html&lt;/a&gt;,
that ds5 is a problem primarily for undersampled images, i.e. those
taken in the normal mapping mode. This â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've concluded, based on previous posts
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/02/downsampling-why-is-dec-2010-different.html"&gt;http://bolocam.blogspot.com/2011/02/downsampling-why-is-dec-2010-different.html&lt;/a&gt;,
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/03/revisiting-calibration-yet-again.html"&gt;http://bolocam.blogspot.com/2011/03/revisiting-calibration-yet-again.html&lt;/a&gt;,
and
&lt;a class="reference external" href="http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html"&gt;http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html&lt;/a&gt;,
that ds5 is a problem primarily for undersampled images, i.e. those
taken in the normal mapping mode. This makes bootstrapping a bit tricky.&lt;/p&gt;
&lt;p&gt;There are two options:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Map Uranus and AFGL 4029 both in Volts and figure out what flux density
AFGL 4029 must have to lie on that curve&lt;/li&gt;
&lt;li&gt;Map Uranus and compute a calibration curve, apply that calibration curve
to AFGL 4029, and then compare derived flux densities.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Both have the major problem that the individual AFGL 4029 maps will
forcibly be undersampled if I use ds5 data (which is normally OK,
according to the first paragraph). In the second case, it is possible to
co-add the images and get around the under-sampling issue, while in the
first case it is not because of the dependence on total loading
(MEANDC).&lt;/p&gt;
&lt;p&gt;The real problem is that the whole goal of these observations was to
compare the different observing methods and see if they agree (1x1, 3x1,
pointing, etc.) since the pointing-style observations were used to
calibrate the others. But if the 1x1s are just straight-up unreliable,
how can we do the comparison? I think the co-added AFGL 4029 is the only
option, but then how do I test if it's correct? It would be really nice
to have AFGL 4029 observed with both scan types...&lt;/p&gt;
&lt;p&gt;Alright, onto the data. After last week's fix of the bad bolos, I really
hope ds1 and ds5 agree. However, first glance at the cal curves says
they don't. ds1 and ds2 agree, but ds5 is different.&lt;/p&gt;
&lt;p&gt;After checking them out with
&lt;tt class="docutils literal"&gt;ds9 &lt;span class="pre"&gt;*ds[15]*13pca*_map10.fits&lt;/span&gt; &lt;span class="pre"&gt;-scale&lt;/span&gt; limits &lt;span class="pre"&gt;-1&lt;/span&gt; 1000 &lt;span class="pre"&gt;-log&lt;/span&gt; &lt;span class="pre"&gt;-cmap&lt;/span&gt; hsv &lt;span class="pre"&gt;-match&lt;/span&gt; colorbars &lt;span class="pre"&gt;-match&lt;/span&gt; scales &lt;span class="pre"&gt;-match&lt;/span&gt; frames wcs &amp;amp;&lt;/tt&gt;,
it appears that the _mask_ data is all... wrong, somehow. That's OK, I
want to discard the mask data anyway, so I'm happy to NOT spend time
debugging it.&lt;/p&gt;
&lt;p&gt;Even after careful examination showing that the fits look good - and
noting that the fluxes look pretty much the same - the calibration
curves still look rather different. Unfortunately I had to spend 3 hours
debugging IDL plotting commands; I want to show the fits each time and
save them as postscripts. What does &amp;quot;xyouts&amp;quot; with &amp;quot;/device,/normal&amp;quot; do?
I thought that should plot x,y text at the coordinates specified in the
plot window... but no, that is JUST /normalize.&lt;/p&gt;
&lt;p&gt;Anyway, realized that centroid_map treated NANs as zero. Added ERR
keyword (with a reasonable estimate of the error) in centroid_map to
ignore NANs. It looks like improper treatment of NANs is responsible for
a lot of the scatter seen in the calibration plots.&lt;/p&gt;
&lt;p&gt;There is a substantial difference between the &amp;quot;fitted&amp;quot; peak and the
&amp;quot;measured&amp;quot; peak (the latter computed by taking the sum of the pixels
divided by the area of the fitted gaussian). It looks like the
&amp;quot;measured&amp;quot; version is more robust, at first glance. However,
unfortunately, for 101208_o11, the difference between ds1 and ds5
exists in both quantities. I will have to examine timestreams now...
ARGH.&lt;/p&gt;
&lt;p&gt;Well, the timestreams show... that indeed the model is lower in ds1, but
not why. The &amp;quot;remainder&amp;quot; (new_astro; the stuff that never gets
incorporated into the model but DOES get incorporated into the map)
appears to be the same in both. Similarly, there is little to no flux in
the PCA atmosphere, so it's not simply being cleaned out. Where is the
flux going or coming from?&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-6lqGwWn650Q/TY_rgZKA9QI/AAAAAAAAGCI/Iq9O5mnmhl8/s320/101208_o11_ds1_uranus_indivtest_delinetimestream011_plots_20_bolo02.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-7uBbEU1tAqM/TY_rgg6Jq9I/AAAAAAAAGCQ/iaGhOSb6gtQ/s320/101208_o11_ds5_uranus_indivtesttimestream011_plots_20_bolo02.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-YKdZcNOjm7Q/TY_rg6tcvhI/AAAAAAAAGCY/fr4l8j-v4xI/s320/101208_o11_ds1_uranus_indivtesttimestream011_plots_20_bolo02.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="downsampling"></category><category term="discrepancy"></category><category term="calibration"></category><category term="pipeline"></category></entry><entry><title>A workaround for individual maps?</title><link href="https://keflavich.github.io/blog/a-workaround-for-individual-maps.html" rel="alternate"></link><published>2011-03-24T00:33:00-06:00</published><updated>2011-03-24T00:33:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-03-24:/blog/a-workaround-for-individual-maps.html</id><summary type="html">&lt;p&gt;I closely examined the timestreams of 101208_ob7 as I said I would
yesterday. Unfortunately, all I can do is describe the symptoms: the
first deconvolution model looks good, though it isn't quite as wide as
the true source (this should be OK; it is an iterative method, after
all â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I closely examined the timestreams of 101208_ob7 as I said I would
yesterday. Unfortunately, all I can do is describe the symptoms: the
first deconvolution model looks good, though it isn't quite as wide as
the true source (this should be OK; it is an iterative method, after
all). In the second iteration, though, the deconvolution model is even
smaller and lower amplitude... and it goes on like that.&lt;/p&gt;
&lt;p&gt;Not deconvolving results in a healthy-looking clean map - pretty much
what you expect and want to see.&lt;/p&gt;
&lt;p&gt;This implies that somehow removing an incomplete deconvolved model leads
to more of the source being included in the 'atmosphere' than would have
been included with no model subtraction at all. I'm not sure how this is
possible. In fact... I'm really quite sure that it is not.
The workaround is to only add positive changes to the model. This should
'definitely work' but may be non-convergent and assumes that the model
never has anything wrong with it at any iteration. I have demonstrated
that this works nicely for the two Uranus observations I tested on, but
now I have to run the gamut of tests.... the first (very obvious)
problem is that the background is now positive, which is dead wrong.
This workaround is not viable.
Alright, so what next? I've described the symptoms and that I think they
can't occur...
A closer look shows that new_astro is not being incorporated into
astro_model at the second iteration. Why?
AHA! Pyflagger + find_all_points reveals the problem!&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Map value: 16.939728   Weighted average: 17.476323   Unweighted Average: 524.573136
scan,bolo,time:       mapped       astro       flags      weight       scale
3,  22,  12:     8.380408   13.561113    0.000000    0.025132    1.000000
4, 124,  23:   822.005327   13.561113    0.000000    0.000038    1.118012
4,  21,  38:   719.408983   13.561113    0.000000    0.000037    0.946721
5,  20,   7:     4.470616   13.561113    0.000000    0.013303    1.400000
5, 119,  23:   882.508303   13.561113    0.000000    0.000033    0.926887
5, 100,  35:   327.007750   13.561113    0.000000    0.000074    1.184397
5, 106,  38:   162.562098   13.561113    0.000000    0.000704    0.970000
6, 116,  27:   779.075640   13.561113    0.000000    0.000033    0.891768
8, 112,   3:   235.557390   13.561113    0.000000    0.000147    0.947130
9,   3,  14:   966.721773   13.561113    0.000000    0.000032    1.166292
9, 109,  41:   139.753656   13.561113    0.000000    0.000753    1.075269
10, 104,   8:   641.121935   13.561113    0.000000    0.000050    0.927827
10, 105,  24:     4.323228   13.561113    0.000000    0.032759    0.019022
10,  32,  36:   847.646990   13.561113    0.000000    0.000034    1.099406
11,  36,   9:   834.757586   13.561113    0.000000    0.000038    1.184751
11,  76,  37:   566.851891   13.561113    0.000000    0.000040    1.111000
12,  77,  13:   834.603090   13.561113    0.000000    0.000034    1.128464
12,  44,  44:   335.465654   13.561113    0.000000    0.000195    2.165775
13,  26,  17:    50.423143   13.561113    0.000000    0.004826    0.829932
13,  75,  29:   724.884676   13.561113    0.000000    0.000042    0.923077
14,  49,  21:   797.618990   13.561113    0.000000    0.000038    1.091918
14,  29,  33:   743.856012   13.561113    0.000000    0.000035    1.050360
15,  33,  13:   660.670099   13.561113    0.000000    0.000031    0.832180
15,  53,  25:   604.174286   13.561113    0.000000    0.000047    0.889922
15,  88,  40:     4.626476   13.561113    0.000000    0.008241    0.191489
17,  64,  20:   778.950533   13.561113    0.000000    0.000037    1.233108
18,  68,  30:   686.048136   13.561113    0.000000    0.000040    1.387283
&lt;/pre&gt;
&lt;p&gt;Note that the lowest points have the highest weights. They DEFINITELY
shouldn't. What's wrong with them?
Apparently they have NO sensitivity to the sky! What?! There were a
bunch of bad bolos in Dec2010 that weren't flagged out... I wonder if
that problem persists to other epochs. Still, why does it only affect
pointing observations? Looking at the power spectra... the
large-timescale stuff becomes less dominant when scans are longer, but
the noisy spectra are still clearly noise-only. How odd.
Dropped to 112 good bolos from 134. That is much more believable. Have
to go back and fix Dec09 data too...
Even after fixing the bad bolos, the model drops with iteration number.
Why why why?
Well, looking at deconv_map, I've always returned the truly deconvolved
version, not the reconvolved... maybe the reconvolved really is better?
Again, this will have to be extensively tested, but it certainly gets
rid of the obvious/dominant error that the model kept dropping off.
However, FINALLY, based on how ridiculously good the reconv-deconvolved
map looks, I think I'm ready to do the extensive pipeline tests. So,
10dec_caltest has been started up with all of the new bolo_params
applied and the changes in place to deconv_map... let's see what
happens.&lt;/p&gt;
&lt;p&gt;After that runs, I'll have to re-run the fit_and_plot routines&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="iterating"></category><category term="mapping"></category><category term="flagging"></category><category term="pipeline"></category></entry><entry><title>Revisiting calibration yet again</title><link href="https://keflavich.github.io/blog/revisiting-calibration-yet-again.html" rel="alternate"></link><published>2011-03-23T00:22:00-06:00</published><updated>2011-03-23T00:22:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-03-23:/blog/revisiting-calibration-yet-again.html</id><summary type="html">&lt;p&gt;The recent hiatus for paper revisions has, unfortunately, come to an
end.
Re-examining my work, I did quite a lot but encountered many dead-ends.
First, we would very much like to use an *identical* reduction process
on both the calibration data and the science data. That way, we could
feel â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The recent hiatus for paper revisions has, unfortunately, come to an
end.
Re-examining my work, I did quite a lot but encountered many dead-ends.
First, we would very much like to use an *identical* reduction process
on both the calibration data and the science data. That way, we could
feel very confident that the reduction process isn't introducing any
weird artifacts.
Unfortunately, I discovered early on that using ds5 data, 13 pca
components, and n&amp;gt;1 iterations resulted in strange shape and flux
conservation failures. These errors do NOT occur in co-added maps; they
are unique to single-observation scans (though I don't recollect whether
2 scans is enough or if you need more).
I spent many hours banging my head against this problem and have never
gotten a satisfactory solution. But perhaps it's time to approach it
again. The map00 images look MUCH rounder and generally better than the
map10 images.
So, the problem I need to examine is the iterative process. Why does it
fail for single images? Is it something about the noise properties?
model00 looks fine... what gets put into the timestream? Examining
timestreams is a terrible and horrendous process... but what else can I
do?
The next step will be to examine the timestreams of a particular
observation. I think a good choice is 101208_ob7; the next observation,
101208_ob8 was a large-area map and it looks fine (i.e., it improves
with iteration). So I can start looking at the effects of polysub,
iteration, etc. on this particular source.
Of course, the stupid trick with the pipeline - every time - is that
&amp;quot;fixing&amp;quot; a problem for one source has a nasty tendency to break it for
all other sources. That's why there are so many flags that can be passed
around. Still, this is the approach I have to take...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="planning"></category><category term="calibration"></category><category term="pipeline"></category></entry><entry><title>It looks like, for AFGL 4029 combined images, ds1 ...</title><link href="https://keflavich.github.io/blog/it-looks-like-for-afgl-4029-combined-images-ds1.html" rel="alternate"></link><published>2011-02-14T22:55:00-07:00</published><updated>2011-02-14T22:55:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-14:/blog/it-looks-like-for-afgl-4029-combined-images-ds1.html</id><content type="html">&lt;p&gt;It looks like, for AFGL 4029 combined images, ds1 and ds5 agree to
within 5% in the Dec2010 data. This implies that the offset is a result
of the individual scans instead of coadds, though for the individual
observations ds1&amp;gt;ds5 pretty uniformly.&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>Downsampling - Why is Dec 2010 different?</title><link href="https://keflavich.github.io/blog/downsampling-why-is-dec-2010-different.html" rel="alternate"></link><published>2011-02-13T19:08:00-07:00</published><updated>2011-02-13T19:08:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-13:/blog/downsampling-why-is-dec-2010-different.html</id><summary type="html">&lt;p&gt;As you'll recall from &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/02/downsampling-what-is-going-on.html"&gt;my previous post&lt;/a&gt; (and references therein...),
the 2005 Orion data shows a discrepancy between ds1 and ds5 data in
which the ds1 data is significantly (~10%) higher than the ds5 data.
However, the 2010 Uranus observations show much larger discrepancies
between ds1 and ds5 favoring the â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;As you'll recall from &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/02/downsampling-what-is-going-on.html"&gt;my previous post&lt;/a&gt; (and references therein...),
the 2005 Orion data shows a discrepancy between ds1 and ds5 data in
which the ds1 data is significantly (~10%) higher than the ds5 data.
However, the 2010 Uranus observations show much larger discrepancies
between ds1 and ds5 favoring the ds5 data! Because that was somewhat
unbelievable to me, I ran ds1-ds5 comparisons on Uranus data from other
epochs, and discovered that ds1&amp;gt;ds5 uniformly (also, it looks a LOT
better).
So, the question remains, WHY is the Dec 2010 data brighter in ds5? More
confusing to me, why do the ds5 PSFs from 2010 look so reasonable, while
the ds5 PSFs from all earlier epochs look terrible?
For example, I use the observations 070727_o31 and _o32. These show
clearly the blurring and flux-loss that happens when ds5 data are used
for 'normal' point-sources:&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>From a comparison of 3 different epochs using abou...</title><link href="https://keflavich.github.io/blog/from-a-comparison-of-3-different-epochs-using-abou.html" rel="alternate"></link><published>2011-02-12T01:30:00-07:00</published><updated>2011-02-12T01:30:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-12:/blog/from-a-comparison-of-3-different-epochs-using-abou.html</id><summary type="html">&lt;p&gt;From a comparison of 3 different epochs using about a dozen different
reduction techniques, but all with pairs of cross-scans, ds1 is
uniformly higher than ds5.
The only thing left to do is compare the individual scans, I suppose...
if the cross-scans behave differently, that explains the difference
between 2010 â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;From a comparison of 3 different epochs using about a dozen different
reduction techniques, but all with pairs of cross-scans, ds1 is
uniformly higher than ds5.
The only thing left to do is compare the individual scans, I suppose...
if the cross-scans behave differently, that explains the difference
between 2010 and other epochs&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>Downsampling - what is going on?</title><link href="https://keflavich.github.io/blog/downsampling-what-is-going-on.html" rel="alternate"></link><published>2011-02-11T04:19:00-07:00</published><updated>2011-02-11T04:19:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-11:/blog/downsampling-what-is-going-on.html</id><summary type="html">&lt;p&gt;The downsampling failure I &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/01/downsampling-has-serious-negative.html"&gt;noted&lt;/a&gt; &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/01/more-evidence-that-downsampling-causes.html"&gt;previously&lt;/a&gt; appears to be
illusory. It may be that the offset noted only holds for single-frame
images, in which there may be many blank pixels. It is possible - though
not certain - that the ds1 images were significantly higher than ds5
because more noise-only pixels were â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The downsampling failure I &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/01/downsampling-has-serious-negative.html"&gt;noted&lt;/a&gt; &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/01/more-evidence-that-downsampling-causes.html"&gt;previously&lt;/a&gt; appears to be
illusory. It may be that the offset noted only holds for single-frame
images, in which there may be many blank pixels. It is possible - though
not certain - that the ds1 images were significantly higher than ds5
because more noise-only pixels were included with higher outliers; i.e.,
ds1 high-outlier noise was being compared to ds5 noise that was lower
amplitude.&lt;/p&gt;
&lt;p&gt;What led to these conclusions? First, I was getting inconsistent results
looking at Uranus in particular - ds5 appeared to have higher fluxes
than ds1. This was inconsistent with &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/01/downsampling-has-serious-negative.html"&gt;earlier results&lt;/a&gt; on OMC1. Partly,
this is because I switched from my &lt;a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/TTiWWl3j3dI/AAAAAAAAF3I/Ef3WHEv5oXU/s1600/omc1_dstest_pixel-pixel.png"&gt;hacked-together plots&lt;/a&gt; to the much
more refined &lt;a class="reference external" href="http://code.google.com/p/bgpspipeline/source/browse/bgps_pipeline/plotting/compare_images.py"&gt;compare_images&lt;/a&gt; script, which demonstrated the effect of
changing the cutoff of the comparison.&lt;/p&gt;
&lt;p&gt;Also, I added in a Pearson Correlation Coefficient computation. Given a
single data set with the only difference being downsampling, the data
should be perfectly correlated even if there is a flux offset
(correlation should be 1, but the best fit slope should not be). It was
an indication of a problem when I started seeing correlation
coefficients &amp;lt;0.90 for data that had already been sigma-cut; that means
that noise was being included in the correlation computations.&lt;/p&gt;
&lt;p&gt;Therefore, the approach needed is to cut out the high pixels that are on
map edges. This I accomplished by adding an 'aperture' capability to the
compare_images code (for Uranus) and cropping using montage and a
wcs-based box for Orion.&lt;/p&gt;
&lt;p&gt;The results... are ambiguous. Wow. In some sub-fields - within the same
co-added map - the agreement is near-perfect.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/-i20j3FEx758/TVR-PbQl7lI/AAAAAAAAGAY/imgMqceS9n8/s1600/v2.0_dl_omc_b_OMC4_ds1ds5_compare.png" /&gt;
&lt;p&gt;In others, ds1 is clearly &amp;gt; ds5.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/-JsRH_ZQilWM/TVR-Os6vBSI/AAAAAAAAGAQ/JRR6Trm-weo/s1600/v2.0_dl_omc_b_OMC2_ds1ds5_compare.png" /&gt;
&lt;p&gt;What's going on? ds1 does look uniformly more smooth.
Note that the &lt;em&gt;disagreement&lt;/em&gt; is nearly scale-free:&lt;/p&gt;
&lt;p&gt;OK, so given the conclusion in Orion that ds1&amp;gt;=ds5, what's the deal with
Uranus?&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-AosJ1vzcYSs/TVSZjIZ81fI/AAAAAAAAGAk/qVGeaJtkbPA/s320/101208_o10_ds1ds5_compare.png" /&gt;
&lt;p&gt;The first two comparisons are for 1x1Â° observations; in both cases ds1 &amp;lt;
ds5, but by 6% and 24% respectively! The image of Uranus looks much
better (because of lack of parallel lines) in the second, more extreme
case. In both cases, the ds5 excess is nearly scale-free (not shown).&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TVSZki9k9OI/AAAAAAAAGA0/t9LOGHOAL7Q/s320/101208_o10_ds1ds5_compare.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TVSZj1pglLI/AAAAAAAAGAs/-4153NoAQQ0/s320/101208_o11_ds1ds5_compare.png" /&gt;
&lt;p&gt;The 3x1s are also highly discrepant. #12 shows nearly perfect agreement,
albeit with high dispersion (low correlation) because of pixel-to-pixel
variations around the peak. #13 is the only observation with a huge DS1
excess. It also demonstrates very poor correlation. It looks like the
telescope got bumped for the ds5 data (which is not actually possible;
recall they're the same data set). What happened here? Maybe a glitch
that went unflagged (mad_flagger is off by default for individual
scans)?&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-9gwzGfDBCEk/TVSZllWeBxI/AAAAAAAAGA8/x3mg5RbMScs/s320/101208_o12_ds1ds5_compare.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/-9gwzGfDBCEk/TVSZllWeBxI/AAAAAAAAGA8/x3mg5RbMScs/s320/101208_o13_ds1ds5_compare.png" /&gt;
&lt;p&gt;In observations 4 and 5, we're looking at a 40-50% excess in ds5! What
the heck? There really is no clear explanation for this.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TVSaYfZx0WI/AAAAAAAAGBE/cWbbBQCJOvk/s320/101208_ob4_ds1ds5_compare.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TVSaZM27sqI/AAAAAAAAGBM/XR-6pttUcBo/s320/101208_ob5_ds1ds5_compare.png" /&gt;
&lt;p&gt;But... what? Magically, they come into perfect agreement when the scan
axis nearly lines up with the coordinate axis! Or, is this just an
effect of the worse weather on night 2?&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TVSaaP6ISNI/AAAAAAAAGBU/PvN5aFOxBAQ/s320/101209_ob5_ds1ds5_compare.png" /&gt;
&lt;p&gt;Next thing to try: masked source map comparison. Unfortunately, masking
royally screwed up the long scans - probably because the initial polysub
didn't work. And masking in the individual point source maps did
nothing... so that pretty much rules out atmospheric oversubtraction,
doesn't it?
What else could be causing this offset? 0pca looks the same as 13pca,
give or take, so it's not the atmospheric subtraction. Could the
downsampling result in an offset in the bolo-scaling? Where else in the
process could things go wrong? Tomorrow, need to investigate .sav files
with pyflagger...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Making maps faster</title><link href="https://keflavich.github.io/blog/making-maps-faster.html" rel="alternate"></link><published>2011-02-07T04:39:00-07:00</published><updated>2011-02-07T04:39:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-07:/blog/making-maps-faster.html</id><summary type="html">&lt;p&gt;The fundamental problem at this point is making the pipeline run faster.
At current speeds, with undownsampled data, it may take ~days to process
a single map. Ideas for faster processing:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Find out how long it takes to converge to 1%, 5%.... If it only
requires 10 iterations, that's a â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;The fundamental problem at this point is making the pipeline run faster.
At current speeds, with undownsampled data, it may take ~days to process
a single map. Ideas for faster processing:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Find out how long it takes to converge to 1%, 5%.... If it only
requires 10 iterations, that's a factor of 2 savings over current
strategies.&lt;/li&gt;
&lt;li&gt;Use downsampled data of some sort if possible. Does DS2 match DS1?
How do we measure it? Flux-flux comparison and PSF point-source size
measurements are the most important. Need to automate PSF
comparison....&lt;/li&gt;
&lt;li&gt;Can we use median-combined individual images as a 0th order model? I
bet the answer is 'yes' and will probably increase the speed of
convergence by a large amount. Tests to run? This is probably needed
if we are to split up the 'super-fields' into smaller sub-fields,
otherwise overlapping data will be used less effectively.&lt;/li&gt;
&lt;li&gt;Find some way to keep bgps.raw, bgps.ra, bgps.dec, and other items
that are only used once on the HD during the iterative process. Is
there any way to separate out data in a struct in this manner?&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category><category term="pipeline"></category></entry><entry><title>Delining - Maps</title><link href="https://keflavich.github.io/blog/delining-maps.html" rel="alternate"></link><published>2011-02-03T22:16:00-07:00</published><updated>2011-02-03T22:16:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-03:/blog/delining-maps.html</id><summary type="html">&lt;p&gt;First comment - delining has &lt;strong&gt;no effect&lt;/strong&gt; on downsampled data. At least
for the 0709 epoch, there were NO lines AT ALL in the data. From 0-5 Hz,
it was just empty. So we don't have to worry about that... the problem
only affects fully-sampled data.
Then, onto map comparisons. Curiously â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;First comment - delining has &lt;strong&gt;no effect&lt;/strong&gt; on downsampled data. At least
for the 0709 epoch, there were NO lines AT ALL in the data. From 0-5 Hz,
it was just empty. So we don't have to worry about that... the problem
only affects fully-sampled data.
Then, onto map comparisons. Curiously, the noise levels don't drop after
delining. They actually go up a bit. This may be because of the effects
on PCA cleaning.
However, flux levels in the sources go up by 0-10%. As usual, the change
in flux changes from field to field without any obvious reason.
Example 1: A pointing field. The source is ~2% brighter in the delined
version, but otherwise the match between the two is nearly perfect.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUskr5xAMSI/AAAAAAAAF_M/J65CutNg9hM/s320/101208_ob8_compare.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUsksatOJSI/AAAAAAAAF_U/9X-rM6JQmCU/s320/101208_ob8_psd.png" /&gt;
&lt;p&gt;Example 2: A bigger map, where the flux recovery is much greater when
delining, but the background levels are also higher.&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUsoBrKcQyI/AAAAAAAAF_c/junIzma1zg4/s320/101208_o11_compare.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUsoCFL1DiI/AAAAAAAAF_k/b1QrgajdlaE/s320/101208_o11_psd.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category><category term="pipeline"></category><category term="deline"></category></entry><entry><title>Delining and the Cleaning process</title><link href="https://keflavich.github.io/blog/delining-and-the-cleaning-process.html" rel="alternate"></link><published>2011-02-03T19:49:00-07:00</published><updated>2011-02-03T19:49:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-03:/blog/delining-and-the-cleaning-process.html</id><summary type="html">&lt;p&gt;One item I forgot to mention last night was the effects of
lines/delining on
PCA subtraction. These should be the primary effects on the final map
for all
epochs except 2010, in which case the primary effect SHOULD be to reduce
substantial noise.
In the examples below, there are â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;One item I forgot to mention last night was the effects of
lines/delining on
PCA subtraction. These should be the primary effects on the final map
for all
epochs except 2010, in which case the primary effect SHOULD be to reduce
substantial noise.
In the examples below, there are PSDs of whole timestreams (left) and
example timestreams from single scans (right). The first thing to note
is that
the delined timestreams still have correlated components in the line
region,
but they are suppressed - their amplitudes, and therefore their sort
order in
the PCA removal scheme, are changed. Since PCA cleaning is by its nature
adaptive
(the number of components remains fixed, but the order changes), these
effects
can be significant and dangerous. If the line noise is more correlated,
a PCA
component will be dedicated to removing it instead of atmospheric
signal.
Below are examples from l089 (epoch 0709) first. These have less
correlated
line noise and are more typical of BGPS observations. The first PCA
component,
the average, does not change much with PCA cleaning. However it is clear
that
the second component changes substantially, from large-amplitude
high-frequency
noise to small-amplitude variations that are very likely to describe
atmosphere.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Example 1 - Zeroing out the lines:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUrs_QRBBHI/AAAAAAAAF9Y/BH4XEdrFdt0/s320/zero_pca_psds.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUrs_nWI6YI/AAAAAAAAF9g/1Dcr0zyMBvM/s320/zero_pca_timestreams.png" /&gt;
&lt;p&gt;Example 2 - Fitting and removing the lines:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUrs-f7qfqI/AAAAAAAAF9I/Dt3Kk9roeW8/s320/fitline_pca_psds.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUrs-_it9CI/AAAAAAAAF9Q/06KgQOS2vNA/s320/fitline_pca_timestreams.png" /&gt;
&lt;p&gt;Example 3 - Suppressing the lines with a non-fitted Gaussian:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUr_QHkPADI/AAAAAAAAF9o/n5ylgDCLKPw/s320/wingsupp_pca_psds.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUr_QnuPZfI/AAAAAAAAF9w/lt4rEB1Qlq0/s320/wingsupp_pca_timestreams.png" /&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;The next examples are from December 2010 observations of Uranus. In this
case, the correlated noise component is clearly dominant.&lt;/p&gt;
&lt;p&gt;Zeroing lines:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCBUeD67I/AAAAAAAAF94/CCj9gbJOgk8/s320/zero_pca_psds.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCB4wFnSI/AAAAAAAAF-A/YgbjYlybcOc/s320/zero_pca_timestreams.png" /&gt;
&lt;p&gt;Fitted lines:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCCQNHurI/AAAAAAAAF-I/a5_FQ7bqUjI/s320/fitline_pca_psds.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUsCCtO7DTI/AAAAAAAAF-Q/wKBz0UhDruE/s320/fitline_pca_timestreams.png" /&gt;
&lt;p&gt;Non-fitted gaussian suppression:&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUsCLgCRbmI/AAAAAAAAF-Y/WzHcr1E5q4s/s320/wingsupp_pca_psds.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCL5e9eGI/AAAAAAAAF-g/TgmNWbiJzbs/s320/wingsupp_pca_timestreams.png" /&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Finally, these two are demonstrations of what you might expect to see
for a purely noiseless images of a planet (it was constructed from a
PSF). PCA is first:&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCyELAZ1I/AAAAAAAAF-o/65L-rwGFscM/s320/noiselesssim_pca_psds.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUsCyRaYY7I/AAAAAAAAF-w/ZaRL4CPWw2E/s320/noiselesssim_pca_timestreams.png" /&gt;
&lt;p&gt;A single bolometer's timestream and PSD:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUsDgR4xcEI/AAAAAAAAF-4/udxMkuH6kio/s320/noiselesssim_deline_wingsupp_10hz_noscan_nsig0_psds_000.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUsDgtnBPNI/AAAAAAAAF_A/weQNMCgtrtc/s320/noiselesssim_deline_wingsupp_10hz_noscan_nsig0_timestreams_000.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="cleaning"></category><category term="pipeline"></category><category term="deline"></category></entry><entry><title>Delining</title><link href="https://keflavich.github.io/blog/delining.html" rel="alternate"></link><published>2011-02-03T04:54:00-07:00</published><updated>2011-02-03T04:54:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-03:/blog/delining.html</id><summary type="html">&lt;p&gt;Delining refers to the process of removing electronic noise that is
aliased to
particular frequencies by the discrete sampling of the data. Typical
electronic noise is at 60 Hz with some width. It gets aliased to these
frequencies:
&lt;tt class="docutils literal"&gt;linefreqs = &lt;span class="pre"&gt;[10.05+findgen(10)*1.2,10.05-((findgen(7)+1 â€¦&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Delining refers to the process of removing electronic noise that is
aliased to
particular frequencies by the discrete sampling of the data. Typical
electronic noise is at 60 Hz with some width. It gets aliased to these
frequencies:
&lt;tt class="docutils literal"&gt;linefreqs = &lt;span class="pre"&gt;[10.05+findgen(10)*1.2,10.05-((findgen(7)+1))*1.2]&lt;/span&gt;&lt;/tt&gt;
The 10.05 Hz and 20.10 Hz are the worst in most cases, and they are
wider. For
the above lines, we &amp;quot;remove&amp;quot; a bandwidth of 0.09 Hz by averaging over
the
neighboring 0.5 Hz on either side. For the wider lines, we remove 0.5 Hz
by
averaging over the neighboring 1.5 Hz on either side.
There are a few new things about the delining process that did not exist
in James' old version:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The wide-band lines are removed&lt;/li&gt;
&lt;li&gt;A check is performed before removing the lines - they are only
removed if the line region mean is
2-sigma above the average region (as computed via median and mad)&lt;/li&gt;
&lt;li&gt;The replaced noise is computed via median/mad, and the new noise
level is set 5x lower than in the
neighboring region&lt;/li&gt;
&lt;/ol&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Now, some examples:&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUisqDHJ08I/AAAAAAAAF58/BpgnudfdAAw/s400/deline_timestreams_003.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUisqWN6ueI/AAAAAAAAF6E/yAka7dlomjo/s400/deline_psds_003.png" /&gt;
&lt;p&gt;The timestream (left) and PSD (right) of a &amp;quot;pretty good&amp;quot; bolometer.
There is a lot of noise in lines, but note that the peak power is 2-3
orders of magnitude below the PSD peak. In this case the &amp;quot;Power&amp;quot; is in
Jy. There is little astrophysical information below ~14&amp;quot; (9 Hz), and
there should be none below 7.2&amp;quot; (17 Hz), but there is plausibly
information at these scales. It therefore makes sense to save as much
information as possible. As can be seen in the delined PSD, the peaks
drop by a substantial fraction, but not all the way - that's because
these lines are wider than typically observed. Unfortunately, I don't
have any really good ideas about how to fix this issue - I think fitting
gaussians to each line, while attractive, is going to be prohibitively
expensive in both programmer and processor time. However... it would be
a very interesting project to undertake. In the timestream, it can be
seen that the RMS drops substantially when the lines are filtered out
(note that the timestream is strongly dominated by large-scale
structure, so 'substantial' is really based on the RMS of the lines
removed).&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUisq6D55wI/AAAAAAAAF6M/PZ4hyu5FkZM/s400/deline_10hz_timestreams_003.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUisrWpL7yI/AAAAAAAAF6U/tSsL5Jc4n-A/s400/deline_10hz_psds_003.png" /&gt;
&lt;p&gt;The next two plots look identical to the previous ones. In principle,
they include the wide-band delining. However, in this case, the
satellite lines to either side of the 10 Hz line are too strong and
prevent identification of the 10 Hz line. This is unfortunate, again,
but no obvious solution presents itself.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUixLZbVHPI/AAAAAAAAF6c/xCWLpb9CKX4/s400/deline_timestreams_004.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUixL8APCQI/AAAAAAAAF6k/j8FyKbgOdDo/s400/deline_psds_004.png" /&gt;
&lt;p&gt;Now we come to a truly problematic bolometer. The lines completely
dominate the power spectrum. Narrow line removal fails.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUixMjNxbkI/AAAAAAAAF6s/Hr8ouprcMpY/s400/deline_10hz_timestreams_004.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUixNMO2NsI/AAAAAAAAF60/ZAsirbb25QY/s400/deline_10hz_psds_004.png" /&gt;
&lt;p&gt;Wide line removal does a much, much better job, dropping the RMS by an
order of magnitude.... but the bolometer probably still needs to be
removed, since the astrophysical signal is 2-3 orders of magnitude below
that.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUizkq9x4TI/AAAAAAAAF68/2xYY86d6aTQ/s400/deline_timestreams_001.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUizlH0XvMI/AAAAAAAAF7E/ptDb5I3os6A/s400/deline_psds_001.png" /&gt;
&lt;p&gt;The 2010 data had much worse line noise and had to be delined. JS
accomplished this by throwing out all data above a certain frequency,
but I prefer the delining approach. It is clearly effective, but again
leaves much to be desired. Should the flagged bandwidth be increased?
What about the extra lines around 18 Hz?&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUizln1mSCI/AAAAAAAAF7M/hTkZRUU3-ck/s400/deline_10hz_timestreams_001.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUizmdrMkgI/AAAAAAAAF7U/-dlB4u30hBo/s400/deline_10hz_psds_001.png" /&gt;
&lt;p&gt;Again, the wide line flagging fails because of the satellite lines.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category><category term="deline"></category></entry><entry><title>Next step: prove that this works in maps...</title><link href="https://keflavich.github.io/blog/next-step-prove-that-this-works-in-maps.html" rel="alternate"></link><published>2011-02-03T04:53:00-07:00</published><updated>2011-02-03T04:53:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-03:/blog/next-step-prove-that-this-works-in-maps.html</id><content type="html">&lt;p&gt;Next step: prove that this works in maps...&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>Some pretty neat things about delining....</title><link href="https://keflavich.github.io/blog/some-pretty-neat-things-about-delining.html" rel="alternate"></link><published>2011-02-03T04:50:00-07:00</published><updated>2011-02-03T04:50:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-03:/blog/some-pretty-neat-things-about-delining.html</id><summary type="html">&lt;p&gt;Well, I did the work, so might as well come up with some plots...
I created a gaussian-fitting based delining code that saves all of the
fits in a text file! That's a lot of data to play with, and allows me to
draw some conclusions:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;For the narrow lines â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;Well, I did the work, so might as well come up with some plots...
I created a gaussian-fitting based delining code that saves all of the
fits in a text file! That's a lot of data to play with, and allows me to
draw some conclusions:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;For the narrow lines, the linewidth (gaussian sigma) is 0.03 Hz. For
the wide lines, it is 0.05.&lt;/li&gt;
&lt;li&gt;The amplitudes from December 2010 are ENORMOUS compared to others!&lt;/li&gt;
&lt;li&gt;The width distributions of the two are similar, though the lines
appear to be significantly wider in July 2009&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I've also gotten to the point that I'm satisfied with how delining with
wing suppression works. Wing suppression is 0.4-2x quicker than fitting
directly, depending on... not clear what exactly; it depends on epoch,
but that could either be because there are more lines found or because
of relative data size. Does delining have to be done on whole
timestreams, or can it be done on a scan-by-scan basis? This is not
entirely clear... the peaks are less suppressed when done on a
scan-by-scan basis (presumably because the S/N is low and peaks are
therefore not detected), but incorrect suppression (removing a line
that's not there) is reduced. For short scans, the scan-by-scan approach
is 10x faster; for longer scans it's ~20% faster. I think the
scan-by-scan approach is going to be ideal.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Examples from l089 (0709):
Top row: non-fitted line suppression&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUowz4zgpsI/AAAAAAAAF8E/iJd0tAbVj0U/s320/deline_10hz_wingsuppress_psds_003.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUow1IQ_Y9I/AAAAAAAAF8c/1OkISODwwPM/s320/deline_fitline_10hz_noscan_nsig0_preservephase_timestreams_003.png" /&gt;
&lt;p&gt;Bottom row: fitted line suppression&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUow0sTBKsI/AAAAAAAAF8U/GtL0nyvlNBw/s320/deline_fitline_10hz_noscan_nsig0_preservephase_psds_003.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUow0d-vEcI/AAAAAAAAF8M/or2gkvGxW4o/s320/deline_10hz_wingsuppress_timestreams_003.png" /&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Examples from Uranus (1012, really really liney):&lt;/p&gt;
&lt;p&gt;Top row: non-fitted line suppression&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUoxEvWqRwI/AAAAAAAAF8k/J6ImhPN9ZS0/s320/deline_10hz_wingsuppress_psds_003.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUoxFMLdujI/AAAAAAAAF8s/DrzWxFCdBu0/s320/deline_10hz_wingsuppress_timestreams_003.png" /&gt;
&lt;p&gt;Bottom row: fitted line suppression&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUoxFXYN_tI/AAAAAAAAF80/BQwv6ROSOJ4/s320/deline_fitline_10hz_noscan_nsig0_preservephase_psds_003.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUoxF_c0URI/AAAAAAAAF88/JU9_F-8HC2k/s320/deline_fitline_10hz_noscan_nsig0_preservephase_timestreams_003.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category><category term="deline"></category></entry><entry><title>Bleh, a whole day&amp;#39;s work dedicate to new delin...</title><link href="https://keflavich.github.io/blog/bleh-a-whole-days-work-dedicate-to-new-delin.html" rel="alternate"></link><published>2011-02-03T03:29:00-07:00</published><updated>2011-02-03T03:29:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-03:/blog/bleh-a-whole-days-work-dedicate-to-new-delin.html</id><summary type="html">&lt;p&gt;Bleh, a whole day's work dedicate to new delining methods and testing.
Very unrewarding. However, there are results that I need to FINALLY
prove and show tomorrow:
1. amplitude suppression + phase preservation is a good alternative to
zeroing/scrambling or replacing with noise
2. line fitting is effective but slow â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Bleh, a whole day's work dedicate to new delining methods and testing.
Very unrewarding. However, there are results that I need to FINALLY
prove and show tomorrow:
1. amplitude suppression + phase preservation is a good alternative to
zeroing/scrambling or replacing with noise
2. line fitting is effective but slow
3. Assuming a line profile and suppressing is nearly as effective as
line fitting
4. scan-by-scan is less effective than observation-by-observation for
fitting (but it's not clear if that holds for other methods)&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>What about the effects on the map? Unfortunately,...</title><link href="https://keflavich.github.io/blog/what-about-the-effects-on-the-map-unfortunately.html" rel="alternate"></link><published>2011-02-02T02:12:00-07:00</published><updated>2011-02-02T02:12:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-02-02:/blog/what-about-the-effects-on-the-map-unfortunately.html</id><summary type="html">&lt;p&gt;What about the effects on the map? Unfortunately, in the tests I've run,
delining actually INCREASES the noise in the map! How is this possible?
My only hypothesis is that PCA cleaning does an excellent job of
removing the line noise, but when it is replaced with truly uncorrelated
gaussian â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;What about the effects on the map? Unfortunately, in the tests I've run,
delining actually INCREASES the noise in the map! How is this possible?
My only hypothesis is that PCA cleaning does an excellent job of
removing the line noise, but when it is replaced with truly uncorrelated
gaussian noise, the PCA cleaning no longer removes that component.
But we don't want PCA cleaning to grab instrumental correlated noise; we
want it to be limited to atmospheric noise. So ideally we want to
completely remove the line noise without adding noise to the image...
maybe the line regions should just be set to zero after all....&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>Downsampling by a factor of 3 appears not to be an...</title><link href="https://keflavich.github.io/blog/downsampling-by-a-factor-of-3-appears-not-to-be-an.html" rel="alternate"></link><published>2011-01-27T22:16:00-07:00</published><updated>2011-01-27T22:16:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-01-27:/blog/downsampling-by-a-factor-of-3-appears-not-to-be-an.html</id><summary type="html">&lt;p&gt;Downsampling by a factor of 3 appears not to be an option because this
error:
% NCDF_VARGET: Requested read is larger than data in dimension 0.
Reducing COUNT to 615.
% REBIN: Result dimensions must be integer factor of original dimensions
% Execution halted at: NCDF_VARGET_SCALE 133
/Users/adam/work â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Downsampling by a factor of 3 appears not to be an option because this
error:
% NCDF_VARGET: Requested read is larger than data in dimension 0.
Reducing COUNT to 615.
% REBIN: Result dimensions must be integer factor of original dimensions
% Execution halted at: NCDF_VARGET_SCALE 133
/Users/adam/work/bgps_pipeline/support/ncdf_varget_scale.pro
occurs.&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>More evidence that downsampling causes problems</title><link href="https://keflavich.github.io/blog/more-evidence-that-downsampling-causes-problems.html" rel="alternate"></link><published>2011-01-21T22:48:00-07:00</published><updated>2011-01-21T22:48:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-01-21:/blog/more-evidence-that-downsampling-causes-problems.html</id><content type="html">&lt;p&gt;The captions are pretty much the same as for &lt;a class="reference external" href="http://bolocam.blogspot.com/2011/01/downsampling-has-serious-negative.html"&gt;the previous post&lt;/a&gt;, but
this is a larger field and the effects are more serious.&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TToMoxR5xJI/AAAAAAAAF3Q/qod6NlqiNpU/s400/orion_omc1_dstest_images.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TToMpcpYjJI/AAAAAAAAF3Y/Hp9V2KcCEgE/s400/orion_omc1_dstest_autocorrfits.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TToMpxmFurI/AAAAAAAAF3g/-JJwti4yW58/s400/orion_omc1_dstest_psds.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TToMqdKihGI/AAAAAAAAF3o/X54ObZ_AHkk/s400/orion_omc1_dstest_pixel-pixel.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category><category term="pipeline"></category></entry><entry><title>Downsampling has serious negative effects on the data</title><link href="https://keflavich.github.io/blog/downsampling-has-serious-negative-effects-on-the-data.html" rel="alternate"></link><published>2011-01-20T20:16:00-07:00</published><updated>2011-01-20T20:16:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2011-01-20:/blog/downsampling-has-serious-negative-effects-on-the-data.html</id><summary type="html">&lt;p&gt;Background: Downsampling is performed using Old Pipeline code called
&lt;tt class="docutils literal"&gt;process_ncdf&lt;/tt&gt;. All BGPS data was downsampled by a factor of 5
before mapping because of data size concerns. I did this 'blindly'
(i.e., just
accepted that I should) because James said I could.
However, I had previously noted that â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Background: Downsampling is performed using Old Pipeline code called
&lt;tt class="docutils literal"&gt;process_ncdf&lt;/tt&gt;. All BGPS data was downsampled by a factor of 5
before mapping because of data size concerns. I did this 'blindly'
(i.e., just
accepted that I should) because James said I could.
However, I had previously noted that the pointing files could not be
done with
downsampled data because the beams 'looked funny' or something along
those
lines; it may also have been a simple map sampling issue in which not
all
pixels were filled with a downsampled image.
Anyway, I decided to go back and quantify the effects. The plots below
are from the
single &amp;quot;pointing-style&amp;quot; observation of OMC1 from 2009. The units are
volts. 'ds1' indicates
sampling at 0.02 seconds, 'ds5' indicates sampling every 0.1 seconds.
The scan rate was
120&amp;quot;/s.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TTiWWSS-JVI/AAAAAAAAF24/4m2SFfwWkmA/s400/omc1_dstest_autocorrfits.png" /&gt;
&lt;p&gt;The beam sizes were measured from the autocorrelation maps. However,
because there is structure on many scales
in this map, I had to use a rather ad-hoc method to remove the
correlated structure. I fitted a gaussian
to the elliptical northwest-southeast structure, removed it, then fitted
a gaussian to the remaining circular
thing in the center, which is approximately the beam.
If I fit the &amp;quot;beam&amp;quot; gaussian with an ellipse, I get:
Beamsize 1_1: 36.15,26.23
Beamsize 1_5: 48.39,30.21
With a circle:
Beamsize 1_1: 29.51
Beamsize 1_5: 35.31&lt;/p&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TTiWWKeGbJI/AAAAAAAAF2w/jOEmOnDa1hw/s400/omc1_dstest_images.png" /&gt;
&lt;p&gt;The ds1 and ds5 images compared.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TTiWWlzyWKI/AAAAAAAAF3A/nPCN-C0e3Jo/s400/omc1_dstest_psds.png" /&gt;
&lt;p&gt;The PSDs of the two images (on identical grids). Note that ds5 loses
power at small spatial scales, 50% at 40&amp;quot;!&lt;/p&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TTiWWl3j3dI/AAAAAAAAF3I/Ef3WHEv5oXU/s400/omc1_dstest_pixel-pixel.png" /&gt;
&lt;p&gt;The pixel-pixel plot with a fit that shows a 10% overall flux loss
(best-fit).&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category><category term="calibration"></category></entry><entry><title>BGPS data paper published</title><link href="https://keflavich.github.io/blog/bgps-data-paper-published.html" rel="alternate"></link><published>2010-11-03T15:22:00-06:00</published><updated>2010-11-03T15:22:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-11-03:/blog/bgps-data-paper-published.html</id><summary type="html">&lt;p&gt;&amp;nbsp;*[[&lt;a class="reference external" href="http://irsa.ipac.caltech.edu/data/BOLOCAM_GPS/bgps_methods.pdf"&gt;http://irsa.ipac.caltech.edu/data/BOLOCAM_GPS/bgps_methods.pdf&lt;/a&gt;
The Bolocam Galactic Plane Survey I. Survey Description and Data
Reduction] `[`[&lt;a class="reference external" href="http://arxiv.org/abs/1011.0691"&gt;http://arxiv.org/abs/1011.0691&lt;/a&gt; arXiv]`]`
&amp;nbsp;*[[&lt;a class="reference external" href="http://adsabs.harvard.edu/abs/2010ApJS..188..123R"&gt;http://adsabs.harvard.edu/abs/2010ApJS..188..123R&lt;/a&gt; The Bolocam
Galactic Plane Survey II. Catalog of the Image Data]
`[`[&lt;a class="reference external" href="http://arxiv.org/abs/0909.2871"&gt;http://arxiv â€¦&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&amp;nbsp;*[[&lt;a class="reference external" href="http://irsa.ipac.caltech.edu/data/BOLOCAM_GPS/bgps_methods.pdf"&gt;http://irsa.ipac.caltech.edu/data/BOLOCAM_GPS/bgps_methods.pdf&lt;/a&gt;
The Bolocam Galactic Plane Survey I. Survey Description and Data
Reduction] `[`[&lt;a class="reference external" href="http://arxiv.org/abs/1011.0691"&gt;http://arxiv.org/abs/1011.0691&lt;/a&gt; arXiv]`]`
&amp;nbsp;*[[&lt;a class="reference external" href="http://adsabs.harvard.edu/abs/2010ApJS..188..123R"&gt;http://adsabs.harvard.edu/abs/2010ApJS..188..123R&lt;/a&gt; The Bolocam
Galactic Plane Survey II. Catalog of the Image Data]
`[`[&lt;a class="reference external" href="http://arxiv.org/abs/0909.2871"&gt;http://arxiv.org/abs/0909.2871&lt;/a&gt; arXiv]`]`
&amp;nbsp;*[[&lt;a class="reference external" href="http://adsabs.harvard.edu/abs/2010ApJ...717.1157D"&gt;http://adsabs.harvard.edu/abs/2010ApJ...717.1157D&lt;/a&gt; The Bolocam
Galactic Plane Survey III. Characterizing Physical Properties of Massive
Star-Forming Regions in the Gemini OB1 Molecular Cloud ]
`[`[&lt;a class="reference external" href="http://arxiv.org/abs/1005.4969"&gt;http://arxiv.org/abs/1005.4969&lt;/a&gt; arXiv]`]`
&amp;nbsp;*[[&lt;a class="reference external" href="http://adsabs.harvard.edu/abs/2010ApJ...721..137B"&gt;http://adsabs.harvard.edu/abs/2010ApJ...721..137B&lt;/a&gt; The Bolocam
Galactic Plane Survey IV: Î» = 1.1 and 0.35 mm Dust Continuum Emission in
the Galactic Center Region]&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>v2.0 is to v1.0 as ___ is to v1.0</title><link href="https://keflavich.github.io/blog/v20-is-to-v10-as-___-is-to-v10.html" rel="alternate"></link><published>2010-06-24T23:04:00-06:00</published><updated>2010-06-24T23:04:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-24:/blog/v20-is-to-v10-as-___-is-to-v10.html</id><summary type="html">&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TCN8uqZ-xSI/AAAAAAAAFw8/TywL2w_ntIk/s320/l079_comparison.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TCN8vlKAjAI/AAAAAAAAFxE/BZE5Wlca8oU/s320/l079_comparison_psd.png" /&gt;
&lt;p&gt;Apparently v2.0 recovers flux better at all scales than v1.0.&amp;nbsp; However,
it is noisier.&amp;nbsp; The full comparison is available &lt;a class="reference external" href="http://casa.colorado.edu/%7Eginsbura/bgps/v1.0_v2.0_comparison.pdf"&gt;here&lt;/a&gt;.&amp;nbsp; The
trustworthy range of flux scales is 1.2-1.6ish.&amp;nbsp; The flux is increased
at ALL scales in most images.&amp;nbsp; However, as was noted in comparisons with
MAMBO â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TCN8uqZ-xSI/AAAAAAAAFw8/TywL2w_ntIk/s320/l079_comparison.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TCN8vlKAjAI/AAAAAAAAFxE/BZE5Wlca8oU/s320/l079_comparison_psd.png" /&gt;
&lt;p&gt;Apparently v2.0 recovers flux better at all scales than v1.0.&amp;nbsp; However,
it is noisier.&amp;nbsp; The full comparison is available &lt;a class="reference external" href="http://casa.colorado.edu/%7Eginsbura/bgps/v1.0_v2.0_comparison.pdf"&gt;here&lt;/a&gt;.&amp;nbsp; The
trustworthy range of flux scales is 1.2-1.6ish.&amp;nbsp; The flux is increased
at ALL scales in most images.&amp;nbsp; However, as was noted in comparisons with
MAMBO, there may be curvature in the best-fit lines.&amp;nbsp; Also, l=35 does
not appear to scale up linearly... G34 is fainter in v2.0?
In the low S/N fields, the PSD is more reliable than the pixel-pixel
comparison.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="discrepancy"></category><category term="v2.0"></category></entry><entry><title>PPS comparison completed</title><link href="https://keflavich.github.io/blog/pps-comparison-completed.html" rel="alternate"></link><published>2010-06-24T15:24:00-06:00</published><updated>2010-06-24T15:24:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-24:/blog/pps-comparison-completed.html</id><content type="html">&lt;p&gt;The PPS scale factor seems to hold for many different (and ridiculous)
aperture sizes.&amp;nbsp; The full results are &lt;a class="reference external" href="http://casa.colorado.edu/%7Eginsbura/bgps/pps_comparison.pdf"&gt;here.&lt;/a&gt;&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category><category term="discrepancy"></category></entry><entry><title>PPS analysis: suggests a possible solution to the discrepancy</title><link href="https://keflavich.github.io/blog/pps-analysis-suggests-a-possible-solution-to-the-discrepancy.html" rel="alternate"></link><published>2010-06-21T18:17:00-06:00</published><updated>2010-06-21T18:17:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-21:/blog/pps-analysis-suggests-a-possible-solution-to-the-discrepancy.html</id><summary type="html">&lt;p&gt;The comparisons I mentioned in the previous post are sort of done.&amp;nbsp; They
are pretty suggestive of a solution to the &amp;quot;flux recovery problem&amp;quot; we
think must be true.&amp;nbsp; However, even if it is a solution, it doesn't
really solve the problem completely.
It looks like v1.0 should be â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The comparisons I mentioned in the previous post are sort of done.&amp;nbsp; They
are pretty suggestive of a solution to the &amp;quot;flux recovery problem&amp;quot; we
think must be true.&amp;nbsp; However, even if it is a solution, it doesn't
really solve the problem completely.
It looks like v1.0 should be scaled up by a factor of 1.3-1.4 (not
1.5).&amp;nbsp; v2.0 is consistent with the PPS sources to within 5%, and might
even be slightly too high.
The comparison was done by taking the flux in a 60&amp;quot; radius aperture
(equivalent to bolocat 120&amp;quot; diameter apertures) and subtracting off the
background measured in a 120&amp;quot; radius annulus around the source.&amp;nbsp; Without
the background subtraction, these numbers would look very different: in
the science fields, most of the sources sit on an extended background.
Even though the &amp;quot;background flux&amp;quot; isn't recovered in the PPS fields, it
should contribute to the source background because it is involved in the
atmosphere subtraction (it's sort of &amp;quot;already subtracted&amp;quot; so you have to
subtract from the science fields).&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TB-rPT7MLdI/AAAAAAAAFws/7oWTt3FOF-M/s320/BGPS_correction_factors.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TB-rQId8G_I/AAAAAAAAFw0/NUJKQO_5zI4/s320/BGPS_correction_factor_histograms.png" /&gt;
&lt;p&gt;Next step: direct comparison between v1.0 and v2.0.&amp;nbsp; Pixel by pixel,
aperture, and powerspectrum&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category><category term="discrepancy"></category></entry><entry><title>PPS analysis</title><link href="https://keflavich.github.io/blog/pps-analysis.html" rel="alternate"></link><published>2010-06-16T18:06:00-06:00</published><updated>2010-06-16T18:06:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-16:/blog/pps-analysis.html</id><summary type="html">&lt;p&gt;I've started looking at PPS fields to see if I can glean any additional
information about the &amp;quot;flux discrepancy&amp;quot; from them.&amp;nbsp; However, the
results are, as usual, unenlightening.
There is no consistent increase in flux when 3 PCA components are used
instead of 13 PCA components - very plausibly an indication â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've started looking at PPS fields to see if I can glean any additional
information about the &amp;quot;flux discrepancy&amp;quot; from them.&amp;nbsp; However, the
results are, as usual, unenlightening.
There is no consistent increase in flux when 3 PCA components are used
instead of 13 PCA components - very plausibly an indication that 13 PCA
is not too much to subtract because it's only atmosphere.&amp;nbsp; Similarly,
there is no obvious benefit to using a quadratic sky estimator instead
of a PCA estimator.
I'm using aperture photometry (without background subtraction) on
identical fields to perform these comparisons.&amp;nbsp; I've selected
(arbitrarily) the l357pps source as my comparison source.&amp;nbsp; The next step
(ongoing) is to compare to the co-added maps and crosshatched
large-scale maps of the same field.
(next step) PPS &amp;lt; single cross-hatched large-scale observation pair &amp;lt;
13PCA full combined map &amp;lt; 3PCA full combined map.
Unfortunately, this result implies that the small maps under-recover
flux, which suggests that the large maps are too bright, which is the
opposite of what we expect.&amp;nbsp; Additionally, lower noise -&amp;gt; more flux
recovered?
When background subtraction is included, the 3PCA and 13PCA fluxes match
nearly perfectly.
Despite the failure of this test (PPS &amp;lt; full field), I will do a
systematic comparison of PPS sources with 0PCA + masking to the large
fields in the hopes that doing so can provide a legitimate estimate of
the &amp;quot;scale factor&amp;quot; from treating small and large fields differently.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>BGPS Pipeline Published</title><link href="https://keflavich.github.io/blog/bgps-pipeline-published.html" rel="alternate"></link><published>2010-06-11T19:59:00-06:00</published><updated>2010-06-11T19:59:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-11:/blog/bgps-pipeline-published.html</id><content type="html">&lt;p&gt;The BGPS pipeline has officially been released on &lt;a class="reference external" href="http://code.google.com/p/bgpspipeline/"&gt;Google Code&lt;/a&gt;.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Aperture Photometry on Herschel-based simulation</title><link href="https://keflavich.github.io/blog/aperture-photometry-on-herschel-based-simulation.html" rel="alternate"></link><published>2010-06-08T18:15:00-06:00</published><updated>2010-06-08T18:15:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-08:/blog/aperture-photometry-on-herschel-based-simulation.html</id><summary type="html">&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA6IGulWZrI/AAAAAAAAFvU/MHMBrTgxxnU/s200/ApertureCompare_Source00.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TA6IHwUnzhI/AAAAAAAAFvc/6xv7rKG9Ao4/s200/ApertureCompare_Source01.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TA6IIrbLWVI/AAAAAAAAFvk/mVRxd8bCY0w/s200/ApertureCompare_Source02.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TA6IJQBhEoI/AAAAAAAAFvs/VhnsSNbs75A/s200/ApertureCompare_Source03.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TA6IKP3X_SI/AAAAAAAAFv0/LCXAGTyp_yE/s200/ApertureCompare_Source04.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TA6ILDl55sI/AAAAAAAAFv8/jFfTmYof1yQ/s200/ApertureCompare_Source05.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA6IL9QhTmI/AAAAAAAAFwE/TAIwnefrPlE/s200/ApertureCompare_Source06.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TA6IM_9TaaI/AAAAAAAAFwM/0YpADED3SlE/s200/ApertureCompare_Source07.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA6IOYETGbI/AAAAAAAAFwU/aq5OYcifDc8/s200/ApertureCompare_Source08.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA6IPFzIniI/AAAAAAAAFwc/omOacZgjFuc/s200/ApertureCompare_Source09.png" /&gt;
&lt;p&gt;Aperture Photometry on isolated and not-so-isolated sources in the
Herschel-based BGPS simulation using the L=111 field for the &amp;quot;noise&amp;quot;.
Depending on the aperture, our flux recovery can be really really low.
The images should give an idea of the S/N.&amp;nbsp; Background subtraction means
subtracting the median of the â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA6IGulWZrI/AAAAAAAAFvU/MHMBrTgxxnU/s200/ApertureCompare_Source00.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TA6IHwUnzhI/AAAAAAAAFvc/6xv7rKG9Ao4/s200/ApertureCompare_Source01.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TA6IIrbLWVI/AAAAAAAAFvk/mVRxd8bCY0w/s200/ApertureCompare_Source02.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TA6IJQBhEoI/AAAAAAAAFvs/VhnsSNbs75A/s200/ApertureCompare_Source03.png" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TA6IKP3X_SI/AAAAAAAAFv0/LCXAGTyp_yE/s200/ApertureCompare_Source04.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TA6ILDl55sI/AAAAAAAAFv8/jFfTmYof1yQ/s200/ApertureCompare_Source05.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA6IL9QhTmI/AAAAAAAAFwE/TAIwnefrPlE/s200/ApertureCompare_Source06.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TA6IM_9TaaI/AAAAAAAAFwM/0YpADED3SlE/s200/ApertureCompare_Source07.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA6IOYETGbI/AAAAAAAAFwU/aq5OYcifDc8/s200/ApertureCompare_Source08.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA6IPFzIniI/AAAAAAAAFwc/omOacZgjFuc/s200/ApertureCompare_Source09.png" /&gt;
&lt;p&gt;Aperture Photometry on isolated and not-so-isolated sources in the
Herschel-based BGPS simulation using the L=111 field for the &amp;quot;noise&amp;quot;.
Depending on the aperture, our flux recovery can be really really low.
The images should give an idea of the S/N.&amp;nbsp; Background subtraction means
subtracting the median of the image.... it works frighteningly well in
most cases.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="simulation"></category></entry><entry><title>Pipeline Flowcharts</title><link href="https://keflavich.github.io/blog/pipeline-flowcharts.html" rel="alternate"></link><published>2010-06-07T22:39:00-06:00</published><updated>2010-06-07T22:39:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-07:/blog/pipeline-flowcharts.html</id><summary type="html">&lt;p&gt;In the process of hunting down a supposed calibration error, I
determined that it was necessary to generate a more intuitive graphical
display of the pipeline. Hence, pipeline flowcharts (generated in
keynote). The key should be self-explanatory to the degree that any part
of these charts is understandable to an â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the process of hunting down a supposed calibration error, I
determined that it was necessary to generate a more intuitive graphical
display of the pipeline. Hence, pipeline flowcharts (generated in
keynote). The key should be self-explanatory to the degree that any part
of these charts is understandable to an outsider. The yellow boxes
represent wrapper scripts/functions while the rounded box bubbles show
individual functions within these wrappers and their interrelationship.&lt;/p&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TA10NjZw6qI/AAAAAAAAFtc/ibmISvLIcm0/s400/PipelineFlowchartV1.0.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TA10O8mOl5I/AAAAAAAAFtk/W5M6XdTf6mM/s400/PipelineFlowchartV2.0.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Minor mystery resolved: Perseus cal curve</title><link href="https://keflavich.github.io/blog/minor-mystery-resolved-perseus-cal-curve.html" rel="alternate"></link><published>2010-06-07T22:32:00-06:00</published><updated>2010-06-07T22:32:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-07:/blog/minor-mystery-resolved-perseus-cal-curve.html</id><summary type="html">&lt;p&gt;When I started working on the Perseus data again, I decided to use the
Enoch 2006 calibration curve directly. However, it has a very different
form than all other epochs. The reason, as revealed below, is that it
was not forced through 0,0. Additionally, all of the BGPS data â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I started working on the Perseus data again, I decided to use the
Enoch 2006 calibration curve directly. However, it has a very different
form than all other epochs. The reason, as revealed below, is that it
was not forced through 0,0. Additionally, all of the BGPS data was
observed with mean DC ~ 2-3 V, while the Perseus data was observed with
mean DC 4-5 V, so the relevant regime is in a very different location.
The reference DC bias was much lower, ~2.15 V vs. 4.6 V in the 2005-2007
BGPS and 2.6 V in the 2009 BGPS.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TA1yfdAS7BI/AAAAAAAAFtU/XvYiDQKi-cM/s320/CalCurveComparison.png" /&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="perseus"></category><category term="calibration"></category></entry><entry><title>Minor mystery solved</title><link href="https://keflavich.github.io/blog/minor-mystery-solved.html" rel="alternate"></link><published>2010-06-07T22:23:00-06:00</published><updated>2010-06-07T22:23:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2010-06-07:/blog/minor-mystery-solved.html</id><content type="html"></content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>RELEASE</title><link href="https://keflavich.github.io/blog/release.html" rel="alternate"></link><published>2009-06-22T23:30:00-06:00</published><updated>2009-06-22T23:30:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-06-22:/blog/release.html</id><content type="html">&lt;p&gt;Finally.
&lt;a class="reference external" href="http://irsa.ipac.caltech.edu/"&gt;http://irsa.ipac.caltech.edu/&lt;/a&gt;&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Eimers project</title><link href="https://keflavich.github.io/blog/eimers-project.html" rel="alternate"></link><published>2009-03-21T01:24:00-06:00</published><updated>2009-03-21T01:24:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-03-21:/blog/eimers-project.html</id><content type="html">&lt;p&gt;Project for Marc Eimers:
Determine velocities to molecular clouds by a variety of methods. Start
with l=30
1. Find archival data, particularly from the JCMT, for each core.
2. Compare morphologically to 13CO from GRS
3. Find Vizier data&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category></entry><entry><title>locating beams</title><link href="https://keflavich.github.io/blog/locating-beams.html" rel="alternate"></link><published>2009-03-20T21:18:00-06:00</published><updated>2009-03-20T21:18:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-03-20:/blog/locating-beams.html</id><content type="html">&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/ScQIDaTTPhI/AAAAAAAAEzk/C67XkoQb244/s400/beamlocations_050619_default_bolopars.png" /&gt;
&lt;p&gt;White - &amp;quot;Default&amp;quot;, OP-calculated beam-locations
Red - My code's beam locations
Yellow - Boloparams, the fiducial beam locations&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="distortion mapping"></category></entry><entry><title>Gem OB1 comparisons</title><link href="https://keflavich.github.io/blog/gem-ob1-comparisons.html" rel="alternate"></link><published>2009-03-09T00:07:00-06:00</published><updated>2009-03-09T00:07:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-03-09:/blog/gem-ob1-comparisons.html</id><summary type="html">&lt;p&gt;I'm running 0,1,2,3,5,7,10,16, and 19 PCA component 51 iteration maps of
Gem OB1 with deconvolution. No clue when they'll be done because they're
at the end of a long queue.
Next (important!) step is to re-run the simulations with linear source
sizes but â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm running 0,1,2,3,5,7,10,16, and 19 PCA component 51 iteration maps of
Gem OB1 with deconvolution. No clue when they'll be done because they're
at the end of a long queue.
Next (important!) step is to re-run the simulations with linear source
sizes but with different numbers of PCA components, different kernel
sizes, etc..... there is a LOT of parameter space to cover.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category><category term="simulation"></category></entry><entry><title>A detailed look at l086</title><link href="https://keflavich.github.io/blog/a-detailed-look-at-l086.html" rel="alternate"></link><published>2009-03-04T21:35:00-07:00</published><updated>2009-03-04T21:35:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-03-04:/blog/a-detailed-look-at-l086.html</id><summary type="html">&lt;p&gt;Despite a slew of alignment errors, it appears that the alignment for
MOST fields turns out OK using Method 3 of the pixel-shift code; the
signal to noise is VERY low in a lot of fields.
070724_o38 does not come up with a good fit, for very good reason â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Despite a slew of alignment errors, it appears that the alignment for
MOST fields turns out OK using Method 3 of the pixel-shift code; the
signal to noise is VERY low in a lot of fields.
070724_o38 does not come up with a good fit, for very good reason -
there appears to be no signal at all.
070907_o20 is a problem. The offset was 27 pixels, which is too large,
but nonetheless correct. I had to institute the plane fitter at an
earlier stage to get it to work.
However, the biggest problem: the SCUBA source aligns with 070907_o20
but not the rest of the maps. So I needed to re-fit everything. That was
a BIG mistake, we need to check carefully for it in other fields.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Methods Paper: Figures / analysis to produce</title><link href="https://keflavich.github.io/blog/methods-paper-figures-analysis-to-produce.html" rel="alternate"></link><published>2009-03-04T03:43:00-07:00</published><updated>2009-03-04T03:43:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-03-04:/blog/methods-paper-figures-analysis-to-produce.html</id><summary type="html">&lt;p&gt;The methods paper needs some justification of the number of PCA
components used. This will require a map of some field with a range of
number of PCA components.
Plan:
simulate a map of L111 (the most square field) with 0-20 PCA components
x 21 iterations and a variety of â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The methods paper needs some justification of the number of PCA
components used. This will require a map of some field with a range of
number of PCA components.
Plan:
simulate a map of L111 (the most square field) with 0-20 PCA components
x 21 iterations and a variety of source sizes and plot the recovered
flux vs. number of PCA components. Ideally, do this with both
deconvolution and not. Estimated processing time is ~24 hours.
Also, a plot of flux vs. iteration number will be useful.
Glitch filtering method has been modified:
&amp;quot;Glitches are removed by drizzling each bolometer measurement into a
given pixel using the mapping M[p], but retaining each pixel as an array
of measurements. Then, measurements exceeding $3\times MAD$ (Median
Average Deviation) are flagged out in the timestream. In cases where
there were too few ($&amp;lt;3$) hits per pixel, the pixel was completely
flagged out. This only occurred for pixels at scan edges.&amp;quot;
Data flagging:
Partly covered by deglitching. Many scans were flagged by hand to remove
overly noisy scans and those that were observed to confuse the iterative
mapper. Hand flagging is more robust than automated and can remove
features caused by the filter convolved with the glitch.
Creation of astrophysical model:
Not entirely sure what this section entails. Should have a subsection on
deconvolution though.
Jackknifing has not generally been done...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="methods paper"></category></entry><entry><title>4.3 Relative Alignment and Mosaicing</title><link href="https://keflavich.github.io/blog/43-relative-alignment-and-mosaicing.html" rel="alternate"></link><published>2009-03-04T02:57:00-07:00</published><updated>2009-03-04T02:57:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-03-04:/blog/43-relative-alignment-and-mosaicing.html</id><summary type="html">&lt;p&gt;Relative alignment was performed by finding the peak of the
cross-correlation between images and a pointing master selected from the
epoch with the best-constrained pointing model for that field. Each
observation was initially mapped individually, then all observations of
a given field were cross-correlated with a selected master image of â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Relative alignment was performed by finding the peak of the
cross-correlation between images and a pointing master selected from the
epoch with the best-constrained pointing model for that field. Each
observation was initially mapped individually, then all observations of
a given field were cross-correlated with a selected master image of that
field. The cross-correlation peak was fit with a gaussian and the
difference between the gaussian peak and the image center was used as
the pixel offset. The offsets were recorded and written to the
timestreams. Finally, all observations of a field were merged into a
single timestream with pointing offsets applied to create the field
mosaic.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="methods paper"></category></entry><entry><title>a bunch of plots</title><link href="https://keflavich.github.io/blog/a-bunch-of-plots.html" rel="alternate"></link><published>2009-03-03T01:06:00-07:00</published><updated>2009-03-03T01:06:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-03-03:/blog/a-bunch-of-plots.html</id><content type="html">&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/SayCk8uDT2I/AAAAAAAAEzE/hVCHxfejfxk/s400/noise_per_deg.png" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/SayCkyW19KI/AAAAAAAAEy8/Df_SgR-blY4/s400/fillfact_per_deg.png" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/SayCk9BDNzI/AAAAAAAAEy0/oBgJX2IWav8/s400/mean_per_deg.png" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SayCksjhWmI/AAAAAAAAEys/vt0ZUY50Uqw/s400/sources_per_deg.png" /&gt;
&lt;p&gt;I wasted a lot of time making these so I figured I might as well waste a
little space showing them.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="plots"></category></entry><entry><title>A new series of problems</title><link href="https://keflavich.github.io/blog/a-new-series-of-problems.html" rel="alternate"></link><published>2009-03-03T00:52:00-07:00</published><updated>2009-03-03T00:52:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-03-03:/blog/a-new-series-of-problems.html</id><summary type="html">&lt;ol class="arabic simple"&gt;
&lt;li&gt;There are severe (~5 pixel) pointing offsets in the MOSAICs. They are
caused by IRAF and I can't figure out exactly why.&lt;/li&gt;
&lt;li&gt;Deconvolution has created more artifacts at l=54, 70, 357. I don't
know how to fix them.&lt;/li&gt;
&lt;li&gt;Either my earlier time estimates were way off, or the mapping â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;ol class="arabic simple"&gt;
&lt;li&gt;There are severe (~5 pixel) pointing offsets in the MOSAICs. They are
caused by IRAF and I can't figure out exactly why.&lt;/li&gt;
&lt;li&gt;Deconvolution has created more artifacts at l=54, 70, 357. I don't
know how to fix them.&lt;/li&gt;
&lt;li&gt;Either my earlier time estimates were way off, or the mapping has
gotten slower. It now takes ~120 computer hours (72 real hours) where
before it was taking closer to 48.&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Return to Deconvolution</title><link href="https://keflavich.github.io/blog/return-to-deconvolution.html" rel="alternate"></link><published>2009-02-23T18:55:00-07:00</published><updated>2009-02-23T18:55:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-02-23:/blog/return-to-deconvolution.html</id><summary type="html">&lt;p&gt;I ran the v0.7 reductions with deconvolution on for 50 iterations. I had
cut out deconvolution originally because of the funky noise maps, but
that was partly an error on my part. There is also an issue with bright
sources being largely left over in the noise maps.
The â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I ran the v0.7 reductions with deconvolution on for 50 iterations. I had
cut out deconvolution originally because of the funky noise maps, but
that was partly an error on my part. There is also an issue with bright
sources being largely left over in the noise maps.
The deconvolver does MUCH better at filtering out the fuzzy atmospheric
emission, so I want to use it. It leaves some flux from bright point
sources behind, though, so I decided to try to make the deconvolution
kernel smaller to see if that recovers more of the pointlike flux.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>planet fluxes</title><link href="https://keflavich.github.io/blog/planet-fluxes.html" rel="alternate"></link><published>2009-02-06T22:39:00-07:00</published><updated>2009-02-06T22:39:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-02-06:/blog/planet-fluxes.html</id><summary type="html">&lt;p&gt;; ephemerides from the JCMT
; MARS:
; June 30 2005: 730.14 Jy UT:53551
; July 15 2005: 872.83 Jy UT:53566
; Sept 10 2005: 1941.72 Jy UT:53623
; June 5 2006: 553.13 Jy UT:53891
; June 23 2006: 674.14 Jy UT:53544
; Sept 10 2006: 135.79 â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;; ephemerides from the JCMT
; MARS:
; June 30 2005: 730.14 Jy UT:53551
; July 15 2005: 872.83 Jy UT:53566
; Sept 10 2005: 1941.72 Jy UT:53623
; June 5 2006: 553.13 Jy UT:53891
; June 23 2006: 674.14 Jy UT:53544
; Sept 10 2006: 135.79 Jy UT:53896
; July 20 2007: 381.18 Jy UT:54301
; Sept 10 2007: 597.87 Jy UT:54353
;
; URANUS:
; June 30 2005: 43.43 Jy UT:53551
; July 15 2005: 44.35 Jy UT:53566
; Sept 10 2005: 45.78 Jy UT:53623
; June 5 2006: 41.71 Jy UT:53891
; June 23 2006: 42.96 Jy UT:53544
; Sept 10 2006: 41.62 Jy UT:53896
; July 20 2007: 43.90 Jy UT:54301
; Sept 10 2007: 45.57 Jy UT:54353
;
; NEPTUNE:
; June 30 2005: 17.42 Jy UT:53551
; July 15 2005: 17.58 Jy UT:53566
; Sept 10 2005: 17.50 Jy UT:53623
; June 5 2006: 17.04 Jy UT:53891
; June 23 2006: 17.33 Jy UT:53544
; Sept 10 2006: 17.09 Jy UT:53896
; July 20 2007: 17.59 Jy UT:54301
; Sept 10 2007: 17.56 Jy UT:54353&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>Rant: calc_beam_locations</title><link href="https://keflavich.github.io/blog/rant-calc_beam_locations.html" rel="alternate"></link><published>2009-02-06T18:24:00-07:00</published><updated>2009-02-06T18:24:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-02-06:/blog/rant-calc_beam_locations.html</id><summary type="html">&lt;p&gt;It took me a few days to figure this out, but &amp;quot;calc_beam_locations&amp;quot; is
about 800 lines of wasted space. It does nothing substantive until line
335. Everything to that point is parameter parsing. But there doesn't
need to be any of that crap, really, and it should have â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;It took me a few days to figure this out, but &amp;quot;calc_beam_locations&amp;quot; is
about 800 lines of wasted space. It does nothing substantive until line
335. Everything to that point is parameter parsing. But there doesn't
need to be any of that crap, really, and it should have been outsourced
to functions to begin with.
NCDF files are read to get the rotation angle - JUST as an error check!
There is no a priori reason to include it.
All that the code does is read in a centroid file (a list of x,y
offsets), rotate them, and output them as r,theta,error. Sure, there's a
bunch of automated outlier rejection etc, but... seriously?! We don't
have enough observations to hold up the statistics necessary for that to
begin with! NO ONE would if each observation takes an hour. It's absurd.
Odd as it is coming from me, manual rejection makes a lot more sense in
this case.
Now, I still have to understand WHY the beam locations are rotated by
the fiducial array angle.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>distortion mapping done?</title><link href="https://keflavich.github.io/blog/distortion-mapping-done.html" rel="alternate"></link><published>2009-02-02T00:12:00-07:00</published><updated>2009-02-02T00:12:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-02-02:/blog/distortion-mapping-done.html</id><content type="html">&lt;p&gt;Created 'beam_locations_0707.txt' from uranus_070702_o42 with a few
contributions from g34.3_070630_o34.
The rest were created by averaging over all of the beam location files&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>0707 distortion maps</title><link href="https://keflavich.github.io/blog/0707-distortion-maps.html" rel="alternate"></link><published>2009-02-01T20:26:00-07:00</published><updated>2009-02-01T20:26:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-02-01:/blog/0707-distortion-maps.html</id><content type="html">&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SYYFc97uFjI/AAAAAAAAEt0/nxjKDE_KBIA/s400/0707distmaps.png" /&gt;
&lt;p&gt;They're consistent but not very close to each other.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>beam locations &amp; peak fluxes</title><link href="https://keflavich.github.io/blog/beam-locations-peak-fluxes.html" rel="alternate"></link><published>2009-02-01T19:50:00-07:00</published><updated>2009-02-01T19:50:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-02-01:/blog/beam-locations-peak-fluxes.html</id><summary type="html">&lt;p&gt;The results of my distortion mapping work below. Note that, especially
for 06, there are a LOT of cases where no beam locations correction
(noBL) had a higher peak than the distortion corrected map. I have no
explanation for this yet. More work to come...&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PEAK COMPARISON BL:       5.95824 â€¦&lt;/pre&gt;</summary><content type="html">&lt;p&gt;The results of my distortion mapping work below. Note that, especially
for 06, there are a LOT of cases where no beam locations correction
(noBL) had a higher peak than the distortion corrected map. I have no
explanation for this yet. More work to come...&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PEAK COMPARISON BL:       5.95824  noBL:       3.09836    uranus_050619_o23 PEAK COMPARISON BL:       3.93725  noBL:       2.85479    uranus_050619_o24 PEAK COMPARISON BL:       15.5613  noBL:       523.035    neptune_050626_o19 PEAK COMPARISON BL:       16.4601  noBL:       16.0038    neptune_050626_o20 PEAK COMPARISON BL:       426.671  noBL:       375.174    mars_050627_o31 PEAK COMPARISON BL:       415.968  noBL:       413.327    mars_050627_o32  PEAK COMPARISON BL:       15.2464  noBL:       33.8593    uranus_050628_o33 PEAK COMPARISON BL:       34.6631  noBL:       35.5086    uranus_050628_o34 PEAK COMPARISON BL:       164.832  noBL:       403.189    uranus_050904_o31 PEAK COMPARISON BL:       216.820  noBL:       425.613    uranus_050904_o32 PEAK COMPARISON BL:       134.972  noBL:       156.196    uranus_050911_ob8 PEAK COMPARISON BL:       11.0957  noBL:       11.1993    neptune_060602_o30 PEAK COMPARISON BL:       12.0000  noBL:       11.0947    neptune_060602_o31 PEAK COMPARISON BL:       2478.20  noBL:       2365.17    mars_060605_ob1 PEAK COMPARISON BL:       2144.68  noBL:       2147.18    mars_060605_ob2  PEAK COMPARISON BL:       17.7354  noBL:       25.7041    uranus_060621_o29 PEAK COMPARISON BL:       18.7889  noBL:       25.6599    uranus_060621_o30 PEAK COMPARISON BL:       28.1957  noBL:       31.1013    uranus_060625_o46 PEAK COMPARISON BL:       23.0236  noBL:       27.8556    uranus_060905_ob6 PEAK COMPARISON BL:       18.8731  noBL:       28.4964    uranus_060906_o12 PEAK COMPARISON BL:       23.3481  noBL:       29.8294    uranus_060908_o13 PEAK COMPARISON BL:       20.6238  noBL:       26.9424    uranus_060909_o12 PEAK COMPARISON BL:       21.1049  noBL:       28.8533    uranus_060910_o12 PEAK COMPARISON BL:       24.0231  noBL:       32.0877    uranus_060914_o10 PEAK COMPARISON BL:       23.2590  noBL:       33.3496    uranus_060914_o11 PEAK COMPARISON BL:       24.0538  noBL:       30.0552    uranus_060919_ob9 PEAK COMPARISON BL:       355.467  noBL:       669.416    g34.3_070630_o34 PEAK COMPARISON BL:       246.803  noBL:       296.252    g34.3_070630_o35 PEAK COMPARISON BL:       724.874  noBL:       807.152    uranus_070702_o42 PEAK COMPARISON BL:       7.60370  noBL:       9.02960    uranus_070912_o27 PEAK COMPARISON BL:       98.8058  noBL:       88.9957    mars_070913_o22 PEAK COMPARISON BL:       82.2708  noBL:       89.3476    mars_070913_o23
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>sign errors</title><link href="https://keflavich.github.io/blog/sign-errors.html" rel="alternate"></link><published>2009-02-01T19:50:00-07:00</published><updated>2009-02-01T19:50:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-02-01:/blog/sign-errors.html</id><summary type="html">&lt;p&gt;pinned down the problem. Was a minor sign error in the offsets. Why is
it that simple sign errors are ALWAYS the hardest things to track down?
Now, open question: should x,y scaling be free parameters or not? What I
mean is, when I measure the positions of bolometers â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;pinned down the problem. Was a minor sign error in the offsets. Why is
it that simple sign errors are ALWAYS the hardest things to track down?
Now, open question: should x,y scaling be free parameters or not? What I
mean is, when I measure the positions of bolometers on the array using
the planet map, should I allow the X and Y stretch (the bolometer
spacing) to change? Should it be a uniform stretch in X and Y or should
it be allowed to 'distort' too? My opinion is, none of the above: I'm
measuring their actual positions (in terms of a fixed spacing) and
therefore stretching or distorting to match the nominal positions is not
necessary.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>BL/noBL Mars</title><link href="https://keflavich.github.io/blog/blnobl-mars.html" rel="alternate"></link><published>2009-02-01T03:22:00-07:00</published><updated>2009-02-01T03:22:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-02-01:/blog/blnobl-mars.html</id><summary type="html">&lt;p&gt;Mars using uranus_070702_o42 distortion map:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
BL070706_o38_raw_ds1.nc_indiv0    134.8757324     -0.2325330      0.0721872   3282.5439453      2.0985703      2.1959550   3147.6682129      2.3311033      2.1237679BL070706_o39_raw_ds1.nc_indiv0    188.0588379     -0.0947621     -0.0643225   3782.3984375      2.1416662      1.9909470   3594.3395996 â€¦&lt;/pre&gt;</summary><content type="html">&lt;p&gt;Mars using uranus_070702_o42 distortion map:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
BL070706_o38_raw_ds1.nc_indiv0    134.8757324     -0.2325330      0.0721872   3282.5439453      2.0985703      2.1959550   3147.6682129      2.3311033      2.1237679BL070706_o39_raw_ds1.nc_indiv0    188.0588379     -0.0947621     -0.0643225   3782.3984375      2.1416662      1.9909470   3594.3395996      2.2364283      2.0552695BL070706_o40_raw_ds1.nc_indiv0    451.6955566     -0.0427303     -0.3303463   3461.9191895      2.1925442      2.0726480   3010.2236328      2.2352746      2.4029944BL070713_o36_raw_ds1.nc_indiv0    294.5898438     -0.2068889      0.0493107   5975.9482422      1.9935303      2.1527038   5681.3583984      2.2004192      2.1033931BL070713_o37_raw_ds1.nc_indiv0    813.5678711     -0.4597032      0.0361557   5515.4501953      2.0334179      2.1772604   4701.8823242      2.4931211      2.1411047BL070713_o38_raw_ds1.nc_indiv0    286.2934570     -0.1904230      0.0520797   5967.7011719      1.9853363      2.1624830   5681.4077148      2.1757593      2.1104033BL070713_o39_raw_ds1.nc_indiv0    773.2104492     -0.0816238     -0.3387871   5409.8344727      2.0317609      2.1736624   4636.6240234      2.1133847      2.5124495BL070714_o76_raw_ds1.nc_indiv0    244.2031250     -0.2079357      0.0572422   5312.0419922      1.9982606      2.1597764   5067.8388672      2.2061963      2.1025343BL070714_o77_raw_ds1.nc_indiv0    688.7365723     -0.1176772     -0.3138330   4706.1503906      2.0379941      2.1989338   4017.4138184      2.1556714      2.5127668BL070715_o45_raw_ds1.nc_indiv0    108.5583496     -0.0652246     -0.0818899   2397.9819336      2.1608708      1.9907858   2289.4235840      2.2260954      2.0726757BL070715_o46_raw_ds1.nc_indiv0    268.4321289     -0.2927990     -0.0692098   2236.4533691      2.1387808      2.0159581   1968.0212402      2.4315798      2.0851679BL070717_o47_raw_ds1.nc_indiv0    372.6528320     -0.2188239      0.0690587   7070.0649414      1.9820960      2.1670835   6697.4121094      2.2009199      2.0980248BL070717_o48_raw_ds1.nc_indiv0    498.4628906     -0.2993519      0.0410304   6636.1396484      2.0418782      2.1088474   6137.6767578      2.3412302      2.0678170BL070718_o41_raw_ds1.nc_indiv0    287.1591797     -0.2016468      0.0641356   6684.1699219      1.9891322      2.1470959   6397.0107422      2.1907790      2.0829604BL070718_o42_raw_ds1.nc_indiv0    841.6083984     -0.0809386     -0.3511798   5934.2832031      2.0332539      2.1427581   5092.6748047      2.1141925      2.4939380BL070725_o34_raw_ds1.nc_indiv0    245.6381836     -0.0810674     -0.0582435   5918.6728516      1.9807132      2.1547492   5673.0346680      2.0617807      2.2129927BL070725_o35_raw_ds1.nc_indiv0    697.7910156      0.1512802     -0.6174591   4873.1469727      2.3222449      2.0499101   4175.3559570      2.1709647      2.6673691BL070726_o33_raw_ds1.nc_indiv0    216.2124023     -0.0697458     -0.0627950   5056.3364258      2.1531394      1.9873902   4840.1240234      2.2228851      2.0501852BL070726_o34_raw_ds1.nc_indiv0    433.0415039     -0.0154374     -0.3017542   4586.9204102      2.1483676      2.0385454   4153.8789062      2.1638050      2.3402996BL070730_o23_raw_ds1.nc_indiv0    105.4489746      0.1025155     -0.2241490   2679.8452148      2.1567283      1.9786894   2574.3962402      2.0542128      2.2028384BL070730_o24_raw_ds1.nc_indiv0    440.7482910     -0.3968222     -0.0447321   2595.1044922      2.0618360      2.1782801   2154.3562012      2.4586582      2.2230122
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>distortion mapping failures</title><link href="https://keflavich.github.io/blog/distortion-mapping-failures.html" rel="alternate"></link><published>2009-01-25T16:08:00-07:00</published><updated>2009-01-25T16:08:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-25:/blog/distortion-mapping-failures.html</id><content type="html">&lt;p&gt;So, despite the fact that I clearly have a distortion mapper working,
applying the distortion maps that come out of it do NOT improve the peak
or FWHM of the data.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>filling factors</title><link href="https://keflavich.github.io/blog/filling-factors.html" rel="alternate"></link><published>2009-01-25T06:00:00-07:00</published><updated>2009-01-25T06:00:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-25:/blog/filling-factors.html</id><content type="html">&lt;p&gt;to do: histogram per square degree, plot cumulative &amp;gt; some bin number
(100 mJy, 300 mJy, 1 Jy) vs l, then do it again for b=+/-.1, +/-.3.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="analysis"></category></entry><entry><title>distortion mapping</title><link href="https://keflavich.github.io/blog/distortion-mapping.html" rel="alternate"></link><published>2009-01-24T19:18:00-07:00</published><updated>2009-01-24T19:18:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-24:/blog/distortion-mapping.html</id><summary type="html">&lt;p&gt;Between sign errors, failures to fit, and.... I really don't know WHAT
was going on, I finally figured out how to get the cursed distortion
mapping to work. I still haven't even started testing, unfortunately.
I don't know why I can fit the way the OP did, fitting R and â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Between sign errors, failures to fit, and.... I really don't know WHAT
was going on, I finally figured out how to get the cursed distortion
mapping to work. I still haven't even started testing, unfortunately.
I don't know why I can fit the way the OP did, fitting R and Theta, and
I apparently can't fit x,y. It's frustrating.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="calibration"></category></entry><entry><title>Flagger images</title><link href="https://keflavich.github.io/blog/flagger-images.html" rel="alternate"></link><published>2009-01-17T16:13:00-07:00</published><updated>2009-01-17T16:13:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-17:/blog/flagger-images.html</id><summary type="html">&lt;p&gt;James requested sample images from the flagger for the methods paper.
Below are images + description:
.. image:: &lt;a class="reference external" href="http://3.bp.blogspot.com/_lsgW26mWZnU/SXHsZcqegtI/AAAAAAAAEs4/3PjUtU2IXtQ/s400/sample_waterfall_070911_o15_highFnoisepng.png"&gt;http://3.bp.blogspot.com/_lsgW26mWZnU/SXHsZcqegtI/AAAAAAAAEs4/3PjUtU2IXtQ/s400/sample_waterfall_070911_o15_highFnoisepng.png&lt;/a&gt;
This is a &amp;quot;noise-dominated&amp;quot; scan in the sense that the high/low pixels
are set by noise, not â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;James requested sample images from the flagger for the methods paper.
Below are images + description:
.. image:: &lt;a class="reference external" href="http://3.bp.blogspot.com/_lsgW26mWZnU/SXHsZcqegtI/AAAAAAAAEs4/3PjUtU2IXtQ/s400/sample_waterfall_070911_o15_highFnoisepng.png"&gt;http://3.bp.blogspot.com/_lsgW26mWZnU/SXHsZcqegtI/AAAAAAAAEs4/3PjUtU2IXtQ/s400/sample_waterfall_070911_o15_highFnoisepng.png&lt;/a&gt;
This is a &amp;quot;noise-dominated&amp;quot; scan in the sense that the high/low pixels
are set by noise, not signal. Despite the clear high frequency noise,
this image actually maps out pretty well - I think the high-noise
bolometers get downweighted and the high/low pixels probably get clipped
by my hot pixel rejection procedure.
.. image:: &lt;a class="reference external" href="http://3.bp.blogspot.com/_lsgW26mWZnU/SXHsY7Rgq3I/AAAAAAAAEsY/0NT8IB26JUo/s400/flagger_marked_source_050708_o15.png"&gt;http://3.bp.blogspot.com/_lsgW26mWZnU/SXHsY7Rgq3I/AAAAAAAAEsY/0NT8IB26JUo/s400/flagger_marked_source_050708_o15.png&lt;/a&gt;
An image of the galactic center with a source southeast of center
identified.
.. image:: &lt;a class="reference external" href="http://1.bp.blogspot.com/_lsgW26mWZnU/SXHsYyHCEGI/AAAAAAAAEsg/3iwoklY0--0/s400/sample_waterfall_050708_o15_glitchandsources.png"&gt;http://1.bp.blogspot.com/_lsgW26mWZnU/SXHsYyHCEGI/AAAAAAAAEsg/3iwoklY0--0/s400/sample_waterfall_050708_o15_glitchandsources.png&lt;/a&gt;
A scan from the GC image above. I forgot to mark the source, I should go
back and do that. The glitch is obvious.
.. image:: &lt;a class="reference external" href="http://1.bp.blogspot.com/_lsgW26mWZnU/SXHsZHVZ4OI/AAAAAAAAEso/pOXwGFn7rGg/s400/sample_waterfall_050708_o15_glitchflagged.png"&gt;http://1.bp.blogspot.com/_lsgW26mWZnU/SXHsZHVZ4OI/AAAAAAAAEso/pOXwGFn7rGg/s400/sample_waterfall_050708_o15_glitchflagged.png&lt;/a&gt;
I drew a box to flag out the region affected by the glitch.
.. image:: &lt;a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/SXHsZG_MmWI/AAAAAAAAEsw/RA6tqAWMnLM/s400/sample_waterfall_050708_o15_glitchgone.png"&gt;http://4.bp.blogspot.com/_lsgW26mWZnU/SXHsZG_MmWI/AAAAAAAAEsw/RA6tqAWMnLM/s400/sample_waterfall_050708_o15_glitchgone.png&lt;/a&gt;
This is what happens when I redraw after flagging out the glitch - the
colorbar is rescaled and no more glitch.
.. image:: &lt;a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/SXIDILh3hfI/AAAAAAAAEtQ/cMuOhlFO_fA/s400/sample_waterfall_050708_o15_glitchandsources_marked.png"&gt;http://4.bp.blogspot.com/_lsgW26mWZnU/SXIDILh3hfI/AAAAAAAAEtQ/cMuOhlFO_fA/s400/sample_waterfall_050708_o15_glitchandsources_marked.png&lt;/a&gt;
Timestream with glitches and sources marked (one pixel in the map is hit
by 3 different points in this scan).
.. image:: &lt;a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/SXIDH3uIjHI/AAAAAAAAEtI/vijTeEWf_nA/s400/sample_waterfall_050708_o15_glitchandsources_gray.png"&gt;http://4.bp.blogspot.com/_lsgW26mWZnU/SXIDH3uIjHI/AAAAAAAAEtI/vijTeEWf_nA/s400/sample_waterfall_050708_o15_glitchandsources_gray.png&lt;/a&gt;
Grayscale version of above (ok, I lied about grayscale being impossible)
with a different pixel marked.
.. image:: &lt;a class="reference external" href="http://1.bp.blogspot.com/_lsgW26mWZnU/SXIDHbYLbiI/AAAAAAAAEtA/nSh2rM6GhMc/s400/flagger_marked_source_footprint_050708_o15.png"&gt;http://1.bp.blogspot.com/_lsgW26mWZnU/SXIDHbYLbiI/AAAAAAAAEtA/nSh2rM6GhMc/s400/flagger_marked_source_footprint_050708_o15.png&lt;/a&gt;
A zoom-in around the 'kidney bean' source with the Bolocam footprint
overlaid and a pixel marked. Note that this pixel corresponds to the 3
points in the color waterfall above.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="methods paper"></category><category term="flagging"></category></entry><entry><title>0709 rotators fixed, latest run</title><link href="https://keflavich.github.io/blog/0709-rotators-fixed-latest-run.html" rel="alternate"></link><published>2009-01-17T14:26:00-07:00</published><updated>2009-01-17T14:26:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-17:/blog/0709-rotators-fixed-latest-run.html</id><summary type="html">&lt;p&gt;0709 11-13 needed to be 83.88 degrees, they're all fixed now.
I flagged the l060 070911 maps; I'm not convinced that was weather,
there were some fluctuations up to 2400 Jy! Maybe a cloud would do that
though.&lt;/p&gt;
&lt;p&gt;Problems in the latest run:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
l359 - missing files?
Reading files from â€¦&lt;/pre&gt;</summary><content type="html">&lt;p&gt;0709 11-13 needed to be 83.88 degrees, they're all fixed now.
I flagged the l060 070911 maps; I'm not convinced that was weather,
there were some fluctuations up to 2400 Jy! Maybe a cloud would do that
though.&lt;/p&gt;
&lt;p&gt;Problems in the latest run:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
l359 - missing files?
Reading files from /scratch/sliced/INFILES/l359\_infile.txt
FIELD v0.7\_l359 BEGUN at Fri Jan 16 20:11:34 2009
MRDFITS: File access error
% HEULER: ERROR - First parameter must be a FITS header or astrometry
 structure
l012 - missing files?
% READFITS: ERROR - Unable to locate file
 /scratch/adam\_work/l012/060614\_o10\_raw\_ds5.nc\_indiv13pca\_map01.fi
 ts
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>More problem maps</title><link href="https://keflavich.github.io/blog/more-problem-maps.html" rel="alternate"></link><published>2009-01-16T02:29:00-07:00</published><updated>2009-01-16T02:29:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-16:/blog/more-problem-maps.html</id><content type="html">&lt;p&gt;the l060-l062 range has some severe noise problems and rotator issues.
They need to be fixed before release.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="maps"></category></entry><entry><title>Uh?</title><link href="https://keflavich.github.io/blog/uh.html" rel="alternate"></link><published>2009-01-15T18:22:00-07:00</published><updated>2009-01-15T18:22:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-15:/blog/uh.html</id><summary type="html">&lt;p&gt;I'm not sure the error reported yesterday is reproducible.
Tonight, I started a complete re-mapping of the entire survey. The new
mapping will include beam-smoothed maps and more complete header
parameters.
I need to re-check the L111 mapping. It looks like the region with NGC
7538 in it did alright â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm not sure the error reported yesterday is reproducible.
Tonight, I started a complete re-mapping of the entire survey. The new
mapping will include beam-smoothed maps and more complete header
parameters.
I need to re-check the L111 mapping. It looks like the region with NGC
7538 in it did alright, but the southeast region didn't do so well. The
combined maps are probably better than in any previous iteration,
though.
Tomorrow's tests will include L024 presumably.
It's time to get to work on this stuff. There is definitely a reasonably
efficient way to go through all of this stuff; the most difficult part
is post-facto error checking.
Here are some awk commands I found useful (the \'s are because of VI):
`` awk '{printf( $0); if ($2 != 0){ printf(&amp;quot; %4i%4i&amp;quot;,$4-443,$5-207) }; if($4!=0){printf(&amp;quot; %4i,%4i&amp;quot;,$2-272,$3-742)}; printf(&amp;quot;n&amp;quot;) }' align/l111_fitslist_shiftfind.txt``
&lt;tt class="docutils literal"&gt;awk '{print &lt;span class="pre"&gt;$6,$7}'&lt;/span&gt; align/l111_fitslist_shiftfind.txt &amp;gt; align/shifts_all_lb.txt&lt;/tt&gt;
One important point: I had to add a parameter to the header file to say
whether the current pointing model was used or not. It matters when
applying the offsets. Note that since I'm using the pointing model to
make all the individual maps, we actually have to stick with this
current set of pointing models for all coaligned maps.
The current models:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#   Definition of coefficientts:#   start/end mjd are the start/end modified Julian date of a given pointing model#   the 'a' coefficients are for the AZIMUTH OFFSET, the b coefficients are for the ZENITH ANGLE OFFSET#   a0/b0 are constants (e.g. the mean)#   [ab][12] are the 1st and 2nd coefficients of Azimuth.  They have been fiated to zero for most of#   the past year or three.#   [ab][34] are the 1st and 2nd coefficients of Zenith Angle.#   A 'pointing model' is therefore something like this:#   azoff = a0 + a3*alt + a4*alt^2#   altoff = b0 + b3*alt + b4*alt^2##   It is important that the start_mjd/end_mjd be in ascending order##   WARNING: LATER THAN JULY 2007 DEFAULTS TO JULY 2007 WHICH WILL PROBABLY RESULT IN ERRORS!#   I don't have a September 2007 model yet.##   start_mjd      end_mjd               a0              a1            a2              a3             a4                 b0             b1             b2             b3                b4       realdate      53522.5      53582.5       -9.2413685             0.0           0.0   -0.0066354359  -0.0015110883          7.0392221            0.0            0.0   -0.053635657    -0.00047042481       20050601      53614.5      53643.5        84.969583             0.0           0.0      -2.4339154    0.016300937          126.00164            0.0            0.0     -2.4424431       0.015455417       20050901      53887.5      53947.5        9.5305281             0.0           0.0    -0.053191181  -0.0029300592         0.13425019            0.0            0.0     0.48160040     -0.0092814256       20060601      53979.5      54008.5       -98.980381             0.0           0.0      0.65354164   -0.012414466          52.841380            0.0            0.0      1.6705743      -0.020893018       20060901      54101.5      54252.5       -99.078392             0.0           0.0        0.105270   -0.005943491          86.896333            0.0            0.0     0.54257415      -0.011919129       20070101      54252.5      54288         -103.03831             0.0           0.0      0.20972540  -0.0060336987          100.74491            0.0            0.0   0.0099012827     -0.0033331895       20070601#      54288        54313         -99.078392             0.0           0.0      0.10527000  -0.0059434911          86.896333            0.0            0.0     0.54257415      -0.011919129       20070707      54288        54313         -98.803883             0.0           0.0      0.11810246  -0.0051207995          91.720516            0.0            0.0     0.18953269      -0.0078189793       20070707      54313        54500         -99.078392             0.0           0.0      0.10527000  -0.0059434911          86.896333            0.0            0.0     0.54257415      -0.011919129       20070707mjd2date,53522.5 ,y,m,d &amp;amp; print,y,m,dmjd2date,53614.5 ,y,m,d &amp;amp; print,y,m,dmjd2date,53887.5 ,y,m,d &amp;amp; print,y,m,dmjd2date,53979.5 ,y,m,d &amp;amp; print,y,m,dmjd2date,54101.5 ,y,m,d &amp;amp; print,y,m,dmjd2date,54252.5 ,y,m,d &amp;amp; print,y,m,dmjd2date,54288   ,y,m,d &amp;amp; print,y,m,d
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="alignment"></category></entry><entry><title>New mapping procedure</title><link href="https://keflavich.github.io/blog/new-mapping-procedure.html" rel="alternate"></link><published>2009-01-15T18:21:00-07:00</published><updated>2009-01-15T18:21:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-15:/blog/new-mapping-procedure.html</id><summary type="html">&lt;p&gt;I cut down the number of maps made by the pipeline from 80 to 30 by
merging regions with severe overlap. I don't think this will result in
any net change in efficiency of the mapping process because a few of the
maps will go over to swap, but it â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I cut down the number of maps made by the pipeline from 80 to 30 by
merging regions with severe overlap. I don't think this will result in
any net change in efficiency of the mapping process because a few of the
maps will go over to swap, but it will reduce the amount of overlap /
noisy edges and make debugging simpler. It should also reduce hard drive
usage once I decide that I'm satisfied with the results and remove the
old (v0.6) redundant data.
As part of this process, the reference fields for coalignment have been
re-set to the v0.6.2 coadds + some (crappy) mosaics from v0.6.2 so that
we no longer need to rely on 3x1's for the alignment.
See /data/bgps/releases/v0.7/readme.txt for details (reproduced below)
Created 01/14/09
Version 0.7 does not exist yet. This is the 'release notes' indicating
what will change
-Overlapping redundant fields will be eliminated
Mapping of field name to area covered, followed by number of
observations
included:
gemob1: l189-l192 11 - 2 = 9
w5: l135-l138 46 = 46
l133: l133-l134 34 - 1 = 33
l111: l110-l111 88 = 88
l086: l085-l086 17 = 17
l082: l080-l084 33 = 33
l077: l075-l080 43 - 1 = 42
l072: l070-l074 10 - 2 = 8
l065: l059-l069 19 = 19
l055: l053-l058 10 - 1 = 9
l050: l048-l052 19 = 19
l045: l043-l047 20 - 4 = 16
l040: l038-l042 33 - 4 = 27
l035: l034-l037 53 = 53
l032: l031-l033 61 = 61
l030: l030 61 - 3 = 58
l029: l028-l029 53 - 4 = 49
l024: l021-l027 29 = 29
l018: l015-l021 29 - 3 = 26
l012: l011-l014 7 = 7
l009: l008-l010 11 = 11
l006: l005-l007 15 - 1 = 14
l003: l002-l004 25 - 1 = 24
l001: l001 20 = 20
l000: l000 23 - 1 = 23
l359: l359 14 = 14
l357: l356-l358 9 - 1 = 8
l354: l353-l355 3 = 3
l351: l350-l352 9 = 9&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Gem OB1</title><link href="https://keflavich.github.io/blog/gem-ob1.html" rel="alternate"></link><published>2009-01-14T23:49:00-07:00</published><updated>2009-01-14T23:49:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-14:/blog/gem-ob1.html</id><summary type="html">&lt;p&gt;With Miranda's help, I discovered some serious errors in Gem OB1 and
fixed them.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;L189 was using L134 data for no apparent reason&lt;/li&gt;
&lt;li&gt;many September 2007 observations have the WRONG rotation angle in
place in array_params! Unfortunately it's not clear yet which ones
suffer from this problem: I need â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;With Miranda's help, I discovered some serious errors in Gem OB1 and
fixed them.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;L189 was using L134 data for no apparent reason&lt;/li&gt;
&lt;li&gt;many September 2007 observations have the WRONG rotation angle in
place in array_params! Unfortunately it's not clear yet which ones
suffer from this problem: I need a list of when rotangle was/was not
used, and it looks like it'll be a pain to fix the problem.&lt;/li&gt;
&lt;li&gt;GemOB1link wasn't mapped, it will be now.&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Back to work</title><link href="https://keflavich.github.io/blog/back-to-work.html" rel="alternate"></link><published>2009-01-13T16:45:00-07:00</published><updated>2009-01-13T16:45:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2009-01-13:/blog/back-to-work.html</id><summary type="html">&lt;p&gt;I started working again yesterday, mostly looking at the 31PCA
reductions I did. I have no strong opinions yet on their quality.
It's time to work towards a final data release, though, and to that end,
I'm going to start removing duplicate fields. e.g. l023 and l024 have
identical â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I started working again yesterday, mostly looking at the 31PCA
reductions I did. I have no strong opinions yet on their quality.
It's time to work towards a final data release, though, and to that end,
I'm going to start removing duplicate fields. e.g. l023 and l024 have
identical data, so only one of them should ever be used.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="data release"></category></entry><entry><title>L111 observation notes</title><link href="https://keflavich.github.io/blog/l111-observation-notes.html" rel="alternate"></link><published>2008-12-09T11:40:00-07:00</published><updated>2008-12-09T11:40:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-12-09:/blog/l111-observation-notes.html</id><summary type="html">&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SJZ5AakkcMI/AAAAAAAADL4/BV6bqAe26oc/s320/l111_sep05_noptgmdl_fixedoffset.jpg" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SJZ5ArDzBhI/AAAAAAAADMA/Qa6nxqshl7Y/s320/l111_sep05_rawcsoptg.jpg" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/SJZ5Avg041I/AAAAAAAADMI/flj9idr7F54/s320/l111_sep05_ptgapplied.jpg" /&gt;
&lt;p&gt;In L111, the failures noted in the &lt;a class="reference external" href="http://bolocam.blogspot.com/2008/08/pointing-model-failure.html"&gt;previous post&lt;/a&gt; are specific to
September 2005. By comparing the pointing model images to the &amp;quot;raw cso
pointing&amp;quot; and &amp;quot;no pointing model&amp;quot; (the latter still have FAZO/FZAO
applied, all that has been done to them is aberration/nutation and
precession correction) it â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SJZ5AakkcMI/AAAAAAAADL4/BV6bqAe26oc/s320/l111_sep05_noptgmdl_fixedoffset.jpg" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SJZ5ArDzBhI/AAAAAAAADMA/Qa6nxqshl7Y/s320/l111_sep05_rawcsoptg.jpg" /&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/SJZ5Avg041I/AAAAAAAADMI/flj9idr7F54/s320/l111_sep05_ptgapplied.jpg" /&gt;
&lt;p&gt;In L111, the failures noted in the &lt;a class="reference external" href="http://bolocam.blogspot.com/2008/08/pointing-model-failure.html"&gt;previous post&lt;/a&gt; are specific to
September 2005. By comparing the pointing model images to the &amp;quot;raw cso
pointing&amp;quot; and &amp;quot;no pointing model&amp;quot; (the latter still have FAZO/FZAO
applied, all that has been done to them is aberration/nutation and
precession correction) it appears that the Sep 05 model is simply wrong.
I haven't had time to check on W3/4/5 and L033, but presumably they have
a similar issue. W3/4/5 includes late July 07 and September 06. L033
includes July 05, June 06, and July 07. I will need to generate pointing
plots for September 05 and 06, and probably regenerate June 06. I have
the rest and I think Meredith's models are fine for those dates - they
certainly don't create recognizable errors in the maps.
It is possible that my pointing_model.pro has some pointing models (the
problematic ones) entered incorrectly. It would be nice to get those
double-checked.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Pointing model failure</title><link href="https://keflavich.github.io/blog/pointing-model-failure.html" rel="alternate"></link><published>2008-12-09T11:40:00-07:00</published><updated>2008-12-09T11:40:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-12-09:/blog/pointing-model-failure.html</id><summary type="html">&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SJXjh0a_cRI/AAAAAAAADBM/J3qzKAdvAE8/s320/l033_pointingmodel_failure.jpg" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SJXjiJuyDoI/AAAAAAAADBU/mVcnF0BNdFM/s320/l111_pointingmodel_failure.jpeg" /&gt;
&lt;p&gt;I attempted to map L111, L033, and W3/4/5 with the pointing model
corrections applied. That was a failure. Two images are attached to
illustrate the problem - relative pointing is clearly not correct
(middle of L33, bottom left of L111).
So.... possibilities:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Pointing models are incorrect&lt;/li&gt;
&lt;li&gt;Pointing model signs â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SJXjh0a_cRI/AAAAAAAADBM/J3qzKAdvAE8/s320/l033_pointingmodel_failure.jpg" /&gt;
&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SJXjiJuyDoI/AAAAAAAADBU/mVcnF0BNdFM/s320/l111_pointingmodel_failure.jpeg" /&gt;
&lt;p&gt;I attempted to map L111, L033, and W3/4/5 with the pointing model
corrections applied. That was a failure. Two images are attached to
illustrate the problem - relative pointing is clearly not correct
(middle of L33, bottom left of L111).
So.... possibilities:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Pointing models are incorrect&lt;/li&gt;
&lt;li&gt;Pointing model signs have been misinterpreted (don't think this one
is possible based on other graphs)&lt;/li&gt;
&lt;li&gt;Uhh... ideas?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Next step, I'll use the individual maps with no ptg mdl and find out
what the offsets should be....&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category><category term="mapping"></category></entry><entry><title>Deconvolution vs. Not</title><link href="https://keflavich.github.io/blog/deconvolution-vs-not.html" rel="alternate"></link><published>2008-11-28T19:39:00-07:00</published><updated>2008-11-28T19:39:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-28:/blog/deconvolution-vs-not.html</id><summary type="html">&lt;p&gt;I've done some by-eye comparisons of deconvolutions vs no deconvolution.
The no-deconvolution clearly does better on the bright sources: probably
the deconvolved beam size is a little bit different from (larger?
smaller?) the actual source size. Deconvolution does better in putting
noise from noisy regions into the noisemap and keeping â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've done some by-eye comparisons of deconvolutions vs no deconvolution.
The no-deconvolution clearly does better on the bright sources: probably
the deconvolved beam size is a little bit different from (larger?
smaller?) the actual source size. Deconvolution does better in putting
noise from noisy regions into the noisemap and keeping it out of the
astromap.
Both might be useful - the deconvolved maps may end up being prettier,
but the no-deconvolve maps will probably have more reliable fluxes.
This all probably relies on testing / simulation.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>4 errors</title><link href="https://keflavich.github.io/blog/4-errors.html" rel="alternate"></link><published>2008-11-28T16:46:00-07:00</published><updated>2008-11-28T16:46:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-28:/blog/4-errors.html</id><content type="html">&lt;p&gt;l047, l083, l359 (l000 is in /usb, l359 is in /scratch), l136p15
Only 83 is a code error, the others are file location errors. l083 is an
error in 'pixshift' with subscripting and will require real debugging.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="errors"></category></entry><entry><title>def_user_common modified</title><link href="https://keflavich.github.io/blog/def_user_common-modified.html" rel="alternate"></link><published>2008-11-23T15:21:00-07:00</published><updated>2008-11-23T15:21:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-23:/blog/def_user_common-modified.html</id><summary type="html">&lt;p&gt;The NP doesn't work without USER_COMMON defined because at a single
point it makes use of the 'which' function.
def_user_common is a disaster, though, because it calls
get_screen_size(), which forces an X connection to be launched, which
means that if you start a remote session â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The NP doesn't work without USER_COMMON defined because at a single
point it makes use of the 'which' function.
def_user_common is a disaster, though, because it calls
get_screen_size(), which forces an X connection to be launched, which
means that if you start a remote session and close X IDL crashes. This
has been a constant nagging problem and has cost me ~a few days of work.
So I commented out the offending (and offensive) line. The worst of it
is, I'm not even convinced there's anything that uses any of that
information. The common block is only needed to get paths, so which
could have been written better.
The pipeline ground to a halt for an unknown reason at an unknown point
so I added a lot more timing outputs to try to figure out what's going
on.
Back to the grind...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>flagger</title><link href="https://keflavich.github.io/blog/flagger.html" rel="alternate"></link><published>2008-11-22T01:37:00-07:00</published><updated>2008-11-22T01:37:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-22:/blog/flagger.html</id><summary type="html">&lt;p&gt;Discovered that the flagger causes some pretty serious problems if you
try to run it on a non-coadd for obvious reasons: there's practically no
coverage! Individual maps should NOT go through the flagger, so I have
added a piece of code that turns off the flagger if only one observation â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Discovered that the flagger causes some pretty serious problems if you
try to run it on a non-coadd for obvious reasons: there's practically no
coverage! Individual maps should NOT go through the flagger, so I have
added a piece of code that turns off the flagger if only one observation
is being used. That code is in map_iter where the flagger is called.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="flagging"></category></entry><entry><title>v0.6.1 done</title><link href="https://keflavich.github.io/blog/v061-done.html" rel="alternate"></link><published>2008-11-21T02:42:00-07:00</published><updated>2008-11-21T02:42:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-21:/blog/v061-done.html</id><content type="html"></content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Version 0.6 begun</title><link href="https://keflavich.github.io/blog/version-06-begun.html" rel="alternate"></link><published>2008-11-19T04:52:00-07:00</published><updated>2008-11-19T04:52:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-19:/blog/version-06-begun.html</id><content type="html">&lt;p&gt;I started on (what I hope will be) v0.6 tonight.
New things:
-Sigma-rejection flagging in the spatial domain
-Inverse-variance weighting&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>MAD flagger</title><link href="https://keflavich.github.io/blog/mad-flagger.html" rel="alternate"></link><published>2008-11-19T04:50:00-07:00</published><updated>2008-11-19T04:50:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-19:/blog/mad-flagger.html</id><summary type="html">&lt;pre class="literal-block"&gt;
; The Mad Flagger; Flag based on the median average deviation within a spatial pixelfunction mad_flagger,data,inds,flags,nsig=nsig    t = systime(/sec)    f0 = total(where(flags))    if n_e(nsig) eq 0 then nsig = 3            newflags = flags    mx=max(inds)    vec3=fltarr(mx+1)    h=histogram(inds,reverse â€¦&lt;/pre&gt;</summary><content type="html">&lt;pre class="literal-block"&gt;
; The Mad Flagger; Flag based on the median average deviation within a spatial pixelfunction mad_flagger,data,inds,flags,nsig=nsig    t = systime(/sec)    f0 = total(where(flags))    if n_e(nsig) eq 0 then nsig = 3            newflags = flags    mx=max(inds)    vec3=fltarr(mx+1)    h=histogram(inds,reverse_indices=ri,OMIN=om)    for j=0L,n_elements(h)-1 do begin        if ri[j+1] gt ri[j] then begin            v_inds = [ri[ri[j]:ri[j+1]-1]]            if n_e(v_inds) gt 2 then begin                vec = data[v_inds];                vecmad = mad(vec)  ; the MAD is WAY too small!  I ended up rejecting 8% of points!                vecmad = stddev(vec)                vecmed = median(vec,/even)                madreject = where( (vec gt vecmed + nsig*vecmad) or (vec lt vecmed - nsig*vecmad) )                if (n_e(madreject) gt 0 and total(madreject)) gt 0 then begin                    reject_inds = v_inds[madreject]                    newflags[reject_inds] = 1                endif             endif        endif    endfor    print,&amp;quot;MAD flagger took &amp;quot;,strc(systime(/sec)-t),&amp;quot; seconds and flagged &amp;quot;,$        strc(round(total(where(newflags)) - f0)),' points'    return,newflagsend
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="flagging"></category></entry><entry><title>Median drizzling</title><link href="https://keflavich.github.io/blog/median-drizzling.html" rel="alternate"></link><published>2008-11-18T16:11:00-07:00</published><updated>2008-11-18T16:11:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-18:/blog/median-drizzling.html</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://groups.google.com/group/comp.lang.idl-pvwave/browse_thread/thread/762770933591238d"&gt;http://groups.google.com/group/comp.lang.idl-pvwave/browse_thread/thread/762770933591238d&lt;/a&gt;
Someone going by the name 'wox' introduced me to a spectacularly simple
drizzling algorithm for medianing. It will be a little less efficient
because it can't take advantage of some 'partial sum' tricks that the
average can, but â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a class="reference external" href="http://groups.google.com/group/comp.lang.idl-pvwave/browse_thread/thread/762770933591238d"&gt;http://groups.google.com/group/comp.lang.idl-pvwave/browse_thread/thread/762770933591238d&lt;/a&gt;
Someone going by the name 'wox' introduced me to a spectacularly simple
drizzling algorithm for medianing. It will be a little less efficient
because it can't take advantage of some 'partial sum' tricks that the
average can, but it will median over ALL data points, which is an
advantage.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Massive upgrades, new strategy?</title><link href="https://keflavich.github.io/blog/massive-upgrades-new-strategy.html" rel="alternate"></link><published>2008-11-18T04:01:00-07:00</published><updated>2008-11-18T04:01:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-18:/blog/massive-upgrades-new-strategy.html</id><summary type="html">&lt;p&gt;A few major things today:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;#. I renamed 'ts_to_map' to 'drizzle' and made 'ts_to_map' a wrapper
that will either median combine by scans (if passed the right keywords,
i.e. tstomapmedian and scans_info). This will reject cosmic rays much
more effectively than previously.
#. My extensive test â€¦&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;A few major things today:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;#. I renamed 'ts_to_map' to 'drizzle' and made 'ts_to_map' a wrapper
that will either median combine by scans (if passed the right keywords,
i.e. tstomapmedian and scans_info). This will reject cosmic rays much
more effectively than previously.
#. My extensive test runs on the 'weird' fields completed. Conclusions:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Deconvolution is DEFINITELY responsibly for the weird fuzzy effects&lt;/dt&gt;
&lt;dd&gt;seen esp. in l=33, l=2.&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Even a descending iterator is ineffective at alleviating this&lt;/dt&gt;
&lt;dd&gt;problem
What I still don't understand is WHY the deconvolver is behaving badly
for some regions. It is extracting peaks that are too high.&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Not deconvolving works pretty well, so I'm not really concerned. I'm&lt;/dt&gt;
&lt;dd&gt;resetting the defaults to no deconvolution once my next test is done....&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Started up a new test run to compare median stacking with weighted
average stacking&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>5x1?</title><link href="https://keflavich.github.io/blog/5x1.html" rel="alternate"></link><published>2008-11-17T16:32:00-07:00</published><updated>2008-11-17T16:32:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-17:/blog/5x1.html</id><content type="html">&lt;p&gt;060609_o17 is weird looking. It appears to be TWO 3x1s with an overlap,
but it's only 1 observation. Any idea what happened?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Weighting - next steps</title><link href="https://keflavich.github.io/blog/weighting-next-steps.html" rel="alternate"></link><published>2008-11-15T01:04:00-07:00</published><updated>2008-11-15T01:04:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-15:/blog/weighting-next-steps.html</id><summary type="html">&lt;p&gt;Idea: 'edge taper' for scans. The scan start/end usually has higher
noise, so it would be good to downweight those regions slightly.
Probably only the first/last 5% of each scan should be linearly
downweighted.
I'm running a lot of tests on l001 with/without deconvolution, lots of
iterations â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Idea: 'edge taper' for scans. The scan start/end usually has higher
noise, so it would be good to downweight those regions slightly.
Probably only the first/last 5% of each scan should be linearly
downweighted.
I'm running a lot of tests on l001 with/without deconvolution, lots of
iterations, different pca components. They'll be done sometime tomorrow.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Weighting and high-frequency noise</title><link href="https://keflavich.github.io/blog/weighting-and-high-frequency-noise.html" rel="alternate"></link><published>2008-11-15T00:41:00-07:00</published><updated>2008-11-15T00:41:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-15:/blog/weighting-and-high-frequency-noise.html</id><summary type="html">&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/SR4DzVCz1WI/AAAAAAAADfk/cJ70OPeqEzg/s400/psds.png" /&gt;
&lt;p&gt;Image of PSDs (with no normalization) of the raw (blue), delined and
exponential and polynomial subtracted (white), the noise timestream
(yellow), and the data (cyan).
The good: It looks like all of the powerline noise got into the noise
timestream and almost none in the data.
The bad: weighting is â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/SR4DzVCz1WI/AAAAAAAADfk/cJ70OPeqEzg/s400/psds.png" /&gt;
&lt;p&gt;Image of PSDs (with no normalization) of the raw (blue), delined and
exponential and polynomial subtracted (white), the noise timestream
(yellow), and the data (cyan).
The good: It looks like all of the powerline noise got into the noise
timestream and almost none in the data.
The bad: weighting is based on the noise timestream so it's possible
that the weights aren't quite right as a result
The weird: the data PSD. What's up with that? Apparently I'm
preferentially subtracting certain scales but I don't know why, unless
deconvolution is at fault.
Edit/Update: The deconvolution is definitely at fault. Here's the same
scan done without deconvolution:&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/SR4ZM6FPfrI/AAAAAAAADf0/baHOQwedeqs/s400/psds2.png" /&gt;
&lt;p&gt;It should have been obvious; the cyan in the first plot is the PSD of
the deconvolution straight up, and that should have no high-frequency
structure...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="weighting"></category></entry><entry><title>Paragraph for the methods paper</title><link href="https://keflavich.github.io/blog/paragraph-for-the-methods-paper.html" rel="alternate"></link><published>2008-11-15T00:25:00-07:00</published><updated>2008-11-15T00:25:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-15:/blog/paragraph-for-the-methods-paper.html</id><summary type="html">&lt;p&gt;The raw data from Bolocam contains noise components from the atmosphere
and instrument in addition to the astrophysical signal. To remove the
atmospheric noise, an iterative approach was required.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The median across all bolometers is subtracted&lt;/li&gt;
&lt;li&gt;A set number of principle components are subtracted. The principle
components are the most â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;The raw data from Bolocam contains noise components from the atmosphere
and instrument in addition to the astrophysical signal. To remove the
atmospheric noise, an iterative approach was required.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The median across all bolometers is subtracted&lt;/li&gt;
&lt;li&gt;A set number of principle components are subtracted. The principle
components are the most correlated components between bolometers. In
this process both the atmosphere above the telescope - which is
assumed to be constant across the field of view - and any large-scale
astrophysical structure are removed.&lt;/li&gt;
&lt;li&gt;The timestream data is mapped into the plane of the sky. Data points
are mapped to the nearest pixel. 7.2&amp;quot; pixels are used so that
sampling is better than Nyquist.&lt;/li&gt;
&lt;li&gt;The map is deconvolved using a maximum entropy deconvolution
algorithm ( Based on paper by Hollis, Dorband, Yusef-Zadeh, Ap.J.
Feb.1992, written by Frank Varosi at NASA/GSFC 1992)&lt;/li&gt;
&lt;li&gt;The deconvolved map is returned to a timestream and subtracted from
the original to yield a noise-only timestream.&lt;/li&gt;
&lt;li&gt;Power spectral densities are calculated for each scan in the noise
timestream, and weights are calculated from these. [At the moment,
the weights are actually inverse-variance]&lt;/li&gt;
&lt;li&gt;The deconvolved map timestream is subtracted from the raw timestream,
and then steps 1-6 are repeated on that timestream to recover flux
that was oversubtracted in the first iteration.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Convergence takes ???? iterations....
??? PCA components are subtracted [default 13]...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="methods paper"></category></entry><entry><title>Rewriting pipeline again</title><link href="https://keflavich.github.io/blog/rewriting-pipeline-again.html" rel="alternate"></link><published>2008-11-14T20:42:00-07:00</published><updated>2008-11-14T20:42:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-14:/blog/rewriting-pipeline-again.html</id><content type="html">&lt;p&gt;Not entirely, but I realized my code had become... clunky, at best.
I'm rewriting the wrappers using structs. I HATE IDL structs, but
they're necessary.... if only they would make them dynamically
modifiable.
Weighting worked to some degree, the mapping is pretty much done.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Implementing weighting</title><link href="https://keflavich.github.io/blog/implementing-weighting.html" rel="alternate"></link><published>2008-11-09T04:56:00-07:00</published><updated>2008-11-09T04:56:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-09:/blog/implementing-weighting.html</id><summary type="html">&lt;p&gt;Not as easy as it ought to be.
I think I need to do a few things:
1. check and make sure there are no more of those !&amp;#64;#$!&amp;#64;#$#&amp;#64;% different
sized array subtractions/multiplications. 'weight' and
'best_astro_model' need to have the same size &amp;amp; shape in mem_iter_pc
2 â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Not as easy as it ought to be.
I think I need to do a few things:
1. check and make sure there are no more of those !&amp;#64;#$!&amp;#64;#$#&amp;#64;% different
sized array subtractions/multiplications. 'weight' and
'best_astro_model' need to have the same size &amp;amp; shape in mem_iter_pc
2. I guess just check and make sure stuff works. The weighted mean I'm
using appears to be right: sum(weight * value) / sum(weight)
I hate making lists that end up being two items....&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="weighting"></category></entry><entry><title>l020 too</title><link href="https://keflavich.github.io/blog/l020-too.html" rel="alternate"></link><published>2008-11-09T04:10:00-07:00</published><updated>2008-11-09T04:10:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-09:/blog/l020-too.html</id><content type="html">&lt;p&gt;l020 too&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>redo targets:&lt;br&gt;l068&lt;br&gt;l086&lt;br&gt;l111&lt;br&gt;l027</title><link href="https://keflavich.github.io/blog/redo-targetsl068l086l111l027.html" rel="alternate"></link><published>2008-11-09T04:10:00-07:00</published><updated>2008-11-09T04:10:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-09:/blog/redo-targetsl068l086l111l027.html</id><content type="html">&lt;p&gt;redo targets:
l068
l086
l111
l027&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>the l111 reference field was 60% flagged out becau...</title><link href="https://keflavich.github.io/blog/the-l111-reference-field-was-60-flagged-out-becau.html" rel="alternate"></link><published>2008-11-09T04:04:00-07:00</published><updated>2008-11-09T04:04:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-09:/blog/the-l111-reference-field-was-60-flagged-out-becau.html</id><summary type="html">&lt;p&gt;the l111 reference field was 60% flagged out because of bad rotators:
ALL PREPROC ... output is&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/scratch/adam\_work/l111/060602\_o34\_raw\_ds5.nc\_indiv13pca READING IN
1 FILES FROM /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
Reading file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
Flagged â€¦&lt;/pre&gt;</summary><content type="html">&lt;p&gt;the l111 reference field was 60% flagged out because of bad rotators:
ALL PREPROC ... output is&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/scratch/adam\_work/l111/060602\_o34\_raw\_ds5.nc\_indiv13pca READING IN
1 FILES FROM /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
Reading file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
Flagged scan 2 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -23.2941
Flagged scan 6 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -24.9265
Flagged scan 7 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -21.3750
Flagged scan 8 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -25.7647
Flagged scan 9 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.110294
Flagged scan 10 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -26.6140
Flagged scan 11 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.143383
Flagged scan 12 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -27.4743
Flagged scan 14 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -28.3235
Flagged scan 15 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -24.6397
Flagged scan 17 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -25.4559
Flagged scan 18 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -30.0441
Flagged scan 19 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.110292
Flagged scan 21 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.220589
Flagged scan 22 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -31.8088
Flagged scan 23 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -27.9596
Flagged scan 24 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -32.7022
Flagged scan 26 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -33.5846
Flagged scan 28 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -34.4890
Flagged scan 30 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -35.3934
Flagged scan 31 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -31.3787
Flagged scan 33 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -0.231617
Flagged scan 34 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.121325
Flagged scan 36 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.132353
Flagged scan 38 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.209558
Flagged scan 39 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by -0.198528
Flagged scan 40 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.231617
Flagged scan 42 in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
 because rotangle changes by 0.121325
Did not find rpcfile /data/bgps/raw/rpc/20060602/20060602\_0811\_rpc.bin
for file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc
Applying pointing model with alt/az off -0.00023445157 -0.00016187002
NO OFFSETS APPLIED
Scans 2 6 7 8 9 10
 11 12 14 15 17 18
 19 21 22 23 24 26
 28 30 31 33 34 36
 38 39 40 42
 flagged in file /scratch/sliced/l111/060602\_o34\_raw\_ds5.nc because
of rotation
4.2049680 sec.
Total of 1947176 points flagged
AC\_BOLOS has 1.94718e+06 NAN points, which is 0.608696 of total
&lt;/pre&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>curiously, l135p1 has a reference field that is on...</title><link href="https://keflavich.github.io/blog/curiously-l135p1-has-a-reference-field-that-is-on.html" rel="alternate"></link><published>2008-11-09T03:59:00-07:00</published><updated>2008-11-09T03:59:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-09:/blog/curiously-l135p1-has-a-reference-field-that-is-on.html</id><content type="html">&lt;p&gt;curiously, l135p1 has a reference field that is only present in the
w3ohbolocam directory. Probably need to remake the infiles for all of
W3/4/5&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>I think l086 needs to be re-treated specially; it ...</title><link href="https://keflavich.github.io/blog/i-think-l086-needs-to-be-re-treated-specially-it.html" rel="alternate"></link><published>2008-11-09T03:55:00-07:00</published><updated>2008-11-09T03:55:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-09:/blog/i-think-l086-needs-to-be-re-treated-specially-it.html</id><content type="html">&lt;p&gt;I think l086 needs to be re-treated specially; it had way too many large
offsets. Probably the error that resulted was from an overlap region
smaller than itself....&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>/scratch/sliced/l354/070724_o10_raw_ds5.nc was the...</title><link href="https://keflavich.github.io/blog/scratchslicedl354070724_o10_raw_ds5nc-was-the.html" rel="alternate"></link><published>2008-11-09T03:49:00-07:00</published><updated>2008-11-09T03:49:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-09:/blog/scratchslicedl354070724_o10_raw_ds5nc-was-the.html</id><content type="html">&lt;p&gt;/scratch/sliced/l354/070724_o10_raw_ds5.nc was the reference file for
l354 but somehow was excluded from the l354_infile. Warrants another
check post-mapping&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>somehow /scratch/sliced_polychrome/l034/050708_o21...</title><link href="https://keflavich.github.io/blog/somehow-scratchsliced_polychromel034050708_o21.html" rel="alternate"></link><published>2008-11-09T03:25:00-07:00</published><updated>2008-11-09T03:25:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-09:/blog/somehow-scratchsliced_polychromel034050708_o21.html</id><content type="html">&lt;p&gt;somehow /scratch/sliced_polychrome/l034/050708_o21_raw_mmd_ds5.nc
got into the l033_infile and screwed things up&lt;/p&gt;
</content><category term="bgps"></category><category term="http://schemas.google.com/blogger/2008/kind#comment"></category></entry><entry><title>BGPS Photo</title><link href="https://keflavich.github.io/blog/bgps-photo.html" rel="alternate"></link><published>2008-11-06T07:29:00-07:00</published><updated>2008-11-06T07:29:00-07:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-11-06:/blog/bgps-photo.html</id><content type="html">&lt;p&gt;&lt;a class="reference external" href="http://www.nrao.edu/index.php/learn/gallery/imagecontest"&gt;http://www.nrao.edu/index.php/learn/gallery/imagecontest&lt;/a&gt;&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>New to-do list, updated things....</title><link href="https://keflavich.github.io/blog/new-to-do-list-updated-things.html" rel="alternate"></link><published>2008-10-15T12:57:00-06:00</published><updated>2008-10-15T12:57:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-10-15:/blog/new-to-do-list-updated-things.html</id><summary type="html">&lt;p&gt;&lt;tt class="docutils literal"&gt;do_maptests.pro&lt;/tt&gt; is running a bunch of different mapping parameters
(pca components, deconvolution, etc.) on l000, l002, l003, l033, l083.
We'll then run bolocat on it and look for the following:
-number of sources found
-flux in sources found as a function of n_pca
-size of sources as â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;tt class="docutils literal"&gt;do_maptests.pro&lt;/tt&gt; is running a bunch of different mapping parameters
(pca components, deconvolution, etc.) on l000, l002, l003, l033, l083.
We'll then run bolocat on it and look for the following:
-number of sources found
-flux in sources found as a function of n_pca
-size of sources as function of n_pca
-BADNESS, e.g. blurring / unremoved atmosphere / oversubtracted sources
&lt;tt class="docutils literal"&gt;bolocat2reg&lt;/tt&gt; makes a region file out of a bolocat catalog. I'd like
to make a separate ds9 region file that includes the actual pointing
error + the centroiding error rather than just the elliptical fit to a
given source; that will be more useful for finder charts.
My current goal is to get a nice set of images I can combine to release
as a poster to Jason Glenn's student who is making pretty posters for
publicity purposes; probably to promote CCAT. Umm.... I blame the late
hour for the alliteration.
That goal also means I've been using an IRAF task to do some mosaicing
(easier than writing the IDL code AGAIN):
&lt;tt class="docutils literal"&gt;mscstack l001_5pca_map09.fits,l002_5pca_map09.fits,l000_5pca_map09.fits,l359_5pca_map09.fits,l003_5pca_map09.fits&amp;nbsp; GCCOMBINE_5pca.fits &lt;span class="pre"&gt;lthresh=-1l001_13pca_map09_scuba_aligned.fits,l002_13pca_map09_scuba_aligned.fits,l000_13pca_map09_scuba_aligned.fits,l359_13pca_map09_scuba_aligned.fits,l003_13pca_map09_scuba_aligned.fits&lt;/span&gt;&amp;nbsp; GCCOMBINE.fits &lt;span class="pre"&gt;lthresh=-1mscstack&lt;/span&gt; l029_13pca_map09_scuba_aligned.fits,l030_13pca_map09_scuba_aligned.fits,l031_13pca_map09_scuba_aligned.fits,l032_13pca_map09_scuba_aligned.fits,l033_13pca_map09_scuba_aligned.fits,l034_13pca_map09_scuba_aligned.fits L33COMBINE.fits &lt;span class="pre"&gt;lthresh=-1&lt;/span&gt; hsig=5 lsig=5&lt;/tt&gt;&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category><category term="pipeline"></category></entry><entry><title>outer galaxy fields done</title><link href="https://keflavich.github.io/blog/outer-galaxy-fields-done.html" rel="alternate"></link><published>2008-10-13T14:47:00-06:00</published><updated>2008-10-13T14:47:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-10-13:/blog/outer-galaxy-fields-done.html</id><summary type="html">&lt;p&gt;they're small files
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;logs/log_101008_coalign.log:/scratch/adam_work/l059/l059_13pca&lt;/span&gt; took 286.08181 &lt;span class="pre"&gt;sec.logs/log_101008_coalign.log:/scratch/adam_work/l062/l062_13pca&lt;/span&gt; took 390.88015 &lt;span class="pre"&gt;sec.logs/log_101008_coalign.log:/scratch/adam_work/l065/l065_13pca&lt;/span&gt; took 296.88441 &lt;span class="pre"&gt;sec.logs/log â€¦&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;they're small files
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;logs/log_101008_coalign.log:/scratch/adam_work/l059/l059_13pca&lt;/span&gt; took 286.08181 &lt;span class="pre"&gt;sec.logs/log_101008_coalign.log:/scratch/adam_work/l062/l062_13pca&lt;/span&gt; took 390.88015 &lt;span class="pre"&gt;sec.logs/log_101008_coalign.log:/scratch/adam_work/l065/l065_13pca&lt;/span&gt; took 296.88441 &lt;span class="pre"&gt;sec.logs/log_101008_coalign.log:/scratch/adam_work/l068/l068_13pca&lt;/span&gt; took 1136.2623 &lt;span class="pre"&gt;sec.logs/log_101008_coalign.log:/scratch/adam_work/l071/l071_13pca&lt;/span&gt; took 899.41245 &lt;span class="pre"&gt;sec.logs/log_101208_coalign.log:/scratch/adam_work/l189p5/l189p5_13pca&lt;/span&gt; took 375.06840 &lt;span class="pre"&gt;sec.logs/log_101208_coalign.log:/scratch/adam_work/l192/l192_13pca&lt;/span&gt; took 403.81112 &lt;span class="pre"&gt;sec.logs/log_101208_coalign.log:/scratch/adam_work/l060/l060_13pca&lt;/span&gt; took 90.815500 &lt;span class="pre"&gt;sec.logs/log_101208_coalign.log:/scratch/adam_work/l069/l069_13pca&lt;/span&gt; took 160.17454 sec.&lt;/tt&gt;&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>flagging</title><link href="https://keflavich.github.io/blog/flagging.html" rel="alternate"></link><published>2008-10-08T04:31:00-06:00</published><updated>2008-10-08T04:31:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-10-08:/blog/flagging.html</id><content type="html">&lt;p&gt;most of what's left now is flagging. I updated the flagger,
flag_manual.pro. Check it out for documentation&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="flagging"></category></entry><entry><title>Maps with problems</title><link href="https://keflavich.github.io/blog/maps-with-problems.html" rel="alternate"></link><published>2008-09-17T14:46:00-06:00</published><updated>2008-09-17T14:46:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-17:/blog/maps-with-problems.html</id><content type="html">&lt;p&gt;l002: fuzzy stuff - bad sky sub?
l033: misalignment
l004: possible misalignment? Pattern recognition fails me here
l354: misalignment&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Mapping update</title><link href="https://keflavich.github.io/blog/mapping-update.html" rel="alternate"></link><published>2008-09-16T20:38:00-06:00</published><updated>2008-09-16T20:38:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-16:/blog/mapping-update.html</id><summary type="html">&lt;p&gt;I made a lot of mistakes in my script, so progress is about 12 computer
hours behind what it should be.
These maps are done:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/scratch/adam_work/l003/l003_13pca_map09.fits/scratch/adam_work/l006/l006_13pca_map09.fits/scratch/adam_work/l009/l009_13pca_map09.fits/scratch â€¦&lt;/pre&gt;</summary><content type="html">&lt;p&gt;I made a lot of mistakes in my script, so progress is about 12 computer
hours behind what it should be.
These maps are done:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/scratch/adam_work/l003/l003_13pca_map09.fits/scratch/adam_work/l006/l006_13pca_map09.fits/scratch/adam_work/l009/l009_13pca_map09.fits/scratch/adam_work/l018/l018_13pca_map09.fits/scratch/adam_work/l021/l021_13pca_map09.fits/scratch/adam_work/l024/l024_13pca_map09.fits/scratch/adam_work/l027/l027_13pca_map09.fits/scratch/adam_work/l030/l030_13pca_map09.fits/scratch/adam_work/l033/l033_13pca_map09.fits/scratch/adam_work/l036/l036_13pca_map09.fits/scratch/adam_work/l039/l039_13pca_map09.fits/scratch/adam_work/l042/l042_13pca_map09.fits/scratch/adam_work/l044/l044_13pca_map09.fits/scratch/adam_work/l048/l048_13pca_map09.fits/scratch/adam_work/l050/l050_13pca_map09.fits/scratch/adam_work/l054/l054_13pca_map09.fits/scratch/adam_work/l057/l057_13pca_map09.fits
&lt;/pre&gt;
&lt;p&gt;Things I've learned so far:
There is an observation (a master?) in L003 that should be the galactic
center master.
L018 has some really bad noise that needs fixing.
The wackiness I saw in L024 seems to be gone now.
L044 has the same noise stripes as L357.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/scratch/adam_work/l018/l018_13pca took 1118.3684 sec./scratch/adam_work/l018/l018_13pca_nooffs took 1106.6423 sec./scratch/adam_work/l021/l021_13pca took 1703.7266 sec./scratch/adam_work/l021/l021_13pca_nooffs took 1716.7393 sec./scratch/adam_work/l024/l024_13pca took 1622.3164 sec./scratch/adam_work/l024/l024_13pca_nooffs took 1672.3263 sec./scratch/adam_work/l027/l027_13pca took 1376.1939 sec./scratch/adam_work/l027/l027_13pca_nooffs took 1383.4335 sec./scratch/adam_work/l030/l030_13pca took 2487.1311 sec./scratch/adam_work/l030/l030_13pca_nooffs took 2543.1740 sec./scratch/adam_work/l036/l036_13pca took 549.76983 sec./scratch/adam_work/l036/l036_13pca_nooffs took 548.84132 sec./scratch/adam_work/l039/l039_13pca took 299.96889 sec./scratch/adam_work/l039/l039_13pca_nooffs took 299.16787 sec./scratch/adam_work/l042/l042_13pca took 366.34139 sec./scratch/adam_work/l042/l042_13pca_nooffs took 364.31475 sec./scratch/adam_work/l044/l044_13pca took 427.26923 sec./scratch/adam_work/l044/l044_13pca_nooffs took 424.42403 sec./scratch/adam_work/l048/l048_13pca took 313.86412 sec./scratch/adam_work/l048/l048_13pca_nooffs took 303.52545 sec./scratch/adam_work/l050/l050_13pca took 421.22899 sec./scratch/adam_work/l050/l050_13pca_nooffs took 477.16070 sec./scratch/adam_work/l054/l054_13pca took 315.14965 sec./scratch/adam_work/l054/l054_13pca_nooffs took 342.69137 sec.
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Scripting the Whole Survey</title><link href="https://keflavich.github.io/blog/scripting-the-whole-survey.html" rel="alternate"></link><published>2008-09-16T00:43:00-06:00</published><updated>2008-09-16T00:43:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-16:/blog/scripting-the-whole-survey.html</id><summary type="html">&lt;p&gt;First, discovered more fields with some sort of failure:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ls -d l[0-3][0-9][0-9] | sed 's:\(.*\):ls \1/*_map01.fits &amp;gt; \1/\1_infile.txt:' | bashls: l004/*_map01.fits: No such file or directoryls: l017/*_map01.fits: No such file or directoryls: l025/*_map01.fits: No such file or directoryls â€¦&lt;/pre&gt;</summary><content type="html">&lt;p&gt;First, discovered more fields with some sort of failure:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ls -d l[0-3][0-9][0-9] | sed 's:\(.*\):ls \1/*_map01.fits &amp;gt; \1/\1_infile.txt:' | bashls: l004/*_map01.fits: No such file or directoryls: l017/*_map01.fits: No such file or directoryls: l025/*_map01.fits: No such file or directoryls: l108/*_map01.fits: No such file or directoryls: l135/*_map01.fits: No such file or directoryls: l136/*_map01.fits: No such file or directoryls: l137/*_map01.fits: No such file or directoryls: l138/*_map01.fits: No such file or directoryls: l192/*_map01.fits: No such file or directory
&lt;/pre&gt;
&lt;p&gt;Also, that command was a total screwup.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ls -d l[0-3][0-9][0-9] | sed 's:\(.*\):ls /scratch/adam_work/\1/*_map01.fits &amp;gt; \1/\1_fitslist.txt:' | bashls: /scratch/adam_work/l004/*_map01.fits: No such file or directoryls: /scratch/adam_work/l017/*_map01.fits: No such file or directorybash: line 12: l020/l020_fitslist.txt: Permission deniedls: /scratch/adam_work/l025/*_map01.fits: No such file or directoryls: /scratch/adam_work/l108/*_map01.fits: No such file or directoryls: /scratch/adam_work/l135/*_map01.fits: No such file or directoryls: /scratch/adam_work/l136/*_map01.fits: No such file or directoryls: /scratch/adam_work/l137/*_map01.fits: No such file or directoryls: /scratch/adam_work/l138/*_map01.fits: No such file or directoryls: /scratch/adam_work/l192/*_map01.fits: No such file or directory
&lt;/pre&gt;
&lt;p&gt;Now that those files exist, it should be possible to run a set of
super-scripts like this:
coalign_field,'l057','070719_o29',sliced_dir='sliced_polychrome',premap=0
coalign_field,'l351','070725_ob3'
coalign_field,'l354','070724_o10'
coalign_field,'l357','070724_ob3'
coalign_field,'l000','070719_o14'
coalign_field,'l003','070718_o16'
coalign_field,'l006','070715_ob5'
coalign_field,'l009','070717_ob5'
coalign_field,'l012','070715_o10'
coalign_field,'l015','070714_o36'
coalign_field,'l018','070717_o10'
coalign_field,'l021','070715_o15'
coalign_field,'l024','070717_o15'
coalign_field,'l027','070715_o20'
coalign_field,'l030','070717_o20'
coalign_field,'l033','070718_ob5',sliced_dir='sliced_polychrome'
coalign_field,'l036','070715_o25',sliced_dir='sliced_polychrome'
coalign_field,'l039','070717_o25',sliced_dir='sliced_polychrome'
coalign_field,'l042','070715_o30',sliced_dir='sliced_polychrome'
coalign_field,'l044','070718_o24',sliced_dir='sliced_polychrome'
coalign_field,'l048','070717_o30',sliced_dir='sliced_polychrome'
coalign_field,'l050','070718_o29',sliced_dir='sliced_polychrome'
coalign_field,'l054','070724_o28',sliced_dir='sliced_polychrome'
coalign_field,'l057','070719_o29',sliced_dir='sliced_polychrome'
where premap=0 means I'm not re-mapping the whole field, the
sliced_dir='slice_polychrome' keyword is for those fields that do not
have a regular sliced directory.
This kind of thing ought to be really, really helpful when mapping the
fields whose masters are not in the field: I'll have to modify the
'coalign_field' code to search in a different directory, though.
Yearghhh.... last command was bad too.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ls -d l[0-3][0-9][0-9] | sed 's:\(.*\):ls /scratch/adam_work/\1/0*_map01.fits &amp;gt; \1/\1_fitslist.txt:' | bashls: /scratch/adam_work/l004/0*_map01.fits: No such file or directoryls: /scratch/adam_work/l017/0*_map01.fits: No such file or directorybash: line 12: l020/l020_fitslist.txt: Permission deniedls: /scratch/adam_work/l025/0*_map01.fits: No such file or directoryls: /scratch/adam_work/l108/0*_map01.fits: No such file or directoryls: /scratch/adam_work/l135/0*_map01.fits: No such file or directoryls: /scratch/adam_work/l136/0*_map01.fits: No such file or directoryls: /scratch/adam_work/l137/0*_map01.fits: No such file or directoryls: /scratch/adam_work/l138/0*_map01.fits: No such file or directoryls: /scratch/adam_work/l192/0*_map01.fits: No such file or directory
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="alignment"></category><category term="mapping"></category><category term="pipeline"></category></entry><entry><title>Alignment success stories</title><link href="https://keflavich.github.io/blog/alignment-success-stories.html" rel="alternate"></link><published>2008-09-15T04:33:00-06:00</published><updated>2008-09-15T04:33:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-15:/blog/alignment-success-stories.html</id><content type="html">&lt;img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/SM3ki00LXOI/AAAAAAAADYA/5izD0hrve40/s400/l111_align_success.jpg" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/SM3krUz_JTI/AAAAAAAADYI/uzayPOqbiss/s400/l024_align_success.jpg" /&gt;
&lt;img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/SM3krkSjAGI/AAAAAAAADYQ/ZOoWxknrDDA/s400/l024_align_failure.jpg" /&gt;
&lt;p&gt;Two success stories, one failure story.&lt;/p&gt;
&lt;p&gt;Successes: L111, L024. On the left is the aligned map, on the right the
unaligned map.&lt;/p&gt;
&lt;p&gt;Failure: L024. What's going on here? Is it an issue of that noisy
observation, or the fact that we're using a 5x1 (I think?) as a
reference?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="alignment"></category></entry><entry><title>Progress on alignment, ideas for the next few steps</title><link href="https://keflavich.github.io/blog/progress-on-alignment-ideas-for-the-next-few-steps.html" rel="alternate"></link><published>2008-09-15T02:19:00-06:00</published><updated>2008-09-15T02:19:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-15:/blog/progress-on-alignment-ideas-for-the-next-few-steps.html</id><summary type="html">&lt;p&gt;Alignment: I did a more thorough test of the aligner, and found an error
that was getting me the wrong results. I'm still getting distinctly
different results than I got with imalign, but I'm not convinced they're
wrong. One problem I have to deal with is the ambiguity between pointing â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Alignment: I did a more thorough test of the aligner, and found an error
that was getting me the wrong results. I'm still getting distinctly
different results than I got with imalign, but I'm not convinced they're
wrong. One problem I have to deal with is the ambiguity between pointing
model applied / no pointing model applied. In retrospect, I should have
done ALL of the maps with no pointing model: it would be simpler to
maintain a self-consistent set of alignment corrections.
However, since that isn't what I did - and there isn't enough memory to
host both data sets at the moment - I've dealt with the problem by
adding all of the offsets to the header. Hopefully now it will be
obvious if and what offsets have been applied, both pointing model and
'manual', from header keywords. Sadly, it was a pain to get that to work
- IDL's _extra does not work the same way as normal keyword passing,
which is disappointing and frustrating because it made me rename a lot
of variables that should not have been renamed.
IF this alignment fails to produce perfect results (which I don't really
expect to happen - it will just take time to debug), it is still a good
first step, and all we'd really need to do is use bolocat to pull out
sources from the reference image and then match those in the others,
doing the same thing imalign does. It wouldn't be difficult but it would
be time consuming to program.
Had a bunch of ideas during my insomnia last night, but I'm afraid I
forgot most of them...
One idea was related to the use of MAD as opposed to STDDEV: it may
allow for a more robust sigma-rejection for automated flagging. But
that's difficult.
Another thought was using the maps to auto-identify glitches. To do
this, I'd make a combined map and an individual map, hastrom them, and
subtract the combined from the individual. We could then probably pretty
easily spot any glitches; they should be the only outliers left, in
principle. I'll test that idea, but it actually looks less promising
than I'd hoped. Things are not coming out right in preliminary tests -
huge residuals.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Failed fields</title><link href="https://keflavich.github.io/blog/failed-fields.html" rel="alternate"></link><published>2008-09-13T21:00:00-06:00</published><updated>2008-09-13T21:00:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-13:/blog/failed-fields.html</id><summary type="html">&lt;ul class="simple"&gt;
&lt;li&gt;l030 - comments were in the form ;; instead of # in the infile&lt;/li&gt;
&lt;li&gt;l055 - no such folder&lt;/li&gt;
&lt;li&gt;l026 - no infile existed; made one&lt;/li&gt;
&lt;li&gt;l028 - /scratch/sliced_polychrome/l028/060605_o[**]_raw_ds5.nc
are bad&lt;/li&gt;
&lt;li&gt;l031 - Downsampling seems to have failed for most of this directory.
Need to downsample all files and â€¦&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;ul class="simple"&gt;
&lt;li&gt;l030 - comments were in the form ;; instead of # in the infile&lt;/li&gt;
&lt;li&gt;l055 - no such folder&lt;/li&gt;
&lt;li&gt;l026 - no infile existed; made one&lt;/li&gt;
&lt;li&gt;l028 - /scratch/sliced_polychrome/l028/060605_o[**]_raw_ds5.nc
are bad&lt;/li&gt;
&lt;li&gt;l031 - Downsampling seems to have failed for most of this directory.
Need to downsample all files and create a new infile&lt;/li&gt;
&lt;li&gt;l035 - /scratch/sliced_polychrome/l035/060605_o[**]_raw_ds5.nc
are bad - that's all 060605 observations of l035.&lt;/li&gt;
&lt;li&gt;l036 - /scratch/sliced_polychrome/l036/070702_o25_raw_ds5.nc,
/scratch/sliced_polychrome/l036/070705_o21_raw_ds5.nc are bad&lt;/li&gt;
&lt;li&gt;l038 - /scratch/sliced_polychrome/l038/060627_ob3_raw_ds5.nc,
/scratch/sliced_polychrome/l038/060627_ob[3567]_raw.nc are bad -
had to re-preprocess&lt;/li&gt;
&lt;li&gt;l054 - /scratch/sliced_polychrome/l054/070724_o25_raw_ds5.nc is
bad&lt;/li&gt;
&lt;li&gt;l057 - /scratch/sliced_polychrome/l057/070907_o16_raw_ds5.nc is
bad&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Except for l057, there is no guarantee that the whole observation is
bad, BUT the code failed on ncdf_open, so it possible the observation
turned bad during downsampling/preprocessing.
fixed: 30, 26, 55, 35, 28, 31, 38, 54, 57
so far all observations on 060605 are bad.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Disagreement over definition of l,b coordinates</title><link href="https://keflavich.github.io/blog/disagreement-over-definition-of-lb-coordinates.html" rel="alternate"></link><published>2008-09-10T22:43:00-06:00</published><updated>2008-09-10T22:43:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-10:/blog/disagreement-over-definition-of-lb-coordinates.html</id><summary type="html">&lt;p&gt;DS9 does something intuitive: cd0_0 and cd1_1 multiplied by the x,y
pixel difference gets you the new l,b coordinate. I think this is very
likely to be correct on the galactic plane. IDL does something
different. I don't know why different, or really how - it's buried â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;DS9 does something intuitive: cd0_0 and cd1_1 multiplied by the x,y
pixel difference gets you the new l,b coordinate. I think this is very
likely to be correct on the galactic plane. IDL does something
different. I don't know why different, or really how - it's buried
somewhere in wcsxy2sph - but it's definitely different. Which is right?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="projection"></category></entry><entry><title>Broken rotation</title><link href="https://keflavich.github.io/blog/broken-rotation.html" rel="alternate"></link><published>2008-09-09T01:34:00-06:00</published><updated>2008-09-09T01:34:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-09:/blog/broken-rotation.html</id><summary type="html">&lt;p&gt;I have to echo James in saying how remarkable it is than anything I ever
did worked at all! I'm growing more and more certain that I've been
double-correcting rotation for the past 2 months, and my maps don't look
all that bad!
.. image:: &lt;a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/SMW4oOPcLaI/AAAAAAAADXw/1ARG8iyVXDQ/s400/070717_o15_rotations.png"&gt;http://4.bp.blogspot.com/_lsgW26mWZnU â€¦&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have to echo James in saying how remarkable it is than anything I ever
did worked at all! I'm growing more and more certain that I've been
double-correcting rotation for the past 2 months, and my maps don't look
all that bad!
.. image:: &lt;a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/SMW4oOPcLaI/AAAAAAAADXw/1ARG8iyVXDQ/s400/070717_o15_rotations.png"&gt;http://4.bp.blogspot.com/_lsgW26mWZnU/SMW4oOPcLaI/AAAAAAAADXw/1ARG8iyVXDQ/s400/070717_o15_rotations.png&lt;/a&gt;
Image caption:
Top left - both PA and rotang
Top right - neither
Bottom left - rotang only
Bottom right - PA only
I'm running the same sort of comparison on all of the GC and L=24 data.
Check out /scratch/adam_work/ROT_TEST for the results. I'll be
updating this when I've completed that analysis.
Update 6:35 PM: !&amp;#64;#$, etc. New problem child:
.. image:: &lt;a class="reference external" href="http://1.bp.blogspot.com/_lsgW26mWZnU/SMXFUjLjRGI/AAAAAAAADX4/aynvuycRzGM/s400/060603_o16_rotations.png"&gt;http://1.bp.blogspot.com/_lsgW26mWZnU/SMXFUjLjRGI/AAAAAAAADX4/aynvuycRzGM/s400/060603_o16_rotations.png&lt;/a&gt;
Image caption (same as above, luckily):
Top left - both PA and rotang
Top right - neither
Bottom left - rotang only
Bottom right - PA only
So, can anyone tell me which one of THESE is right? Because I can't. Top
left is 'correct' except that it's not.
Update 7:10 PM: I compared adding/subtracting PA and RA, and I can say
this: subtracting PA never works. Adding/subtracting RA works variably.
I think I'm done testing parameter space. I haven't had very good luck
doing parameter space tests in the past; it usually is more beneficial
to take a step back and try to think through the problem.
Update 7:30 PM: Fixed. Much as this looks like a short-lived, easily
solved problem, it was one of the most subtle and insidious errors I've
made. I got extremely lucky that plotting PA and ROTANGLE happened to
spark off warning sirens in my mind about the positioning of the
variable names. I wouldn't normally look for that.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>fresh blood</title><link href="https://keflavich.github.io/blog/fresh-blood.html" rel="alternate"></link><published>2008-09-08T23:34:00-06:00</published><updated>2008-09-08T23:34:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-08:/blog/fresh-blood.html</id><content type="html">&lt;p&gt;hate to put it this way, but probably true - bolocam will eat us all.
Cara and Marc have both agreed to help out with alignment work. This is
good news! Next post will be bad news, just to compensate.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="team"></category></entry><entry><title>Alignment</title><link href="https://keflavich.github.io/blog/alignment.html" rel="alternate"></link><published>2008-09-06T18:32:00-06:00</published><updated>2008-09-06T18:32:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-06:/blog/alignment.html</id><summary type="html">&lt;p&gt;a few items...&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;I requested that pyraf be installed on milkyway. I don't really want
to deal with xgterm/xterm issues when remotely logging in.&lt;/li&gt;
&lt;li&gt;I'm writing up a 'script' on
&lt;a class="reference external" href="http://sites.google.com/site/bolocam/pipeline/alignment"&gt;http://sites.google.com/site/bolocam/pipeline/alignment&lt;/a&gt;. I believe
IRAF is capable of interacting with DS9 even if â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;a few items...&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;I requested that pyraf be installed on milkyway. I don't really want
to deal with xgterm/xterm issues when remotely logging in.&lt;/li&gt;
&lt;li&gt;I'm writing up a 'script' on
&lt;a class="reference external" href="http://sites.google.com/site/bolocam/pipeline/alignment"&gt;http://sites.google.com/site/bolocam/pipeline/alignment&lt;/a&gt;. I believe
IRAF is capable of interacting with DS9 even if images are not opened
from IRAF, which should allow you to circumvent the 9-frame limit.&lt;/li&gt;
&lt;li&gt;Most of the individual image fields are done now. There may be a few
stragglers, but those are ones that either didn't have an
_infile.txt or only had single observations. What do we do about
those fields? They'll be undersampled!&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>New code</title><link href="https://keflavich.github.io/blog/new-code.html" rel="alternate"></link><published>2008-09-05T21:00:00-06:00</published><updated>2008-09-05T21:00:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-05:/blog/new-code.html</id><summary type="html">&lt;p&gt;Done for the day after this (observing tonight)
two new procedures:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
alignment_offsets_to_ncdf.pro
calcoeffs_to_ncdf.pro
&lt;/pre&gt;
&lt;p&gt;they're really easy, very nearly one-liners. Once they've been used
once, you can just use ncdf_varput_scale
Modified keyword parameters in do_the_pointing: offsets will always be
applied â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Done for the day after this (observing tonight)
two new procedures:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
alignment_offsets_to_ncdf.pro
calcoeffs_to_ncdf.pro
&lt;/pre&gt;
&lt;p&gt;they're really easy, very nearly one-liners. Once they've been used
once, you can just use ncdf_varput_scale
Modified keyword parameters in do_the_pointing: offsets will always be
applied unless the keyword 'no_offsets' is passed into the code (or the
top-level wrapper). Since offsets default to zero, this should be OK.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Pointing model success</title><link href="https://keflavich.github.io/blog/pointing-model-success.html" rel="alternate"></link><published>2008-09-02T15:11:00-06:00</published><updated>2008-09-02T15:11:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-02:/blog/pointing-model-success.html</id><summary type="html">&lt;p&gt;/scratch/adam_work/plots/models_myptgmdl_0707.ps
Look at the left plots in #1 and #4, and ignore the red lines. The RMS
is 4.87 in alt, 3.51 in az, using all pointing observations in 0707
(i.e. not splitting it into part1/part2 or refining heavily â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;/scratch/adam_work/plots/models_myptgmdl_0707.ps
Look at the left plots in #1 and #4, and ignore the red lines. The RMS
is 4.87 in alt, 3.51 in az, using all pointing observations in 0707
(i.e. not splitting it into part1/part2 or refining heavily). Total is
6.003&amp;quot;, not bad.
I'm calling it quits on pointing refinement for the moment; I'm
satisfied using Meredith's pointing models to get science maps
co-aligned, then we'll use my model on the PPSes to get the pointing to
maximum precision.
Also, in the galactic center, the mapping works happily now. No more
silly problems with that.
It's time for a real Next Step. I think that means mapping nearly
everything. Well, here goes!&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category><category term="mapping"></category><category term="pipeline"></category></entry><entry><title>prepare_map issues</title><link href="https://keflavich.github.io/blog/prepare_map-issues.html" rel="alternate"></link><published>2008-09-01T16:31:00-06:00</published><updated>2008-09-01T16:31:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-09-01:/blog/prepare_map-issues.html</id><summary type="html">&lt;p&gt;The problem: There is a bulk offset that can range from small to ~22'
(largest observed so far) in the combined maps that is not present in
the individual maps.
Observations: I THINK the offset between ra/dec and l/b is most
pronounced when the map boundaries are most â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The problem: There is a bulk offset that can range from small to ~22'
(largest observed so far) in the combined maps that is not present in
the individual maps.
Observations: I THINK the offset between ra/dec and l/b is most
pronounced when the map boundaries are most different.
We have been putting CRPIX in the middle of the map (i.e. number of x/y
elements divided by 2), which is not the same position as the median
ra/dec or l/b. I figured this might be a problem, but there's not really
a way around it - if you just set CRPIX to be 0,0, it doesn't change
anything. xy2ad and ad2xy produce self-consistent results, but that
doesn't mean anything either.
I think the problem is that AD2XY is largely ignorant of CRPIX: it
calculates x/y offsets from the CRVAL assuming that the CRVAL is at
CRPIX.... but I don't know why that should be wrong. Ideas? More to come
if I figure anything out.
Update: from doing the individual maps in l/b vs ra/dec, I don't think
the offset is between l/b and ra/dec.... something less fundamental.
Update 2: still no clues after reading ad2xy and trying to plow through
parts of wcssph2xy. gotta be rect_pix_tstream, but I think it's
right....
Update 3: I think I have figured out the problem, currently testing. My
idea has to do with the fact that all x,y positions in
rect_pix_tstream are positive, but ad2xy is not constrained to return
positive values. In principle, the two-iteration ad2xy should take care
of this, but in the case where the middle of the map in pixels is not
the middle of the map in the WCS coordinate system, it is still possible
to get negative pixel mappings out of the 2nd iteration. I'm still
confused about whether this is really possible - makes my head fuzzy -
but I tried implementing a solution where I simply shift the crpix
rather than recalculating with AD2XY.
Update 4: Based on L111, my test in update 3 fixed the problem. Scuba
contours are correct, and reasonably consistent across the field - still
need to do the more complete test, e.g. Cygnus
Update 5: Cygnus tests still await completion, but a very close
inspection of single L111 maps reveals a ~2 pixel difference that could
go a long way to explaining my high-RMS pointing calculations. Still
doesn't explain the sine curve, but anything helps...
Update 6: My correction definitely fixed the problem, EXCEPT there's
still an ambiguity at the .5 pixel level. Specifically, is AD2XY
treating the pixel center as .5,.5 or 0,0? Ditto IDL. I believe (from my
simulated data) that this ambiguity is still causing a problem.
Update 7: New correction fixed problem to better than 1&amp;quot; (checked by
making a simulated map with 1&amp;quot; pixels) - probably 'perfect' now. Read
prepare_map.pro for details. The issue was a difference in pixel
centers.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Confirmed error in L/B mapping</title><link href="https://keflavich.github.io/blog/confirmed-error-in-lb-mapping.html" rel="alternate"></link><published>2008-08-28T01:32:00-06:00</published><updated>2008-08-28T01:32:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-28:/blog/confirmed-error-in-lb-mapping.html</id><content type="html">&lt;p&gt;I've used my simulated data and confirmed that there is in fact an error
in the l/b mapping, but I haven't tracked it down yet. Stay tuned.
Update: Something is not self-consistent in prepare_map. I've tried a
variety of different things without success yet.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category><category term="mapping"></category></entry><entry><title>Updates today</title><link href="https://keflavich.github.io/blog/updates-today.html" rel="alternate"></link><published>2008-08-25T23:35:00-06:00</published><updated>2008-08-25T23:35:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-25:/blog/updates-today.html</id><summary type="html">&lt;p&gt;I updated the FITS header writing pieces of the software today, we
should now have:
N_PCA
ITERNUM
PPBEAM
in all new maps.
I'm mapping all of Cygnus degree-by-degree in RA/Dec and Galactic to try
to measure offsets... possibly offsets as a function of l/b or ra/dec â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I updated the FITS header writing pieces of the software today, we
should now have:
N_PCA
ITERNUM
PPBEAM
in all new maps.
I'm mapping all of Cygnus degree-by-degree in RA/Dec and Galactic to try
to measure offsets... possibly offsets as a function of l/b or ra/dec. I
should really be doing this with PPSes, though.
My priority list:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;find out what's causing bulk offsets&lt;/li&gt;
&lt;li&gt;beat down noise in my pointing models by rejecting bad sources/points
[has to be done from campus]&lt;/li&gt;
&lt;li&gt;test my personal special pointing models&lt;/li&gt;
&lt;li&gt;make maps!&lt;/li&gt;
&lt;li&gt;figure out the rest of pointing&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category><category term="pipeline"></category></entry><entry><title>Iterating to Convergence</title><link href="https://keflavich.github.io/blog/iterating-to-convergence.html" rel="alternate"></link><published>2008-08-25T17:42:00-06:00</published><updated>2008-08-25T17:42:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-25:/blog/iterating-to-convergence.html</id><summary type="html">&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/SLLufcweELI/AAAAAAAADOs/5LV8RF28aUk/s400/iteratetoconvergence-0.png" /&gt;
&lt;p&gt;Some sample plots of flux-vs-iteration number in the Galactic Center.
The above is for a 13-pca-component map, and the plot is of the
northeast peak of SGR B2. The other plots (available in postscript
below) are of two other points in the GC, and the last one is of the â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/SLLufcweELI/AAAAAAAADOs/5LV8RF28aUk/s400/iteratetoconvergence-0.png" /&gt;
&lt;p&gt;Some sample plots of flux-vs-iteration number in the Galactic Center.
The above is for a 13-pca-component map, and the plot is of the
northeast peak of SGR B2. The other plots (available in postscript
below) are of two other points in the GC, and the last one is of the
whole of SGR B2 (it's a very large aperture).
ps version here:
&lt;a class="reference external" href="http://sites.google.com/site/bolocam/pipeline/mapping/iteratetoconvergence.ps?attredirects=0"&gt;http://sites.google.com/site/bolocam/pipeline/mapping/iteratetoconvergence.ps?attredirects=0&lt;/a&gt;
or /scratch/adam_work/plots/iteratetoconvergence.ps&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="iterating"></category><category term="mapping"></category></entry><entry><title>G34.3 PCA subtraction comparison</title><link href="https://keflavich.github.io/blog/g343-pca-subtraction-comparison.html" rel="alternate"></link><published>2008-08-24T20:30:00-06:00</published><updated>2008-08-24T20:30:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-24:/blog/g343-pca-subtraction-comparison.html</id><summary type="html">&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/SLHDrcGWxqI/AAAAAAAADOM/mVp0tqm6qjI/s400/g34.3_pca_compare.png" /&gt;
&lt;p&gt;From top-left to the blue highlighted box, the 20th iteration of N pca
components subtracted is shown. N goes from 1 to 19. The other plots are
'ascending' and 0-pca components with median and baseline subtraction -
ask if you want more details on those.
19 iterations recovers a LOT of â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/SLHDrcGWxqI/AAAAAAAADOM/mVp0tqm6qjI/s400/g34.3_pca_compare.png" /&gt;
&lt;p&gt;From top-left to the blue highlighted box, the 20th iteration of N pca
components subtracted is shown. N goes from 1 to 19. The other plots are
'ascending' and 0-pca components with median and baseline subtraction -
ask if you want more details on those.
19 iterations recovers a LOT of flux. I haven't generated the plots for
flux as a function of iteration, but I have software to do that
available.
Things to note: at 10 iterations and higher, you start to generate
negative bowls.
One observation is probably independently responsible for the chunks of
glitchy data present even in the 19 PCA component subtraction. While the
bowls do worsen with higher number of PCA components, we also find
fainter structure (e.g. those tongues to the southeast and northwest).&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="maps"></category><category term="mapping"></category></entry><entry><title>Some good news, some.... not news.</title><link href="https://keflavich.github.io/blog/some-good-news-some-not-news.html" rel="alternate"></link><published>2008-08-24T20:09:00-06:00</published><updated>2008-08-24T20:09:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-24:/blog/some-good-news-some-not-news.html</id><summary type="html">&lt;p&gt;I've been mapping all weekend. It turns out that if you do 25 mapping
runs that take ~1hr apiece, that takes ~25 hours. Who knew?
Whole observation took 3965.3506 sec.
Whole observation took 3071.1403 sec.
Whole observation took 4205.3337 sec.
Whole observation took 7362.5490 sec.
Whole â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been mapping all weekend. It turns out that if you do 25 mapping
runs that take ~1hr apiece, that takes ~25 hours. Who knew?
Whole observation took 3965.3506 sec.
Whole observation took 3071.1403 sec.
Whole observation took 4205.3337 sec.
Whole observation took 7362.5490 sec.
Whole observation took 9313.6064 sec.
Whole observation took 3755.2383 sec.
Whole observation took 3755.8278 sec.
Whole observation took 3760.7032 sec.
Whole observation took 3758.5719 sec.
Whole observation took 3763.1436 sec.
Whole observation took 3766.0066 sec.
Whole observation took 3789.5806 sec.
Whole observation took 3760.9774 sec.
Whole observation took 3762.7124 sec.
Whole observation took 3763.1120 sec.
Whole observation took 3767.1255 sec.
Whole observation took 3766.9085 sec.
Whole observation took 3758.5867 sec.
Whole observation took 3760.2131 sec.
Whole observation took 3755.8963 sec.
Whole observation took 3759.9199 sec.
Whole observation took 3764.4494 sec.
Whole observation took 3766.9686 sec.
Whole observation took 3756.5876 sec.
The good news is that I haven't encountered any crashes. Smooth sailing
so far.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category><category term="pipeline"></category></entry><entry><title>Re: Convergence Tests</title><link href="https://keflavich.github.io/blog/re-convergence-tests.html" rel="alternate"></link><published>2008-08-23T17:03:00-06:00</published><updated>2008-08-23T17:03:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-23:/blog/re-convergence-tests.html</id><summary type="html">&lt;p&gt;Made a little code to check out convergence, but frankly it's pretty
easy to just build a mapcube and plot lines in the iteration axis. The
code is in bgps_pipeline/postproc/compareiters.pro, and it is not a
single program.
Comparing deconvolution to no deconvolution, deconvolution is a lot â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Made a little code to check out convergence, but frankly it's pretty
easy to just build a mapcube and plot lines in the iteration axis. The
code is in bgps_pipeline/postproc/compareiters.pro, and it is not a
single program.
Comparing deconvolution to no deconvolution, deconvolution is a lot
better. Without it, there are much more substantial negative regions. In
the GC, my test region, the noise-dominated areas were about the same,
though the no-deconvolve map had a little bit more large scale
structure. The signal-dominated regions were very nearly uniformly
brighter. The deconvolved map was ~3 Jy brighter in SGR B2, or 4%.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>On the list for today....</title><link href="https://keflavich.github.io/blog/on-the-list-for-today.html" rel="alternate"></link><published>2008-08-23T13:42:00-06:00</published><updated>2008-08-23T13:42:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-23:/blog/on-the-list-for-today.html</id><summary type="html">&lt;p&gt;Since my gigantic mapping run is still going, I'm going to work
primarily on developing code for testing the maps, and determining
important information about the mapper.
The data paper will require an iteration-to-convergence figure, or at
least an estimate of degree of convergence.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Need to develop code to show â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;Since my gigantic mapping run is still going, I'm going to work
primarily on developing code for testing the maps, and determining
important information about the mapper.
The data paper will require an iteration-to-convergence figure, or at
least an estimate of degree of convergence.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Need to develop code to show iteration-to-convergence&lt;ol class="arabic"&gt;
&lt;li&gt;need it for both NxNpca and ascending/descending&lt;/li&gt;
&lt;li&gt;have to use region files? make some sort of region reader?&lt;/li&gt;
&lt;li&gt;pick demonstration sources&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Compare N&lt;sub&gt;pca&lt;/sub&gt; results for bright, faint sources&lt;/li&gt;
&lt;li&gt;Compare iterating with/without deconvolution&lt;/li&gt;
&lt;li&gt;Compare median/average/baseline sky subtraction&lt;/li&gt;
&lt;li&gt;Analyze efficiency...&lt;/li&gt;
&lt;li&gt;Try to figure out what's causing huge offsets. Is it Galactic
Coordinate mapping?&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="literal-block"&gt;
-bash-3.00$ less /scratch/adam_work/logs/log_082208_domemiter.log | grep WholeWhole observation took 5122.6795 sec.Whole observation took 4774.3424 sec.Whole observation took 2687.7761 sec.Whole observation took 2102.5577 sec.Whole observation took 3247.5344 sec.Whole observation took 5515.2907 sec.Whole observation took 2877.6389 sec.Whole observation took 2757.0235 sec.Whole observation took 1453.0918 sec.Whole observation took 1459.7892 sec.Whole observation took 1381.3762 sec.Whole observation took 1443.1440 sec.Whole observation took 614.39645 sec.Whole observation took 2001.6709 sec.Whole observation took 1817.1512 sec.Whole observation took 1879.1385 sec.
&lt;/pre&gt;
&lt;p&gt;Note that the longest set there - 5515s = 1.53 hours - was 40
iterations!&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>TEN!?!</title><link href="https://keflavich.github.io/blog/ten.html" rel="alternate"></link><published>2008-08-23T00:47:00-06:00</published><updated>2008-08-23T00:47:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-23:/blog/ten.html</id><content type="html">&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/SK9Pe1q6PaI/AAAAAAAADOE/yd0bxUMCDB4/s400/EIGHT.png" /&gt;
&lt;p&gt;Look at that. Seriously? a 10' offset? That's ridiculous! There is no
WAY our pointing models could be off by that much! Even if I got the
signs entirely wrong, that's just not possible.
What's going on? First theory: Galactic coordinates fail. Any other
suggestions?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category><category term="mapping"></category></entry><entry><title>Task List</title><link href="https://keflavich.github.io/blog/task-list.html" rel="alternate"></link><published>2008-08-22T00:29:00-06:00</published><updated>2008-08-22T00:29:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-22:/blog/task-list.html</id><summary type="html">&lt;p&gt;For the moment, I'm going to leave the pointing alone. This leaves us
(me) with a very long list of things to do before the data release:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Determine ideal iterative mapping strategy for low-flux fields&lt;/li&gt;
&lt;li&gt;Determine ideal iterative mapping strategy for fields with bright
sources&lt;/li&gt;
&lt;li&gt;Optimize at least the following â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;For the moment, I'm going to leave the pointing alone. This leaves us
(me) with a very long list of things to do before the data release:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Determine ideal iterative mapping strategy for low-flux fields&lt;/li&gt;
&lt;li&gt;Determine ideal iterative mapping strategy for fields with bright
sources&lt;/li&gt;
&lt;li&gt;Optimize at least the following:&lt;ol class="arabic"&gt;
&lt;li&gt;scan flatting (polynomial subtraction)&lt;/li&gt;
&lt;li&gt;PCA subtraction&lt;/li&gt;
&lt;li&gt;Pre-PCA sky subtraction (necessary?)&lt;/li&gt;
&lt;li&gt;Deconvolution/No deconvolution&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;GENERATE MAPS [top priority, but it can't really happen til after the
above]&lt;/li&gt;
&lt;li&gt;Assure consistency with catalogs - e.g. Motte, SCUBA, etc.&lt;/li&gt;
&lt;li&gt;Figure out what needs to go into fits header&lt;/li&gt;
&lt;li&gt;Survive semester before comps [lowest priority]&lt;/li&gt;
&lt;li&gt;sleep [oh, right, real lowest priority]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Sarcasm helps me survive. Almost as much as beer.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="data release"></category><category term="mapping"></category><category term="pipeline"></category></entry><entry><title>New pointing models</title><link href="https://keflavich.github.io/blog/new-pointing-models.html" rel="alternate"></link><published>2008-08-21T20:45:00-06:00</published><updated>2008-08-21T20:45:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-21:/blog/new-pointing-models.html</id><summary type="html">&lt;p&gt;I decided to try to fit the pointing model as a full alt/az or ra/dec
dependent thing using mpfitfun and a 12 (or 16) parameter model. It
didn't work very well.
I could fit out the alt dependence, then independently fit out the az
dependence, and see how â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I decided to try to fit the pointing model as a full alt/az or ra/dec
dependent thing using mpfitfun and a 12 (or 16) parameter model. It
didn't work very well.
I could fit out the alt dependence, then independently fit out the az
dependence, and see how that goes. I think it will work brilliantly.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Got a sign wrong again</title><link href="https://keflavich.github.io/blog/got-a-sign-wrong-again.html" rel="alternate"></link><published>2008-08-21T20:40:00-06:00</published><updated>2008-08-21T20:40:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-21:/blog/got-a-sign-wrong-again.html</id><content type="html">&lt;p&gt;Last night's run failed because I had a wrong sign in the pointing
model. Do over time!&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Notice anything different?</title><link href="https://keflavich.github.io/blog/notice-anything-different.html" rel="alternate"></link><published>2008-08-21T01:08:00-06:00</published><updated>2008-08-21T01:08:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-21:/blog/notice-anything-different.html</id><summary type="html">&lt;p&gt;About milkyway? This post is a red herring, but:
I decided to go ahead and run the mapper on Cygnus, L33, L111, and the
Galactic Center again. The pointing has gotten to the stage where I'm
certain I can't do anything more without a stroke of pure brilliance or
a â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;About milkyway? This post is a red herring, but:
I decided to go ahead and run the mapper on Cygnus, L33, L111, and the
Galactic Center again. The pointing has gotten to the stage where I'm
certain I can't do anything more without a stroke of pure brilliance or
a conversation with someone who hasn't touched a thing - e.g. Jason -
that suddenly enlightens me.
In order to fully reproduce Meredith's results, I'd probably have to go
back through and follow her 'pipeline' process step by step as well, and
I suspect that, if I had used her method on her RA/Dec maps, I would
have come up with exactly the same problem I currently see. Therefore, I
won't do anything about it.
I think the most appropriate response at this point MAY be to just fit a
damned polynomial/sine curve in az and include that as part of the
pointing model, but I can't justify where that comes from. All I know is
that it's present in Meredith's data as well as my own.
What's that next step with the PPSes? We need to do that.
More important, though, is getting some image optimization ready FAST. I
need to be running this stuff before September! Tonight's run will be a
test of numbers of PCA components. At the very least, the v0.5 should
have a consistent set of images even if we cut out the high-flux ones.
We'll deal with that later.
For the high flux objects, e.g. g34.3, since we have so much overlapping
data, a simple average/magical baseline subtraction might be just as if
not more effective than PCA subtraction, so that's one way around it.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category><category term="pipeline"></category></entry><entry><title>Modifications</title><link href="https://keflavich.github.io/blog/modifications.html" rel="alternate"></link><published>2008-08-19T18:07:00-06:00</published><updated>2008-08-19T18:07:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-19:/blog/modifications.html</id><summary type="html">&lt;p&gt;Things that have been changed in the past 24 hours that are very
significant:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;In apply_pointing_model, the signs of FAZO and FZAO have been
swapped. I BELIEVE this is correct but somehow things aren't working
out still.&lt;/li&gt;
&lt;li&gt;In do_the_pointing I have changed from &amp;quot;eq2hor&amp;quot; and &amp;quot;hor2eq â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;Things that have been changed in the past 24 hours that are very
significant:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;In apply_pointing_model, the signs of FAZO and FZAO have been
swapped. I BELIEVE this is correct but somehow things aren't working
out still.&lt;/li&gt;
&lt;li&gt;In do_the_pointing I have changed from &amp;quot;eq2hor&amp;quot; and &amp;quot;hor2eq&amp;quot; to
&amp;quot;my_eq2hor&amp;quot; and &amp;quot;my_hor2eq&amp;quot;. These implement two major changes:&lt;ol class="arabic"&gt;
&lt;li&gt;The LST is passed as a parameter rather than calculated within the
ASTROLIB code&lt;/li&gt;
&lt;li&gt;The conversion is calculated with BOTH hadec2altaz and getaltaz
(and similar for the opposite transformation) and compared for
error checking purposes. If they differ by more than one
arcsecond, the code will spit out an error message and use
getaltaz.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Inconsistent</title><link href="https://keflavich.github.io/blog/inconsistent.html" rel="alternate"></link><published>2008-08-17T18:56:00-06:00</published><updated>2008-08-17T18:56:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-17:/blog/inconsistent.html</id><summary type="html">&lt;p&gt;James: &amp;quot;I think it's fair to say, though, that there is some problem
with the simultaneous assumption that CSO coords are geo and that we are
applying the ab/nut correction correctly.&amp;quot;
Yep. The relevant files are in /scratch/adam_work/plots/:
models_noabnut_radec_0707.ps
models_noabnut_rawcsoptg â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;James: &amp;quot;I think it's fair to say, though, that there is some problem
with the simultaneous assumption that CSO coords are geo and that we are
applying the ab/nut correction correctly.&amp;quot;
Yep. The relevant files are in /scratch/adam_work/plots/:
models_noabnut_radec_0707.ps
models_noabnut_rawcsoptg_radec_0707.ps
models_oppositeabnut_radec_0707.ps
models_oppositeabnut_rawcso_radec_0707.ps
I'm afraid they're pretty confusing.
'noabnut' means no aberration/nutation correction was applied during the
mapping process.
'oppositeabnut' means that an aberration/nutation correction that,
according to the eq2hor and hor2eq texts, should actually convert
heliocentric to geocentric, is being used on data that we believe is
starting in a geocentric frame. There are two possibilities: 1. We are
wrong 2. eq2hor/hor2eq are wrong.
The 'rawcso' files have FAZO/FZAO &amp;quot;subtracted out&amp;quot; (removed) in pages 1
and 3, and FAZO/FZAO added back in on pages 2 and 4. 'rawcso' means that
we're looking at the ra/dec the CSO gave without the users' FAZO/FZAO
corrections.
The non-rawcso have the NCDF ra/dec vectors, with precession correction
applied (and some form of ab/nut correction), but the FAZO/FZAO are
still present. THESE should be equivalent to Meredith's plots, e.g.
where FAZO_SET/FZAO_SET are on the y axis. However, that's only true
for pages 1 and 3. Pages 2 and 4 have FAZO/FZAO essentially
double-subtracted, so they should be ignored. Pages 1 and 3 of the
non-rawcso files should be equivalent to pages 2 and 4 of the rawcso
files with the exception that the sigma-rejection used to choose the
yellow points is different.
So what's in each page? On pages 1 and 2, the red lines are my best fit
to the yellow data, which is the black data with an iterative sigma
rejection applied (i.e. reject at 1 sigma, recalculate sigma from good
data, reject at 2 sigma). The blue lines are Meredith's models. The
right side includes only the yellow data points with the red line
subtracted. On pages 3 and 4, the same is pretty much true except that
ONLY the altitude-dependent line has been subtracted: there is no fit to
azimuth.
Also, the 'sourcecompare' files are similar. I'd check those out too.
I still don't have the extremely low RMS that Meredith saw. I'm going to
go through and try to reject bad data points by hand to see if I can get
to that level. We'll see.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Direct comparison with Meredith's pointing calculations</title><link href="https://keflavich.github.io/blog/direct-comparison-with-merediths-pointing-calculations.html" rel="alternate"></link><published>2008-08-14T04:11:00-06:00</published><updated>2008-08-14T04:11:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-14:/blog/direct-comparison-with-merediths-pointing-calculations.html</id><summary type="html">&lt;p&gt;I've gotten to the point that I'm directly comparing my pointing
calculations to Merediths. So far, it looks like:
1. I can very nearly reproduce Meredith's results on her maps, though
there are a few differences in centroids and I missed the source a few
times where she didn't.
2 â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've gotten to the point that I'm directly comparing my pointing
calculations to Merediths. So far, it looks like:
1. I can very nearly reproduce Meredith's results on her maps, though
there are a few differences in centroids and I missed the source a few
times where she didn't.
2. There is still a spread between my map centroids and hers.
The code I've written to enable this comparison:
publish/debug_testing/compare_me_meredith.pro
I'm still a bit stumped, but I think I have a path to the answer mapped
out.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Centroiding and Meredith's files</title><link href="https://keflavich.github.io/blog/centroiding-and-merediths-files.html" rel="alternate"></link><published>2008-08-13T03:54:00-06:00</published><updated>2008-08-13T03:54:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-13:/blog/centroiding-and-merediths-files.html</id><content type="html">&lt;p&gt;I tried the pointing offset calculations on Meredith's maps and I still
get an RMS of ~9&amp;quot; in both RA and DEC. Check out the files:
/scratch/adam_work/plots/models_meredith*
So... what?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Searching for more offsets</title><link href="https://keflavich.github.io/blog/searching-for-more-offsets.html" rel="alternate"></link><published>2008-08-12T21:35:00-06:00</published><updated>2008-08-12T21:35:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-12:/blog/searching-for-more-offsets.html</id><summary type="html">&lt;p&gt;The defining feature of my pointing calculations - and their
inconsistency - is that the spread for individual sources is bad, which
means that there's still something wrong in the way the bulk ra/dec are
being calculated.&lt;/p&gt;
&lt;p&gt;I checked apply_distortion_map_radec to see if it might have inserted
some â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The defining feature of my pointing calculations - and their
inconsistency - is that the spread for individual sources is bad, which
means that there's still something wrong in the way the bulk ra/dec are
being calculated.&lt;/p&gt;
&lt;p&gt;I checked apply_distortion_map_radec to see if it might have inserted
some bulk offset, but it only changes the average position by &amp;lt;2&amp;quot;. That
might be an issue, but the boresight isn't necessarily aligned with the
mean location of the bolometers. It should be shifted by at least .3&amp;quot;
according to a simple average of sin/cos of the bolo_params angles.
Comparing my pointing code to map_ncdf_reading directly:&lt;/p&gt;
&lt;p&gt;readstruct=map_ncdf_reading(filename,/nopixoff)
offsets are small (e.g. -0.050665803 -0.0029540043 arcseconds ra/dec) if
I don't subtract fazo/fzao
offsets in ra/dec are remarkably close to fazo/fzao if I subtract them:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
92.830656 -126.12773
95.000000 -120.00000
&lt;/pre&gt;
&lt;p&gt;which is because ra/dec are pretty closely aligned to az/el.
So, any difference comes from at least one of the keyword parameters.
Therefore I AM missing something, and that something is one of the
keywords to map_ncdf_reading&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>FFTs and unlucky primes</title><link href="https://keflavich.github.io/blog/ffts-and-unlucky-primes.html" rel="alternate"></link><published>2008-08-12T17:04:00-06:00</published><updated>2008-08-12T17:04:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-12:/blog/ffts-and-unlucky-primes.html</id><summary type="html">&lt;p&gt;I've encountered a lot (!) of unlucky prime numbers that I'm trying to
FFT in too many places, and it basically stops the code.
211151 was impossibly bad, 5827 is pretty bad too.
I solved the first by splitting into by-scan delining, which is better
anyway. But the second is a â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've encountered a lot (!) of unlucky prime numbers that I'm trying to
FFT in too many places, and it basically stops the code.
211151 was impossibly bad, 5827 is pretty bad too.
I solved the first by splitting into by-scan delining, which is better
anyway. But the second is a map, in which I KNOW zero padding is OK.
So... are there any functions that find the nearest reasonably efficient
map size?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>More cleaning modifications</title><link href="https://keflavich.github.io/blog/more-cleaning-modifications.html" rel="alternate"></link><published>2008-08-12T17:01:00-06:00</published><updated>2008-08-12T17:01:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-12:/blog/more-cleaning-modifications.html</id><summary type="html">&lt;p&gt;I had removed sigmadeglitch from deline, now it's permanently gone. I
think it might be worth exploring re-inserting sigmadeglitch somewhere.
My higher-order polynomial fit is creating deeper bowls around sources,
so that's a big problem, but if I use a lower order I get the bad
streaks. What's the best â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I had removed sigmadeglitch from deline, now it's permanently gone. I
think it might be worth exploring re-inserting sigmadeglitch somewhere.
My higher-order polynomial fit is creating deeper bowls around sources,
so that's a big problem, but if I use a lower order I get the bad
streaks. What's the best way to deal with this? I'm thinking perhaps
only doing the polysub on the second iteration (i.e. after a source
model has been subtracted).
Delining runs into some issues now, though, because not all frequencies
are sampled (?).&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Wow - FFT failure</title><link href="https://keflavich.github.io/blog/wow-fft-failure.html" rel="alternate"></link><published>2008-08-12T15:11:00-06:00</published><updated>2008-08-12T15:11:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-12:/blog/wow-fft-failure.html</id><summary type="html">&lt;p&gt;On my huge Cygnus run, the fft keeps failing in the deline code. It's
actually pretty impressive, but there are 844604 points in the
timestream. The prime factorization of 844604 is 2^2 * 211151. This is
just damned bad luck, because I think an FFT is extremely inefficient
when it â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;On my huge Cygnus run, the fft keeps failing in the deline code. It's
actually pretty impressive, but there are 844604 points in the
timestream. The prime factorization of 844604 is 2^2 * 211151. This is
just damned bad luck, because I think an FFT is extremely inefficient
when it can't factorize. What's the best workaround? ....
9 AM update: I've rewritten the deliner to work on a scan-by-scan basis.
It's possible that the delining failed in the past because it was
essentially removing a constant amplitude at the line frequencies across
the observation (or combined observations!) which is not likely to be
true.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>RMS fails to shrink</title><link href="https://keflavich.github.io/blog/rms-fails-to-shrink.html" rel="alternate"></link><published>2008-08-12T13:51:00-06:00</published><updated>2008-08-12T13:51:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-12:/blog/rms-fails-to-shrink.html</id><summary type="html">&lt;p&gt;Spent a while today working on these plots after rejecting every obvious
bad point:
/scratch/adam_work/plots/sourcecompare_0_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_10_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_1_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_2_rawcsoptg_0707.ps â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Spent a while today working on these plots after rejecting every obvious
bad point:
/scratch/adam_work/plots/sourcecompare_0_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_10_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_1_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_2_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_3_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_4_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_5_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_6_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_7_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_8_rawcsoptg_0707.ps
/scratch/adam_work/plots/sourcecompare_9_rawcsoptg_0707.ps
/scratch/adam_work/plots/models_rawcsoptg_0707.ps
The net result is, I still don't have a nice small RMS offset
Update 8/12/08: using RA/DEC mapping doesn't help.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Cleaning ideas</title><link href="https://keflavich.github.io/blog/cleaning-ideas.html" rel="alternate"></link><published>2008-08-11T15:20:00-06:00</published><updated>2008-08-11T15:20:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-11:/blog/cleaning-ideas.html</id><summary type="html">&lt;p&gt;It's proving very difficult to get rid of glitches, so here are some
more ideas:&lt;/p&gt;
&lt;p&gt;Median filter the whole timestream (downsampled) at a resolution that
will pull down the glitch peak. Subtract out the median-filtered
timestream from the original, and look for outliers in that
distribution: in principle, those should â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's proving very difficult to get rid of glitches, so here are some
more ideas:&lt;/p&gt;
&lt;p&gt;Median filter the whole timestream (downsampled) at a resolution that
will pull down the glitch peak. Subtract out the median-filtered
timestream from the original, and look for outliers in that
distribution: in principle, those should be glitches.&lt;/p&gt;
&lt;p&gt;Another option: subtract out the noise map AND the best-model map from
the original timestream before trying to pull out additional astro model
stuff. The map-to-timestream astro model can't include glitches because
they're averaged over, but the sky-subtracted timestream DOES include
glitches (no matter how many PCA components are removed) because
glitches are NOT correlated across detectors. The weird thing is that
this is effectively subtracting out exactly what was calculated from the
sky subtraction - the question is whether subtracting it out BEFORE sky
subtracting again gets you any benefit. If it was just noise,
subtracting noise from noise is fine, but the &amp;quot;noise&amp;quot; does include some
residual signal.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Glitches and errors</title><link href="https://keflavich.github.io/blog/glitches-and-errors.html" rel="alternate"></link><published>2008-08-11T04:24:00-06:00</published><updated>2008-08-11T04:24:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-11:/blog/glitches-and-errors.html</id><summary type="html">&lt;p&gt;It's definitely important to get rid of the spikes and, more
importantly, the exponential decay. The current function is pretty good,
but possibly not good enough because there are some situations in which
the turnaround decay is obviously not well-enough dealt with and results
in high/low streaks.
The glitches â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's definitely important to get rid of the spikes and, more
importantly, the exponential decay. The current function is pretty good,
but possibly not good enough because there are some situations in which
the turnaround decay is obviously not well-enough dealt with and results
in high/low streaks.
The glitches can be ~20 Jy. The problem is that they sometimes show up
in the middle of sources (e.g. in 060609_o26). That will badly distort
fluxes.
My ideal is still to use a median instead of mean combination of data
points into image points, but that seems to be impractical to implement.
Other ideas...&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category></entry><entry><title>Big run this weekend...</title><link href="https://keflavich.github.io/blog/big-run-this-weekend.html" rel="alternate"></link><published>2008-08-09T17:22:00-06:00</published><updated>2008-08-09T17:22:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-09:/blog/big-run-this-weekend.html</id><summary type="html">&lt;p&gt;In case anyone is wondering why Milkyway is going really slowly, I'm
mapping a 69-observation set of Cygnus. It ought to prove to be an
interesting test of Milkyway's swap capacity, but other than that I
doubt it will be useful. While the pointing is reasonably good at this
point â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In case anyone is wondering why Milkyway is going really slowly, I'm
mapping a 69-observation set of Cygnus. It ought to prove to be an
interesting test of Milkyway's swap capacity, but other than that I
doubt it will be useful. While the pointing is reasonably good at this
point (30&amp;quot; still, but whatever), I haven't done ANY work on filtering
out bad observations / flagging stuff in Cyg. Data massaging is going to
be a long process, it would be great if I could do that instead of
pointing stuff. Argh.
One thing to note is that this file:
/scratch/sliced/l078/070702_o33_raw_ds5.nc
is a &amp;quot;_ds5.nc&amp;quot; but is NOT downsampled!
Update:
Mapped the individual files successfully, picked out noisy ones. The
overall map failed - just not enough memory to do a field that large. I
split it up in to two sets of 25 observations, plus I'll be mapping each
L 70-L 90 field separately (I didn't get ride of noisy observations for
this). I'm also remapping the individual observations with PSD flagging
enabled to see how that works.
For notes on the P Cyg observations, see the file
/scratch/adam_work/texts/cygnus_for_pat.in&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Images with artifacts</title><link href="https://keflavich.github.io/blog/images-with-artifacts.html" rel="alternate"></link><published>2008-08-07T23:42:00-06:00</published><updated>2008-08-07T23:42:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-07:/blog/images-with-artifacts.html</id><summary type="html">&lt;p&gt;Here's the list from 0507:
Streaky offsets:
/scratch/adam_work/g34.3/rawcsoptg050706_o47_raw_ds1.nc_indiv3pca_map00.fits
.. image:: &lt;a class="reference external" href="http://3.bp.blogspot.com/_lsgW26mWZnU/SJtP9wKu4_I/AAAAAAAADNo/gmMEFkzCX-A/s320/050706_o47.png"&gt;http://3.bp.blogspot.com/_lsgW26mWZnU/SJtP9wKu4_I/AAAAAAAADNo/gmMEFkzCX-A/s320/050706_o47.png&lt;/a&gt;
Totally messed up (two sets of images many degrees apart):
/scratch/adam_work/g34.3 â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here's the list from 0507:
Streaky offsets:
/scratch/adam_work/g34.3/rawcsoptg050706_o47_raw_ds1.nc_indiv3pca_map00.fits
.. image:: &lt;a class="reference external" href="http://3.bp.blogspot.com/_lsgW26mWZnU/SJtP9wKu4_I/AAAAAAAADNo/gmMEFkzCX-A/s320/050706_o47.png"&gt;http://3.bp.blogspot.com/_lsgW26mWZnU/SJtP9wKu4_I/AAAAAAAADNo/gmMEFkzCX-A/s320/050706_o47.png&lt;/a&gt;
Totally messed up (two sets of images many degrees apart):
/scratch/adam_work/g34.3/rawcsoptg050713_o40_raw_ds1.nc_indiv3pca_map00.fits
070709_ob7 :
.. image:: &lt;a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/SJuIDL161GI/AAAAAAAADN4/D4mxFyx1Fr0/s320/070709_ob7_1730m130_peanut.png"&gt;http://4.bp.blogspot.com/_lsgW26mWZnU/SJuIDL161GI/AAAAAAAADN4/D4mxFyx1Fr0/s320/070709_ob7_1730m130_peanut.png&lt;/a&gt;
070703_o48 :
.. image:: &lt;a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/SJuICzavE_I/AAAAAAAADNw/70Hl5930eU8/s320/070703_o48_3c454.3.png"&gt;http://4.bp.blogspot.com/_lsgW26mWZnU/SJuICzavE_I/AAAAAAAADNw/70Hl5930eU8/s320/070703_o48_3c454.3.png&lt;/a&gt;&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Looking back at the old pipeline</title><link href="https://keflavich.github.io/blog/looking-back-at-the-old-pipeline.html" rel="alternate"></link><published>2008-08-07T16:33:00-06:00</published><updated>2008-08-07T16:33:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-07:/blog/looking-back-at-the-old-pipeline.html</id><summary type="html">&lt;p&gt;I've obviously missed something. So to try to figure out what it is, I'm
going back to the old pipeline... again...
in map_ncdf_reading, lines 441-448, there is something curious that
goes back to a definition-of-variables problem: ddec and dra are ADDED
to ra and dec to get the â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've obviously missed something. So to try to figure out what it is, I'm
going back to the old pipeline... again...
in map_ncdf_reading, lines 441-448, there is something curious that
goes back to a definition-of-variables problem: ddec and dra are ADDED
to ra and dec to get the new &amp;quot;ra_all&amp;quot; and &amp;quot;dec_all&amp;quot; variables. ddec
and dra are calculated from eaz and eel: ERROR OFFSETS in Az and El.
Why? What?!
I added a new piece of code, correct_eaz_eel.pro. It is extremely
short, but extremely necessary.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pro correct_eaz_eel,ra,dec,el,az,eel,eaz,pa    dra=-eaz*cos(!dtor*pa)*cos(!dtor*el)+eel*sin(!dtor*pa)    ddec=eaz*sin(!dtor*pa)*cos(!dtor*el)+eel*cos(!dtor*pa)    dec += ddec/3600.    ra  += dra/3600. / cos(!dtor*dec) / 15.end
&lt;/pre&gt;
&lt;p&gt;This comes back to the fact that I don't know what ANY of the variables
in the NCDF header are supposed to be. Why are &amp;quot;error&amp;quot; variables
actually OFFSET variables, and why didn't anyone know about them?&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>something is wrong in 0507....</title><link href="https://keflavich.github.io/blog/something-is-wrong-in-0507.html" rel="alternate"></link><published>2008-08-07T00:01:00-06:00</published><updated>2008-08-07T00:01:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-07:/blog/something-is-wrong-in-0507.html</id><summary type="html">&lt;img alt="" src="http://picasaweb.google.com/keflavich/Bolocam/photo?authkey=OyC8l5sv3gI#5231555630189235762" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/SJousnsJDjI/AAAAAAAADMY/-hhiIoQ171A/s320/g34.3_zoo.jpg" /&gt;
&lt;p&gt;Look at that zoomed in. Note that the first 20ish are from 0507. I don't
know what's causing the double source. Maybe a 90 degree rotation would
do it, I don't know. I do know that I'm applying an array angle of 76.2
degrees for those July observations and â€¦&lt;/p&gt;</summary><content type="html">&lt;img alt="" src="http://picasaweb.google.com/keflavich/Bolocam/photo?authkey=OyC8l5sv3gI#5231555630189235762" /&gt;
&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/SJousnsJDjI/AAAAAAAADMY/-hhiIoQ171A/s320/g34.3_zoo.jpg" /&gt;
&lt;p&gt;Look at that zoomed in. Note that the first 20ish are from 0507. I don't
know what's causing the double source. Maybe a 90 degree rotation would
do it, I don't know. I do know that I'm applying an array angle of 76.2
degrees for those July observations and 113.6 degrees for the June 05
observations. Maybe that got swapped or something....
It looks like Meredith ran into the same problems when mapping 0506, but
not 0507.&lt;/p&gt;
&lt;img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/SJo7MpPYjDI/AAAAAAAADNg/6_pSjjeKjLM/s320/g34_0507_compare.jpg" /&gt;
&lt;p&gt;comparing mine to hers (I even used the same downsampled/cleand file),
it is obvious that something went wrong with the mapping. I tested a
number of different fiducial array angles and none of them generated
real maps, so the mapping is correct except for offsets in the scan
direction, as usual. What the heck.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Distortion (not distortion maps)</title><link href="https://keflavich.github.io/blog/distortion-not-distortion-maps.html" rel="alternate"></link><published>2008-08-06T20:40:00-06:00</published><updated>2008-08-06T20:40:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-06:/blog/distortion-not-distortion-maps.html</id><content type="html">&lt;p&gt;I still see distortion in a lot of maps, but not all. I think there is a
correlation with altitude ~70+/-2 degrees. So far it's most obvious in
the 0606 pointing sources.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Occasional bad centroid</title><link href="https://keflavich.github.io/blog/occasional-bad-centroid.html" rel="alternate"></link><published>2008-08-06T20:04:00-06:00</published><updated>2008-08-06T20:04:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-06:/blog/occasional-bad-centroid.html</id><content type="html">&lt;img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/SJoDqKsjWsI/AAAAAAAADMQ/89W6FBUZmvQ/s320/badcentroid.jpg" /&gt;
&lt;p&gt;I've gotten some bad centroids for 3c273 that don't make sense.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>0507 mapping</title><link href="https://keflavich.github.io/blog/0507-mapping.html" rel="alternate"></link><published>2008-08-06T17:56:00-06:00</published><updated>2008-08-06T17:56:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-06:/blog/0507-mapping.html</id><summary type="html">&lt;p&gt;Most of the 0507 pointing source maps seem to have failed. Some of them
look like rotator and position angle problems, others have multiple
copies of sources mapped to different locations. I don't know what's up,
but my first bet would be to change the fiducial array angle. After
that â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Most of the 0507 pointing source maps seem to have failed. Some of them
look like rotator and position angle problems, others have multiple
copies of sources mapped to different locations. I don't know what's up,
but my first bet would be to change the fiducial array angle. After
that, I'd check on rotang and then, if desperate, see what the PA is
doing.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="mapping"></category></entry><entry><title>Mapped, but no dice</title><link href="https://keflavich.github.io/blog/mapped-but-no-dice.html" rel="alternate"></link><published>2008-08-06T15:22:00-06:00</published><updated>2008-08-06T15:22:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-06:/blog/mapped-but-no-dice.html</id><summary type="html">&lt;p&gt;Finished mapping what I think are all of the pointing sources. However,
the RMS of the centroids has not gone down. Now I need to go through
each individual source and image and try to get rid of the baddies.
There are presumably some sources with bulk offsets that can â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Finished mapping what I think are all of the pointing sources. However,
the RMS of the centroids has not gone down. Now I need to go through
each individual source and image and try to get rid of the baddies.
There are presumably some sources with bulk offsets that can be removed
to improve the fits. I just have to find them.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Nothing</title><link href="https://keflavich.github.io/blog/nothing.html" rel="alternate"></link><published>2008-08-06T00:32:00-06:00</published><updated>2008-08-06T00:32:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-06:/blog/nothing.html</id><summary type="html">&lt;p&gt;No progress today. Spent the whole day re-mapping pointing sources and
figuring out which observations ARE pointing sources. Mapping STILL not
done - it takes a long time when there are hundreds of separate
observations. Also, finding some corrupt files and noting them in
/scratch/adam_work/texts/toolarge.txt . A â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;No progress today. Spent the whole day re-mapping pointing sources and
figuring out which observations ARE pointing sources. Mapping STILL not
done - it takes a long time when there are hundreds of separate
observations. Also, finding some corrupt files and noting them in
/scratch/adam_work/texts/toolarge.txt . A lot more of that work to be
done.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Observation distribution</title><link href="https://keflavich.github.io/blog/observation-distribution.html" rel="alternate"></link><published>2008-08-04T21:57:00-06:00</published><updated>2008-08-04T21:57:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-04:/blog/observation-distribution.html</id><summary type="html">&lt;pre class="literal-block"&gt;
-bash-3.00$ wc texts/all_*_observations.txt                                                                                                     0      0      0 texts/all_0505_observations.txt    0      0      0 texts/all_0506_observations.txt  151    151   6039 texts/all_0507_observations.txt   33     33   1377 texts/all_0509_observations.txt   16     16    633 texts/all_0605_observations.txt  135    135   5309 â€¦&lt;/pre&gt;</summary><content type="html">&lt;pre class="literal-block"&gt;
-bash-3.00$ wc texts/all_*_observations.txt                                                                                                     0      0      0 texts/all_0505_observations.txt    0      0      0 texts/all_0506_observations.txt  151    151   6039 texts/all_0507_observations.txt   33     33   1377 texts/all_0509_observations.txt   16     16    633 texts/all_0605_observations.txt  135    135   5309 texts/all_0606_observations.txt    0      0      0 texts/all_0607_observations.txt   94     94   3780 texts/all_0609_observations.txt   34     34   1386 texts/all_0705_observations.txt   26     26   1028 texts/all_0706_observations.txt  201    201   7989 texts/all_0707_observations.txt   73     73   2907 texts/all_0709_observations.txt    0      0      0 texts/all_polychrome_0505_observations.txt  222    222  11898 texts/all_polychrome_0506_observations.txt  471    471  24861 texts/all_polychrome_0507_observations.txt  196    196  10346 texts/all_polychrome_0509_observations.txt   43     43   2200 texts/all_polychrome_0605_observations.txt  730    730  38040 texts/all_polychrome_0606_observations.txt   22     22   1195 texts/all_polychrome_0607_observations.txt  471    471  24751 texts/all_polychrome_0609_observations.txt   66     66   3399 texts/all_polychrome_0705_observations.txt  145    145   7533 texts/all_polychrome_0706_observations.txt 1051   1051  54801 texts/all_polychrome_0707_observations.txt  511    511  27049 texts/all_polychrome_0709_observations.txt 4691   4691 236521 total
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="documentation"></category></entry><entry><title>News, modifications</title><link href="https://keflavich.github.io/blog/news-modifications.html" rel="alternate"></link><published>2008-08-03T07:19:00-06:00</published><updated>2008-08-03T07:19:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-03:/blog/news-modifications.html</id><summary type="html">&lt;p&gt;RA / Dec mapping did change centroid locations, but not really for the
better. A deeper analysis is probably necessary, but nevertheless I'm
not convinced mapping type is the problem. The list of possible answers
to the question of why my pointing models don't match Meredith's:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The new mapping is shifting â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;RA / Dec mapping did change centroid locations, but not really for the
better. A deeper analysis is probably necessary, but nevertheless I'm
not convinced mapping type is the problem. The list of possible answers
to the question of why my pointing models don't match Meredith's:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The new mapping is shifting the centroid&lt;/li&gt;
&lt;li&gt;The centroiding method I'm using is different / incorrect&lt;/li&gt;
&lt;li&gt;There is still something in the pointing we haven't caught&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The lack of systematics suggests that the third option is not correct.
The first seems the most likely, but also the most difficult to track
down. I don't know where to go with #2.
I've updated the code so that the pointing model correction offsets in
RA/Dec are written to the FITS header. This will be the standard in all
future runs for individual observations. The calculation of this offset
post-mapping is straightforward but it's nice to have a redundant error
check.
The report for Monday will be kind of empty, sadly. However, I think I
can say that I'll now move on to testing the previous problems we faced,
in particular that we could not match the pointing across whole fields
(L111). If THAT is fixed, then at least we know that whatever my
pipeline is doing differently (e.g. PA at all times...) is useful if not
100% correct.
I'll need to be in the office to test the field mappings, though,
because ds9 display doesn't work well over wireless. I'll do a remote
run of the individual L111 and W5 maps to compare to previous ones.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Pointing update</title><link href="https://keflavich.github.io/blog/pointing-update.html" rel="alternate"></link><published>2008-08-01T22:30:00-06:00</published><updated>2008-08-01T22:30:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-01:/blog/pointing-update.html</id><summary type="html">&lt;p&gt;I believe I've completely dealt with the projection issues. There are a
lot of new plots available now, pretty much everything for Jun/Jul 05
and July 07. Low on my to-do list is the rest of the pointing model
tests.
My conclusion now is that I can't match the â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I believe I've completely dealt with the projection issues. There are a
lot of new plots available now, pretty much everything for Jun/Jul 05
and July 07. Low on my to-do list is the rest of the pointing model
tests.
My conclusion now is that I can't match the 3-4&amp;quot; RMS in dAlt and dAz.
Even with aggressive sigma-rejection of outliers, I only get down to
~10&amp;quot; RMS (which adds to ~15&amp;quot; RMS). My calculated pointing models differ
significantly from Meredith's, but not extremely so for 0707.
The code I've used to generate the plots is centroid_plots.pro under
plotting/. Using that code, I am able to essentially reproduce each
change made in do_the_pointing besides the distortion mapping. Because
of the weak dependence of the pointing model on altitude, even errors on
the scale of precession won't really hurt the pointing model
calculations. The only unanswered question I think may be responsible
for some errors - but not enough, I think - is whether eq2hor/hor2eq
could be double-correcting for aberration and nutation, but this
wouldn't affect the actual data reduction. It WOULD affect my plotting!
I think my next test is to try to coadd different epochal data for
particular fields, e.g. l001, l033. Not l000 because of the galactic
coordinate issue.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Update - Pointing Model</title><link href="https://keflavich.github.io/blog/update-pointing-model.html" rel="alternate"></link><published>2008-08-01T16:43:00-06:00</published><updated>2008-08-01T16:43:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-08-01:/blog/update-pointing-model.html</id><summary type="html">&lt;p&gt;Update - Pointing Model 7/31/08
The pointing model application &amp;quot;works&amp;quot; now, but I have a problem with
our model. We don't get down to the &amp;lt;10&amp;quot; RMS offset we're looking for.
The mean offsets are all zero, but the spread is more like 20&amp;quot;.
Example plots on milkyway: [see â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Update - Pointing Model 7/31/08
The pointing model application &amp;quot;works&amp;quot; now, but I have a problem with
our model. We don't get down to the &amp;lt;10&amp;quot; RMS offset we're looking for.
The mean offsets are all zero, but the spread is more like 20&amp;quot;.
Example plots on milkyway: [see attached PDFs too]&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;::&lt;/dt&gt;
&lt;dd&gt;/scratch/adam_work/plots/models_ptgmdl_0506.ps
/scratch/adam_work/plots/models_ptgmdl_0707.ps
/scratch/adam_work/plots/models_rawcsoptg_0506.ps
/scratch/adam_work/plots/models_rawcsoptg_0707.ps&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;On the left side are plotted &amp;quot;all&amp;quot; of the data points, on the right I've
used a two-iteration 3-sigma rejection to eliminate outliers to a small
degree.&lt;/p&gt;
&lt;p&gt;Top of these plots - as labeled - is altoff vs. alt, bottom is azoff vs.
alt.&lt;/p&gt;
&lt;p&gt;The red lines are a 2nd order polynomial fit to the data.&lt;/p&gt;
&lt;p&gt;The cyan lines are the pointing model corrections calculated by
Meredith.&lt;/p&gt;
&lt;p&gt;The 'ptgmdl' files have had the pointing model corrections applied. Note
that they are centered around offsets of zero.&lt;/p&gt;
&lt;p&gt;The 'rawcsoptg' files DO NOT have pointing model corrections applied,
and FZAO/FAZO have been REMOVED from the original pointing. Hence, these
are RAW CSO TELESCOPE POINTING plots.&lt;/p&gt;
&lt;p&gt;Things to note:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;In the 0707 'ptgmdl' set, the az is not quite centered at zero&lt;/li&gt;
&lt;li&gt;the 0506 'ptgmdl' set still has bulk offsets&lt;/li&gt;
&lt;li&gt;the ALTOFF and AZOFF are in delta-coordinate: this means that azoff&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;should be scaled by dividing by cos(alt) to put the y-axis in consistent
units. In most cases, this means that the already large spread at higher
altitudes is going to INCREASE. That means the problem is going to get
worse...
Questions:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;What is the main difference between my plots and Meredith's? i.e.  why is
my RMS ~an order of magnitude larger?&lt;/li&gt;
&lt;li&gt;Does more outlier rejection make sense? Is there any reason not to trust
certain observations if they visible turn out right?  PPSes are supposed to
be &amp;quot;absolute references&amp;quot; for the 1x1, 3x1 maps OLD PROBLEM: PPS and large
maps mapped with same 'pointing model' but ended up with different
coordinates&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pointing"></category></entry><entry><title>Milkyway /scratch disk usage</title><link href="https://keflavich.github.io/blog/milkyway-scratch-disk-usage.html" rel="alternate"></link><published>2008-07-31T22:40:00-06:00</published><updated>2008-07-31T22:40:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-07-31:/blog/milkyway-scratch-disk-usage.html</id><summary type="html">&lt;pre class="literal-block"&gt;
-bash-3.00$ du -h --max-depth=1 ../16K     ../lost+found80G     ../sliced1.3G    ../elatov70G     ../cleaned58G     ../mapped179G    ../sliced_polychrome4.0K    ../ironsides49G     ../coadd_mapped2.1G    ../pca_coadd2.8G    ../3pca_3iterations11M     ../centroid17M     ../lost34M     ../ptg_maps3.8G    ../montage31G     ../maps_from_polychrome93M     ../ptg_mmd32G     ../backup_from_kilauea31G     ../sharc1.8M    ../distortion6.9G    ../fake138G    ../adam_work136G    ../bgps_dir_from â€¦&lt;/pre&gt;</summary><content type="html">&lt;pre class="literal-block"&gt;
-bash-3.00$ du -h --max-depth=1 ../16K     ../lost+found80G     ../sliced1.3G    ../elatov70G     ../cleaned58G     ../mapped179G    ../sliced_polychrome4.0K    ../ironsides49G     ../coadd_mapped2.1G    ../pca_coadd2.8G    ../3pca_3iterations11M     ../centroid17M     ../lost34M     ../ptg_maps3.8G    ../montage31G     ../maps_from_polychrome93M     ../ptg_mmd32G     ../backup_from_kilauea31G     ../sharc1.8M    ../distortion6.9G    ../fake138G    ../adam_work136G    ../bgps_dir_from_polychrome815G    ../
&lt;/pre&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="administrative"></category></entry><entry><title>Galactic vs. RA mapping</title><link href="https://keflavich.github.io/blog/galactic-vs-ra-mapping.html" rel="alternate"></link><published>2008-07-31T20:57:00-06:00</published><updated>2008-07-31T20:57:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-07-31:/blog/galactic-vs-ra-mapping.html</id><content type="html">&lt;p&gt;They don't match up. This is a serious problem.
I think it's only a problem for the GC: ad2xy refuses to map things
right around that transition. I think it's OK elsewhere.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="pipeline"></category></entry><entry><title>Defining Pointing Terminology</title><link href="https://keflavich.github.io/blog/defining-pointing-terminology.html" rel="alternate"></link><published>2008-07-30T21:50:00-06:00</published><updated>2008-07-30T21:50:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-07-30:/blog/defining-pointing-terminology.html</id><summary type="html">&lt;p&gt;There has been a lot of confusion about pointing terminology.&lt;/p&gt;
&lt;p&gt;CSO pointing model: the telescope pointing model used and written as a
black box&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;has already been corrected for aberration/nutation&lt;/li&gt;
&lt;li&gt;is in current epoch coordinates (e.g. J2007.34)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Instrument-specific correction to pointing model&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;??? also referred to as 't â€¦&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;There has been a lot of confusion about pointing terminology.&lt;/p&gt;
&lt;p&gt;CSO pointing model: the telescope pointing model used and written as a
black box&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;has already been corrected for aberration/nutation&lt;/li&gt;
&lt;li&gt;is in current epoch coordinates (e.g. J2007.34)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Instrument-specific correction to pointing model&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;??? also referred to as 't terms'&lt;/li&gt;
&lt;li&gt;is offset between CSO pointing model and real locations&lt;/li&gt;
&lt;li&gt;should be a function of alt (and maybe az)&lt;/li&gt;
&lt;li&gt;is recorded in &amp;quot;RPC&amp;quot; files&lt;/li&gt;
&lt;li&gt;is in units of distance on the sky: delta-RA and delta-DEC, or
delta-ALT and delta-AZ will be in the same units, while if they were
in coordinate units delta-RA and delta-AZ would have to be scaled by
1/cos(DEC) or 1/cos(ALT) respectively&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FAZO and FZAO: Fixed Azimuth Offset and Fixed Zenith Angle Offset&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;these are ambiguously defined in the pipeline code&lt;/li&gt;
&lt;li&gt;???? FAZO/FZAO include both the functional instrument specific
pointing offset and any manual changes made at the telescope [manual
only relevant to 2007 observations]&lt;/li&gt;
&lt;li&gt;???? or are these JUST fixed offsets, and the instrument specific
corrections are not included? Either way, how can I separate out
manually-applied fixed offsets from fitted-model offsets?&lt;/li&gt;
&lt;/ul&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="documentation"></category><category term="pointing"></category></entry><entry><title>New Pipeline to CVS</title><link href="https://keflavich.github.io/blog/new-pipeline-to-cvs.html" rel="alternate"></link><published>2008-07-30T21:36:00-06:00</published><updated>2008-07-30T21:36:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-07-30:/blog/new-pipeline-to-cvs.html</id><summary type="html">&lt;p&gt;Open topic - what needs to be done to put the new pipeline on the CVS?&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Under the assumption that it will be used by others, the
documentation needs to be complete.&lt;/li&gt;
&lt;li&gt;Needs to be compatible with current pipeline (no name overlap)&lt;/li&gt;
&lt;li&gt;Have to fix / update some Goddard astrolib routines that â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;Open topic - what needs to be done to put the new pipeline on the CVS?&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Under the assumption that it will be used by others, the
documentation needs to be complete.&lt;/li&gt;
&lt;li&gt;Needs to be compatible with current pipeline (no name overlap)&lt;/li&gt;
&lt;li&gt;Have to fix / update some Goddard astrolib routines that have short
integer for loops and need long integer for loops
Which ones?&lt;/li&gt;
&lt;li&gt;Probably need to add instrument specific pointing model corrections
for non-BGPS observations&lt;/li&gt;
&lt;/ol&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="cvs"></category><category term="pipeline"></category></entry><entry><title>BOLOCAM PIPELINE BLOG</title><link href="https://keflavich.github.io/blog/bolocam-pipeline-blog.html" rel="alternate"></link><published>2008-07-30T21:30:00-06:00</published><updated>2008-07-30T21:30:00-06:00</updated><author><name>Adam (adam.g.ginsburg@gmail.com)</name></author><id>tag:keflavich.github.io,2008-07-30:/blog/bolocam-pipeline-blog.html</id><summary type="html">&lt;p&gt;Guy pointed out in the CU meeting today that we need a better way to
keep track of changes / problems / etc. The wiki's kind of a pain, and
this will serve as something of a replacement for the e-mail-only
conversations that have been going on with the Software Power Team â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Guy pointed out in the CU meeting today that we need a better way to
keep track of changes / problems / etc. The wiki's kind of a pain, and
this will serve as something of a replacement for the e-mail-only
conversations that have been going on with the Software Power Team.&lt;/p&gt;
</content><category term="bgps"></category><category term="googlepost"></category><category term="administrative"></category></entry></feed>