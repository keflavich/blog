<!DOCTYPE html>
<html lang="en">
<link rel="stylesheet" type="text/css" href="https://keflavich.github.io/blog/theme/css/style.css" />
<link rel="icon" type="image/gif" href="https://keflavich.github.io/blog/theme/favicon8.ico">
<head>
    <base href="https://keflavich.github.io/blog">
        <title>Adam Ginsburg's blog - pipeline</title>
        <meta charset="utf-8" />
        <link href="https://keflavich.github.io/blog/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Adam Ginsburg's blog Full Atom Feed" />
<!-- Using MathJax, with the delimiters $ -->
<!-- Conflict with pygments for the .mo and .mi -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "inherit !important"}},
    'div.typeset': { 'text-align': 'left'}
    },
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']],processEscapes: true}
    });
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js"]
    }
    MathJax.Hub.Register.StartupHook("HTML-CSS Jax Ready",function () {
    var VARIANT = MathJax.OutputJax["HTML-CSS"].FONTDATA.VARIANT;
    VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
    VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
    VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
    VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
    });
    MathJax.Hub.Register.StartupHook("SVG Jax Ready",function () {
    var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;
    VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
    VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
    VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
    VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
    });
</script>

<script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>
        
</head>

<body id="base" class="home">


    <header id="banner" class="body" >
        <div id="header" style='background-image: url("https://keflavich.github.io/blog/images/GC_4096sq_bolo.png"); background-position:left; min-heigt: 200px;  background-repeat: no-repeat; max-width: 80%;'>
            <h1 style="color: #C4C4C4;"><a class="header" href="https://keflavich.github.io/blog">Adam Ginsburg's blog <strong></strong></a></h1>

            <nav id="menu"><ul id="menulist">
                <li><a href="https://www.adamgginsburg.com">Homepage</a></li>
                <li><a href="/index.html">Blog Index</a></li>
                <li><a href="/category/bgps.html">BGPS Blog</a></li>
                <li><a href="/category/publications.html">Publications</a></li>
                <li><a href="/archives.html">Archives</a></li>
                <li><a href="/tags.html">Tags</a></li>
            </ul></nav><!-- /#menu -->
        </div>
    </header><!-- /#banner -->

  <div id="sidebar">
    <ul>
      <li>
        <h3 id='recent_header'>Recent Posts</h3>
        <ul>
              <li class="post">
                  2011/12/31
                  <br>
                  <a href="https://keflavich.github.io/blog/flow-charts.html">Flow Charts</a>
              </li>
              <li class="post">
                  2011/08/05
                  <br>
                  <a href="https://keflavich.github.io/blog/spatial-transfer-functions-revisit-4.html">Spatial Transfer Functions, revisit 4</a>
              </li>
              <li class="post">
                  2011/07/10
                  <br>
                  <a href="https://keflavich.github.io/blog/minor-ongoing-problems.html">[minor] Ongoing problems...</a>
              </li>
              <li class="post">
                  2011/05/24
                  <br>
                  <a href="https://keflavich.github.io/blog/astrophysical-signal-modeling.html">Astrophysical Signal Modeling</a>
              </li>
              <li class="post">
                  2011/05/22
                  <br>
                  <a href="https://keflavich.github.io/blog/psf-modeling.html">PSF modeling</a>
              </li>
        </ul>
      </li>
    
    </ul>
  </div><!-- end #sidebar -->

  <div id="content">
<section id="content">

<ul id="post-list">
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/deconvolve-and-epochs.html" rel="bookmark" title="Permalink to Deconvolve and Epochs">
                    Deconvolve and Epochs</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-04-05T18:12:00-06:00"> 2011/04/05 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>I've spent a large portion of the last week working on the deconvolver.
I found <a class="reference external" href="http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html">previously</a> that a reconvolved map does a better job of
restoring flux than the straight-up deconvolved map for point sources /
pointing observations.
However, the same update broke the regular mapping modes, leading to
horrible instability in the mapping routines for large maps such as W5.
Curiously, it seems that the aspect that breaks is the weighting;
somehow the noise drops precipitously in certain bolometers, leading to
extremely high weights. Perhaps they somehow dominate the PCA
subtraction and therefore have all their noise removed?
Either way, there are a few large-scale changes that need to be made:</p>
<ol class="arabic simple">
<li>Since Scaling and Weighting are now done on a whole-timestream basis,
we should only map single epochs at once and coadd them after the
fact. This approach will also help relieve RAM strain. Since it
appears that individual observations are now reasonably convergent
with the proper treatment of NANs in the deconvolution scheme, it
should be possible to take any individual map and coadd it in a
reasonable way.</li>
<li>Bolometers with bad weights need to be thrown out. Alternatively, and
more appropriately, I need to discover WHY their weights are going
bad.</li>
</ol>
<p>We also need to explore different weighting schemes.</p>
<ol class="arabic simple">
<li>1/Variance over whole timestream (current default)</li>
<li>1/Variance on a per-scan basis (previous default) [based on PSDs]</li>
<li>Minimum Chi<sup>2</sup> with Astrophysical Model (??)</li>
<li>Min Chi<sup>2</sup> on a per-scan basis?</li>
</ol>
<p>Because of the extensive testing this will require, it is really
becoming essential that we develop an arbitrary map creation &amp; testing
routine.</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/progress-but-still-ds1-ds5-issues.html" rel="bookmark" title="Permalink to Progress, but still ds1-ds5 issues">
                    Progress, but still ds1-ds5 issues</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-03-30T02:47:00-06:00"> 2011/03/30 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>ds1 and ds5 agree pretty well with the recent upgrades to delining and
deconvolution. However, there are still counterexamples, e.g.
101208_o13, in which ds5 &lt; ds1:</p>
<img alt="" src="http://4.bp.blogspot.com/-fIJHF_x5mBI/TZI0cryJfbI/AAAAAAAAGDI/GsNfLRGNZAk/s200/101208_o13_raw_ds1.nc_indiv13pca.png" />
<img alt="" src="http://2.bp.blogspot.com/-QRhiz8W9RDc/TZI0dGUR4UI/AAAAAAAAGDQ/WC8eLQd6_Z0/s200/101208_o13_raw_ds5.nc_indiv13pca.png" />
<p>The 'fitted' values agree better than the 'measured' values now that
NANs are treated properly.
Spent a few hours today trying to figure out if weighting can explain
the difference between ds1 and ds5; it appears to make up for most of it
so I'm doing some more experiments. Why is there so much parameter
space? Why can't weighting just work? It doesn't....
also wasted a few hours trying to write a python drizzling algorithm,
which unfortunately is impossible so I had to resort to an inefficient
for loop.
Finally got some minor results. It really looks like there is a trend
pushing up the recovered flux (i.e. higher volts/Jy) for ds5 over ds1.
There is a discrepancy between map types for ds1 but not for ds5, which
is actually backwards from what I would have expected, since ds1 will
get better-sampled maps.</p>
<img alt="" src="http://2.bp.blogspot.com/-ARaSL7ZdDmc/TZKRcE01DnI/AAAAAAAAGDY/YMZRpRo53Hw/s320/uranus_dcfluxes_dec2010_nomask_ds1_13pca_fits_map10.png" />
<img alt="" src="http://3.bp.blogspot.com/-pWtggp0vSP4/TZKRcwZ_SrI/AAAAAAAAGDg/IqVHQSprkL8/s320/uranus_dcfluxes_dec2010_nomask_ds5_13pca_fits_map10.png" />
<p>Luckily, the difference between peak fitting and &quot;measuring&quot; results in
very small (insignificant) changes to the calibration curve (recall
fitting is direct gaussian fitting; 'measuring' is using the
gaussian-fit width and total flux in an ellipse to infer a peak assuming
a point source):</p>
<img alt="" src="http://2.bp.blogspot.com/-E-FDTTj-4Ik/TZKVyUA8zBI/AAAAAAAAGDo/9NGubgLWBvo/s320/uranus_dcfluxes_dec2010_nomask_ds5_13pca_fits_map10.png" />
<img alt="" src="http://3.bp.blogspot.com/-GdyxFnmwQ7g/TZKVykSg57I/AAAAAAAAGDw/PPVXtfAxW0s/s320/uranus_dcfluxes_dec2010_nomask_ds5_13pca_map10.png" />
<p>Since this work has all been done for the 'bootstrapping' observations
that are supposed to tell us if different map sizes are compatible, I
have included the map sizes in the diagrams now. However, to really
understand the ds1/ds5 difference, there are much better data sets,
which I'm now reprocessing using the new and improved methods.
(the Whole BGPS is also processing with the new methods in the
background, though since the methods are being updated live there may be
more changes and it will have to be re-run.... initial looks at W5 are
BAD but L030 is GOOD (bordering on amazing))</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/careful-comparison-of-ds1-and-ds5.html" rel="bookmark" title="Permalink to Careful comparison of ds1 and ds5">
                    Careful comparison of ds1 and ds5</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-03-29T15:23:00-06:00"> 2011/03/29 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>I looked very closely at the timestream and maps of 101208_o11 and had
a pretty hard time figuring out why the data were different, but it
looked like the data really did differ on a point-by-point basis
(according to pyflagger). The only conclusion I was able to draw is that
the scaling must be off. I realized that the scaling was being done
before delining. I moved scaling from readall_pc to premap, and it
brought at least this one source into agreement. Time to run ds1-ds5
comparisons again!
(this means that ds1 data MUST have deline run on it, but ds5 data
doesn't really need it)
Here are examples of ds1 and ds5 timestreams, with and without scaling,
and ds1 with and without delining:</p>
<img alt="" src="http://4.bp.blogspot.com/-KR_NYG31_O0/TZECtBAgqFI/AAAAAAAAGCg/1jC9Ys2r9Iw/s200/101208_o11_ds5_uranus_indivtesttimestream011_plots_20_bolo02.png" />
<img alt="" src="http://3.bp.blogspot.com/-HbK-hAXjSDs/TZECtUNe8AI/AAAAAAAAGCo/i4fsH12Iw8Y/s200/101208_o11_ds1_uranus_indivtest_delinetimestream011_plots_20_bolo02.png" />
<img alt="" src="http://3.bp.blogspot.com/-edXLnDrrt5o/TZECt0No8oI/AAAAAAAAGCw/QjHg1ScBHG0/s200/101208_o11_ds1_uranus_indivtesttimestream011_plots_20_bolo02.png" />
<img alt="" src="http://1.bp.blogspot.com/-4NIxFxEQ1jU/TZECuDJ1fVI/AAAAAAAAGC4/tGE5tDH_168/s200/101208_o11_ds1_uranus_indivtest_deline_noscaleacbtimestream011_plots_20_bolo02.png" />
<img alt="" src="http://2.bp.blogspot.com/-DfIepZXXCFc/TZECuhm8lwI/AAAAAAAAGDA/Awp60ZuPGps/s200/101208_o11_ds5_uranus_indivtest_noscaleacbtimestream011_plots_20_bolo02.png" />
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/trying-to-bootstrap.html" rel="bookmark" title="Permalink to Trying to bootstrap">
                    Trying to bootstrap</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-03-28T02:01:00-06:00"> 2011/03/28 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>I've concluded, based on previous posts
<a class="reference external" href="http://bolocam.blogspot.com/2011/02/downsampling-why-is-dec-2010-different.html">http://bolocam.blogspot.com/2011/02/downsampling-why-is-dec-2010-different.html</a>,
<a class="reference external" href="http://bolocam.blogspot.com/2011/03/revisiting-calibration-yet-again.html">http://bolocam.blogspot.com/2011/03/revisiting-calibration-yet-again.html</a>,
and
<a class="reference external" href="http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html">http://bolocam.blogspot.com/2011/03/workaround-for-individual-maps.html</a>,
that ds5 is a problem primarily for undersampled images, i.e. those
taken in the normal mapping mode. This makes bootstrapping a bit tricky.</p>
<p>There are two options:</p>
<blockquote>
<ol class="arabic simple">
<li>Map Uranus and AFGL 4029 both in Volts and figure out what flux density
AFGL 4029 must have to lie on that curve</li>
<li>Map Uranus and compute a calibration curve, apply that calibration curve
to AFGL 4029, and then compare derived flux densities.</li>
</ol>
</blockquote>
<p>Both have the major problem that the individual AFGL 4029 maps will
forcibly be undersampled if I use ds5 data (which is normally OK,
according to the first paragraph). In the second case, it is possible to
co-add the images and get around the under-sampling issue, while in the
first case it is not because of the dependence on total loading
(MEANDC).</p>
<p>The real problem is that the whole goal of these observations was to
compare the different observing methods and see if they agree (1x1, 3x1,
pointing, etc.) since the pointing-style observations were used to
calibrate the others. But if the 1x1s are just straight-up unreliable,
how can we do the comparison? I think the co-added AFGL 4029 is the only
option, but then how do I test if it's correct? It would be really nice
to have AFGL 4029 observed with both scan types...</p>
<p>Alright, onto the data. After last week's fix of the bad bolos, I really
hope ds1 and ds5 agree. However, first glance at the cal curves says
they don't. ds1 and ds2 agree, but ds5 is different.</p>
<p>After checking them out with
<tt class="docutils literal">ds9 <span class="pre">*ds[15]*13pca*_map10.fits</span> <span class="pre">-scale</span> limits <span class="pre">-1</span> 1000 <span class="pre">-log</span> <span class="pre">-cmap</span> hsv <span class="pre">-match</span> colorbars <span class="pre">-match</span> scales <span class="pre">-match</span> frames wcs &amp;</tt>,
it appears that the _mask_ data is all... wrong, somehow. That's OK, I
want to discard the mask data anyway, so I'm happy to NOT spend time
debugging it.</p>
<p>Even after careful examination showing that the fits look good - and
noting that the fluxes look pretty much the same - the calibration
curves still look rather different. Unfortunately I had to spend 3 hours
debugging IDL plotting commands; I want to show the fits each time and
save them as postscripts. What does &quot;xyouts&quot; with &quot;/device,/normal&quot; do?
I thought that should plot x,y text at the coordinates specified in the
plot window... but no, that is JUST /normalize.</p>
<p>Anyway, realized that centroid_map treated NANs as zero. Added ERR
keyword (with a reasonable estimate of the error) in centroid_map to
ignore NANs. It looks like improper treatment of NANs is responsible for
a lot of the scatter seen in the calibration plots.</p>
<p>There is a substantial difference between the &quot;fitted&quot; peak and the
&quot;measured&quot; peak (the latter computed by taking the sum of the pixels
divided by the area of the fitted gaussian). It looks like the
&quot;measured&quot; version is more robust, at first glance. However,
unfortunately, for 101208_o11, the difference between ds1 and ds5
exists in both quantities. I will have to examine timestreams now...
ARGH.</p>
<p>Well, the timestreams show... that indeed the model is lower in ds1, but
not why. The &quot;remainder&quot; (new_astro; the stuff that never gets
incorporated into the model but DOES get incorporated into the map)
appears to be the same in both. Similarly, there is little to no flux in
the PCA atmosphere, so it's not simply being cleaned out. Where is the
flux going or coming from?</p>
<img alt="" src="http://3.bp.blogspot.com/-6lqGwWn650Q/TY_rgZKA9QI/AAAAAAAAGCI/Iq9O5mnmhl8/s320/101208_o11_ds1_uranus_indivtest_delinetimestream011_plots_20_bolo02.png" />
<img alt="" src="http://1.bp.blogspot.com/-7uBbEU1tAqM/TY_rgg6Jq9I/AAAAAAAAGCQ/iaGhOSb6gtQ/s320/101208_o11_ds5_uranus_indivtesttimestream011_plots_20_bolo02.png" />
<img alt="" src="http://1.bp.blogspot.com/-YKdZcNOjm7Q/TY_rg6tcvhI/AAAAAAAAGCY/fr4l8j-v4xI/s320/101208_o11_ds1_uranus_indivtesttimestream011_plots_20_bolo02.png" />
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/a-workaround-for-individual-maps.html" rel="bookmark" title="Permalink to A workaround for individual maps?">
                    A workaround for individual maps?</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-03-24T00:33:00-06:00"> 2011/03/24 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>I closely examined the timestreams of 101208_ob7 as I said I would
yesterday. Unfortunately, all I can do is describe the symptoms: the
first deconvolution model looks good, though it isn't quite as wide as
the true source (this should be OK; it is an iterative method, after
all). In the second iteration, though, the deconvolution model is even
smaller and lower amplitude... and it goes on like that.</p>
<p>Not deconvolving results in a healthy-looking clean map - pretty much
what you expect and want to see.</p>
<p>This implies that somehow removing an incomplete deconvolved model leads
to more of the source being included in the 'atmosphere' than would have
been included with no model subtraction at all. I'm not sure how this is
possible. In fact... I'm really quite sure that it is not.
The workaround is to only add positive changes to the model. This should
'definitely work' but may be non-convergent and assumes that the model
never has anything wrong with it at any iteration. I have demonstrated
that this works nicely for the two Uranus observations I tested on, but
now I have to run the gamut of tests.... the first (very obvious)
problem is that the background is now positive, which is dead wrong.
This workaround is not viable.
Alright, so what next? I've described the symptoms and that I think they
can't occur...
A closer look shows that new_astro is not being incorporated into
astro_model at the second iteration. Why?
AHA! Pyflagger + find_all_points reveals the problem!</p>
<pre class="literal-block">
Map value: 16.939728   Weighted average: 17.476323   Unweighted Average: 524.573136
scan,bolo,time:       mapped       astro       flags      weight       scale
3,  22,  12:     8.380408   13.561113    0.000000    0.025132    1.000000
4, 124,  23:   822.005327   13.561113    0.000000    0.000038    1.118012
4,  21,  38:   719.408983   13.561113    0.000000    0.000037    0.946721
5,  20,   7:     4.470616   13.561113    0.000000    0.013303    1.400000
5, 119,  23:   882.508303   13.561113    0.000000    0.000033    0.926887
5, 100,  35:   327.007750   13.561113    0.000000    0.000074    1.184397
5, 106,  38:   162.562098   13.561113    0.000000    0.000704    0.970000
6, 116,  27:   779.075640   13.561113    0.000000    0.000033    0.891768
8, 112,   3:   235.557390   13.561113    0.000000    0.000147    0.947130
9,   3,  14:   966.721773   13.561113    0.000000    0.000032    1.166292
9, 109,  41:   139.753656   13.561113    0.000000    0.000753    1.075269
10, 104,   8:   641.121935   13.561113    0.000000    0.000050    0.927827
10, 105,  24:     4.323228   13.561113    0.000000    0.032759    0.019022
10,  32,  36:   847.646990   13.561113    0.000000    0.000034    1.099406
11,  36,   9:   834.757586   13.561113    0.000000    0.000038    1.184751
11,  76,  37:   566.851891   13.561113    0.000000    0.000040    1.111000
12,  77,  13:   834.603090   13.561113    0.000000    0.000034    1.128464
12,  44,  44:   335.465654   13.561113    0.000000    0.000195    2.165775
13,  26,  17:    50.423143   13.561113    0.000000    0.004826    0.829932
13,  75,  29:   724.884676   13.561113    0.000000    0.000042    0.923077
14,  49,  21:   797.618990   13.561113    0.000000    0.000038    1.091918
14,  29,  33:   743.856012   13.561113    0.000000    0.000035    1.050360
15,  33,  13:   660.670099   13.561113    0.000000    0.000031    0.832180
15,  53,  25:   604.174286   13.561113    0.000000    0.000047    0.889922
15,  88,  40:     4.626476   13.561113    0.000000    0.008241    0.191489
17,  64,  20:   778.950533   13.561113    0.000000    0.000037    1.233108
18,  68,  30:   686.048136   13.561113    0.000000    0.000040    1.387283
</pre>
<p>Note that the lowest points have the highest weights. They DEFINITELY
shouldn't. What's wrong with them?
Apparently they have NO sensitivity to the sky! What?! There were a
bunch of bad bolos in Dec2010 that weren't flagged out... I wonder if
that problem persists to other epochs. Still, why does it only affect
pointing observations? Looking at the power spectra... the
large-timescale stuff becomes less dominant when scans are longer, but
the noisy spectra are still clearly noise-only. How odd.
Dropped to 112 good bolos from 134. That is much more believable. Have
to go back and fix Dec09 data too...
Even after fixing the bad bolos, the model drops with iteration number.
Why why why?
Well, looking at deconv_map, I've always returned the truly deconvolved
version, not the reconvolved... maybe the reconvolved really is better?
Again, this will have to be extensively tested, but it certainly gets
rid of the obvious/dominant error that the model kept dropping off.
However, FINALLY, based on how ridiculously good the reconv-deconvolved
map looks, I think I'm ready to do the extensive pipeline tests. So,
10dec_caltest has been started up with all of the new bolo_params
applied and the changes in place to deconv_map... let's see what
happens.</p>
<p>After that runs, I'll have to re-run the fit_and_plot routines</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/revisiting-calibration-yet-again.html" rel="bookmark" title="Permalink to Revisiting calibration yet again">
                    Revisiting calibration yet again</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-03-23T00:22:00-06:00"> 2011/03/23 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>The recent hiatus for paper revisions has, unfortunately, come to an
end.
Re-examining my work, I did quite a lot but encountered many dead-ends.
First, we would very much like to use an *identical* reduction process
on both the calibration data and the science data. That way, we could
feel very confident that the reduction process isn't introducing any
weird artifacts.
Unfortunately, I discovered early on that using ds5 data, 13 pca
components, and n&gt;1 iterations resulted in strange shape and flux
conservation failures. These errors do NOT occur in co-added maps; they
are unique to single-observation scans (though I don't recollect whether
2 scans is enough or if you need more).
I spent many hours banging my head against this problem and have never
gotten a satisfactory solution. But perhaps it's time to approach it
again. The map00 images look MUCH rounder and generally better than the
map10 images.
So, the problem I need to examine is the iterative process. Why does it
fail for single images? Is it something about the noise properties?
model00 looks fine... what gets put into the timestream? Examining
timestreams is a terrible and horrendous process... but what else can I
do?
The next step will be to examine the timestreams of a particular
observation. I think a good choice is 101208_ob7; the next observation,
101208_ob8 was a large-area map and it looks fine (i.e., it improves
with iteration). So I can start looking at the effects of polysub,
iteration, etc. on this particular source.
Of course, the stupid trick with the pipeline - every time - is that
&quot;fixing&quot; a problem for one source has a nasty tendency to break it for
all other sources. That's why there are so many flags that can be passed
around. Still, this is the approach I have to take...</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/downsampling-what-is-going-on.html" rel="bookmark" title="Permalink to Downsampling - what is going on?">
                    Downsampling - what is going on?</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-02-11T04:19:00-07:00"> 2011/02/11 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>The downsampling failure I <a class="reference external" href="http://bolocam.blogspot.com/2011/01/downsampling-has-serious-negative.html">noted</a> <a class="reference external" href="http://bolocam.blogspot.com/2011/01/more-evidence-that-downsampling-causes.html">previously</a> appears to be
illusory. It may be that the offset noted only holds for single-frame
images, in which there may be many blank pixels. It is possible - though
not certain - that the ds1 images were significantly higher than ds5
because more noise-only pixels were included with higher outliers; i.e.,
ds1 high-outlier noise was being compared to ds5 noise that was lower
amplitude.</p>
<p>What led to these conclusions? First, I was getting inconsistent results
looking at Uranus in particular - ds5 appeared to have higher fluxes
than ds1. This was inconsistent with <a class="reference external" href="http://bolocam.blogspot.com/2011/01/downsampling-has-serious-negative.html">earlier results</a> on OMC1. Partly,
this is because I switched from my <a class="reference external" href="http://4.bp.blogspot.com/_lsgW26mWZnU/TTiWWl3j3dI/AAAAAAAAF3I/Ef3WHEv5oXU/s1600/omc1_dstest_pixel-pixel.png">hacked-together plots</a> to the much
more refined <a class="reference external" href="http://code.google.com/p/bgpspipeline/source/browse/bgps_pipeline/plotting/compare_images.py">compare_images</a> script, which demonstrated the effect of
changing the cutoff of the comparison.</p>
<p>Also, I added in a Pearson Correlation Coefficient computation. Given a
single data set with the only difference being downsampling, the data
should be perfectly correlated even if there is a flux offset
(correlation should be 1, but the best fit slope should not be). It was
an indication of a problem when I started seeing correlation
coefficients &lt;0.90 for data that had already been sigma-cut; that means
that noise was being included in the correlation computations.</p>
<p>Therefore, the approach needed is to cut out the high pixels that are on
map edges. This I accomplished by adding an 'aperture' capability to the
compare_images code (for Uranus) and cropping using montage and a
wcs-based box for Orion.</p>
<p>The results... are ambiguous. Wow. In some sub-fields - within the same
co-added map - the agreement is near-perfect.</p>
<img alt="" src="http://1.bp.blogspot.com/-i20j3FEx758/TVR-PbQl7lI/AAAAAAAAGAY/imgMqceS9n8/s1600/v2.0_dl_omc_b_OMC4_ds1ds5_compare.png" />
<p>In others, ds1 is clearly &gt; ds5.</p>
<img alt="" src="http://4.bp.blogspot.com/-JsRH_ZQilWM/TVR-Os6vBSI/AAAAAAAAGAQ/JRR6Trm-weo/s1600/v2.0_dl_omc_b_OMC2_ds1ds5_compare.png" />
<p>What's going on? ds1 does look uniformly more smooth.
Note that the <em>disagreement</em> is nearly scale-free:</p>
<p>OK, so given the conclusion in Orion that ds1&gt;=ds5, what's the deal with
Uranus?</p>
<img alt="" src="http://3.bp.blogspot.com/-AosJ1vzcYSs/TVSZjIZ81fI/AAAAAAAAGAk/qVGeaJtkbPA/s320/101208_o10_ds1ds5_compare.png" />
<p>The first two comparisons are for 1x1° observations; in both cases ds1 &lt;
ds5, but by 6% and 24% respectively! The image of Uranus looks much
better (because of lack of parallel lines) in the second, more extreme
case. In both cases, the ds5 excess is nearly scale-free (not shown).</p>
<img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TVSZki9k9OI/AAAAAAAAGA0/t9LOGHOAL7Q/s320/101208_o10_ds1ds5_compare.png" />
<img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TVSZj1pglLI/AAAAAAAAGAs/-4153NoAQQ0/s320/101208_o11_ds1ds5_compare.png" />
<p>The 3x1s are also highly discrepant. #12 shows nearly perfect agreement,
albeit with high dispersion (low correlation) because of pixel-to-pixel
variations around the peak. #13 is the only observation with a huge DS1
excess. It also demonstrates very poor correlation. It looks like the
telescope got bumped for the ds5 data (which is not actually possible;
recall they're the same data set). What happened here? Maybe a glitch
that went unflagged (mad_flagger is off by default for individual
scans)?</p>
<img alt="" src="http://3.bp.blogspot.com/-9gwzGfDBCEk/TVSZllWeBxI/AAAAAAAAGA8/x3mg5RbMScs/s320/101208_o12_ds1ds5_compare.png" />
<img alt="" src="http://3.bp.blogspot.com/-9gwzGfDBCEk/TVSZllWeBxI/AAAAAAAAGA8/x3mg5RbMScs/s320/101208_o13_ds1ds5_compare.png" />
<p>In observations 4 and 5, we're looking at a 40-50% excess in ds5! What
the heck? There really is no clear explanation for this.</p>
<img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TVSaYfZx0WI/AAAAAAAAGBE/cWbbBQCJOvk/s320/101208_ob4_ds1ds5_compare.png" />
<img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TVSaZM27sqI/AAAAAAAAGBM/XR-6pttUcBo/s320/101208_ob5_ds1ds5_compare.png" />
<p>But... what? Magically, they come into perfect agreement when the scan
axis nearly lines up with the coordinate axis! Or, is this just an
effect of the worse weather on night 2?</p>
<img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TVSaaP6ISNI/AAAAAAAAGBU/PvN5aFOxBAQ/s320/101209_ob5_ds1ds5_compare.png" />
<p>Next thing to try: masked source map comparison. Unfortunately, masking
royally screwed up the long scans - probably because the initial polysub
didn't work. And masking in the individual point source maps did
nothing... so that pretty much rules out atmospheric oversubtraction,
doesn't it?
What else could be causing this offset? 0pca looks the same as 13pca,
give or take, so it's not the atmospheric subtraction. Could the
downsampling result in an offset in the bolo-scaling? Where else in the
process could things go wrong? Tomorrow, need to investigate .sav files
with pyflagger...</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/making-maps-faster.html" rel="bookmark" title="Permalink to Making maps faster">
                    Making maps faster</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-02-07T04:39:00-07:00"> 2011/02/07 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>The fundamental problem at this point is making the pipeline run faster.
At current speeds, with undownsampled data, it may take ~days to process
a single map. Ideas for faster processing:</p>
<ol class="arabic simple">
<li>Find out how long it takes to converge to 1%, 5%.... If it only
requires 10 iterations, that's a factor of 2 savings over current
strategies.</li>
<li>Use downsampled data of some sort if possible. Does DS2 match DS1?
How do we measure it? Flux-flux comparison and PSF point-source size
measurements are the most important. Need to automate PSF
comparison....</li>
<li>Can we use median-combined individual images as a 0th order model? I
bet the answer is 'yes' and will probably increase the speed of
convergence by a large amount. Tests to run? This is probably needed
if we are to split up the 'super-fields' into smaller sub-fields,
otherwise overlapping data will be used less effectively.</li>
<li>Find some way to keep bgps.raw, bgps.ra, bgps.dec, and other items
that are only used once on the HD during the iterative process. Is
there any way to separate out data in a struct in this manner?</li>
</ol>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/delining-maps.html" rel="bookmark" title="Permalink to Delining - Maps">
                    Delining - Maps</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-02-03T22:16:00-07:00"> 2011/02/03 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>First comment - delining has <strong>no effect</strong> on downsampled data. At least
for the 0709 epoch, there were NO lines AT ALL in the data. From 0-5 Hz,
it was just empty. So we don't have to worry about that... the problem
only affects fully-sampled data.
Then, onto map comparisons. Curiously, the noise levels don't drop after
delining. They actually go up a bit. This may be because of the effects
on PCA cleaning.
However, flux levels in the sources go up by 0-10%. As usual, the change
in flux changes from field to field without any obvious reason.
Example 1: A pointing field. The source is ~2% brighter in the delined
version, but otherwise the match between the two is nearly perfect.</p>
<img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUskr5xAMSI/AAAAAAAAF_M/J65CutNg9hM/s320/101208_ob8_compare.png" />
<img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUsksatOJSI/AAAAAAAAF_U/9X-rM6JQmCU/s320/101208_ob8_psd.png" />
<p>Example 2: A bigger map, where the flux recovery is much greater when
delining, but the background levels are also higher.</p>
<img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUsoBrKcQyI/AAAAAAAAF_c/junIzma1zg4/s320/101208_o11_compare.png" />
<img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUsoCFL1DiI/AAAAAAAAF_k/b1QrgajdlaE/s320/101208_o11_psd.png" />
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/delining-and-the-cleaning-process.html" rel="bookmark" title="Permalink to Delining and the Cleaning process">
                    Delining and the Cleaning process</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2011-02-03T19:49:00-07:00"> 2011/02/03 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>One item I forgot to mention last night was the effects of
lines/delining on
PCA subtraction. These should be the primary effects on the final map
for all
epochs except 2010, in which case the primary effect SHOULD be to reduce
substantial noise.
In the examples below, there are PSDs of whole timestreams (left) and
example timestreams from single scans (right). The first thing to note
is that
the delined timestreams still have correlated components in the line
region,
but they are suppressed - their amplitudes, and therefore their sort
order in
the PCA removal scheme, are changed. Since PCA cleaning is by its nature
adaptive
(the number of components remains fixed, but the order changes), these
effects
can be significant and dangerous. If the line noise is more correlated,
a PCA
component will be dedicated to removing it instead of atmospheric
signal.
Below are examples from l089 (epoch 0709) first. These have less
correlated
line noise and are more typical of BGPS observations. The first PCA
component,
the average, does not change much with PCA cleaning. However it is clear
that
the second component changes substantially, from large-amplitude
high-frequency
noise to small-amplitude variations that are very likely to describe
atmosphere.</p>
<hr class="docutils" />
<p>Example 1 - Zeroing out the lines:</p>
<img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUrs_QRBBHI/AAAAAAAAF9Y/BH4XEdrFdt0/s320/zero_pca_psds.png" />
<img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUrs_nWI6YI/AAAAAAAAF9g/1Dcr0zyMBvM/s320/zero_pca_timestreams.png" />
<p>Example 2 - Fitting and removing the lines:</p>
<img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUrs-f7qfqI/AAAAAAAAF9I/Dt3Kk9roeW8/s320/fitline_pca_psds.png" />
<img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUrs-_it9CI/AAAAAAAAF9Q/06KgQOS2vNA/s320/fitline_pca_timestreams.png" />
<p>Example 3 - Suppressing the lines with a non-fitted Gaussian:</p>
<img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUr_QHkPADI/AAAAAAAAF9o/n5ylgDCLKPw/s320/wingsupp_pca_psds.png" />
<img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUr_QnuPZfI/AAAAAAAAF9w/lt4rEB1Qlq0/s320/wingsupp_pca_timestreams.png" />
<hr class="docutils" />
<p>The next examples are from December 2010 observations of Uranus. In this
case, the correlated noise component is clearly dominant.</p>
<p>Zeroing lines:</p>
<img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCBUeD67I/AAAAAAAAF94/CCj9gbJOgk8/s320/zero_pca_psds.png" />
<img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCB4wFnSI/AAAAAAAAF-A/YgbjYlybcOc/s320/zero_pca_timestreams.png" />
<p>Fitted lines:</p>
<img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCCQNHurI/AAAAAAAAF-I/a5_FQ7bqUjI/s320/fitline_pca_psds.png" />
<img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUsCCtO7DTI/AAAAAAAAF-Q/wKBz0UhDruE/s320/fitline_pca_timestreams.png" />
<p>Non-fitted gaussian suppression:</p>
<img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUsCLgCRbmI/AAAAAAAAF-Y/WzHcr1E5q4s/s320/wingsupp_pca_psds.png" />
<img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCL5e9eGI/AAAAAAAAF-g/TgmNWbiJzbs/s320/wingsupp_pca_timestreams.png" />
<hr class="docutils" />
<p>Finally, these two are demonstrations of what you might expect to see
for a purely noiseless images of a planet (it was constructed from a
PSF). PCA is first:</p>
<img alt="" src="http://2.bp.blogspot.com/_lsgW26mWZnU/TUsCyELAZ1I/AAAAAAAAF-o/65L-rwGFscM/s320/noiselesssim_pca_psds.png" />
<img alt="" src="http://3.bp.blogspot.com/_lsgW26mWZnU/TUsCyRaYY7I/AAAAAAAAF-w/ZaRL4CPWw2E/s320/noiselesssim_pca_timestreams.png" />
<p>A single bolometer's timestream and PSD:</p>
<img alt="" src="http://4.bp.blogspot.com/_lsgW26mWZnU/TUsDgR4xcEI/AAAAAAAAF-4/udxMkuH6kio/s320/noiselesssim_deline_wingsupp_10hz_noscan_nsig0_psds_000.png" />
<img alt="" src="http://1.bp.blogspot.com/_lsgW26mWZnU/TUsDgtnBPNI/AAAAAAAAF_A/weQNMCgtrtc/s320/noiselesssim_deline_wingsupp_10hz_noscan_nsig0_timestreams_000.png" />
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
</ul><!-- /#posts-list -->
<p class="paginator">
            <a href="https://keflavich.github.io/blog/tag/pipeline.html">&laquo;</a>
    Page 2 / 5
        <a href="https://keflavich.github.io/blog/tag/pipeline3.html">&raquo;</a>
</p>
</section><!-- /#content -->
  </div>

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37306139-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-37306139-1');
    ga('send', 'pageview');
</script>
<script type="text/javascript">
  var disqus_shortname = 'adamginsburgsblog';
  (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
   })();
</script>
</body>
</html>
