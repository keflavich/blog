<!DOCTYPE html>
<html lang="en">
<link rel="stylesheet" type="text/css" href="https://keflavich.github.io/blog/theme/css/style.css" />
<link rel="icon" type="image/gif" href="https://keflavich.github.io/blog/theme/favicon8.ico">
<head>
    <base href="https://keflavich.github.io/blog">
        <title>Adam Ginsburg's blog</title>
        <meta charset="utf-8" />
        <link href="https://keflavich.github.io/blog/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Adam Ginsburg's blog Full Atom Feed" />
        <link href="https://keflavich.github.io/blog/feeds/{slug}.atom.xml" type="application/atom+xml" rel="alternate" title="Adam Ginsburg's blog Categories Atom Feed" />
<!-- Using MathJax, with the delimiters $ -->
<!-- Conflict with pygments for the .mo and .mi -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "inherit !important"}},
    'div.typeset': { 'text-align': 'left'}
    },
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']],processEscapes: true}
    });
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js"]
    }
    MathJax.Hub.Register.StartupHook("HTML-CSS Jax Ready",function () {
    var VARIANT = MathJax.OutputJax["HTML-CSS"].FONTDATA.VARIANT;
    VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
    VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
    VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
    VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
    });
    MathJax.Hub.Register.StartupHook("SVG Jax Ready",function () {
    var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;
    VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
    VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
    VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
    VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
    });
</script>

<script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>
        
</head>

<body id="base" class="home">


    <header id="banner" class="body" >
        <div id="header" style='background-image: url("https://keflavich.github.io/blog/images/GC_4096sq_bolo.png"); background-position:left; min-heigt: 200px;  background-repeat: no-repeat; max-width: 80%;'>
            <h1 style="color: #C4C4C4;"><a class="header" href="https://keflavich.github.io/blog">Adam Ginsburg's blog <strong></strong></a></h1>

            <nav id="menu"><ul id="menulist">
                <li><a href="https://www.adamgginsburg.com">Homepage</a></li>
                <li><a href="/index.html">Blog Index</a></li>
                <li><a href="/category/bgps.html">BGPS Blog</a></li>
                <li><a href="/category/publications.html">Publications</a></li>
                <li><a href="/archives.html">Archives</a></li>
                <li><a href="/tags.html">Tags</a></li>
            </ul></nav><!-- /#menu -->
        </div>
    </header><!-- /#banner -->

  <div id="sidebar">
    <ul>
      <li>
        <h3 id='recent_header'>Recent Posts</h3>
        <ul>
              <li class="post">
                  2013/05/20
                  <br>
                  <a href="https://keflavich.github.io/blog/bgps-point-source-recovery-experiment-23-results.html">BGPS Point Source Recovery - Experiment 23 results</a>
              </li>
              <li class="post">
                  2013/05/16
                  <br>
                  <a href="https://keflavich.github.io/blog/bgps-point-source-recovery.html">BGPS Point Source Recovery</a>
              </li>
              <li class="post">
                  2012/12/26
                  <br>
                  <a href="https://keflavich.github.io/blog/catalog-vs-image-shift-a-possible-solution-to-the-atlasgal-issue.html">Catalog vs Image shift? A possible solution to the ATLASGAL issue</a>
              </li>
              <li class="post">
                  2012/12/22
                  <br>
                  <a href="https://keflavich.github.io/blog/idea-multispectral-eigenimage-decomposition.html">Idea: Multispectral Eigenimage decomposition...</a>
              </li>
              <li class="post">
                  2012/12/15
                  <br>
                  <a href="https://keflavich.github.io/blog/pointing-cross-correlation-yet-again.html">Pointing & Cross-Correlation yet again</a>
              </li>
        </ul>
      </li>
    
    </ul>
  </div><!-- end #sidebar -->

  <div id="content">
<section id="content">
<h2>Articles in the bgps category</h2>

<ul id="post-list">
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/bgps-point-source-recovery-experiment-23-results.html" rel="bookmark" title="Permalink to BGPS Point Source Recovery - Experiment 23 results">
                    BGPS Point Source Recovery - Experiment 23 results</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2013-05-20T14:45:00-06:00"> 2013/05/20 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-keflavichgmailcom.html">Adam (keflavich@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>Experiment 23, run in mid-May 2013, created power-law synthetic astrophysical
sky maps with added point sources in order to examine the pipeline + bolocat's
ability to recover point source flux densities accurately.</p>
<p>For the purpose of the BGPS v2 paper, this data is incorporated into Section
5.3: the angular transfer function and comparison with other data sets.</p>
<p>The parameter space explored includes 3 steps in power-spectrum background,
$\alpha_{ps}=1,1.5,2$, which is the major parameter being explored.  A
background with $\alpha_{ps}=2$ is approximately what we measure in both HiGal
and the reproduced regions of the BGPS power-spectrum, so it's probably the
most realistic, but it is also very bad for the pipeline: most of the power is
on the largest angular scales.  $\alpha_{ps}=1$, on the other hand,
beautifully creates point-source-like structures.</p>
<p>These two images show the results of $\alpha_{ps}=2$ and $\alpha_{ps}=1$
skies respectively with faint point sources on top.  The point sources are more
pointy and stick out more in the $\alpha_{ps}=1$ situation, but the
$\alpha_{ps}=1$ map also looks more generally point-like, so there is greater
confusion.  If you believe that there are genuine point sources in the 1.1 mm
maps, the $\alpha_{ps}=1$ would actually be very difficult to deal with since
many extracted sources would actually be part of the background.</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/exp23_faint_ds2_astrosky_arrang45_atmotest_amp5.0E-05_sky-2.0_seed00_peak5.0E-03_smooth_withptsrc_label_compare.png" style="width: 800px;" />
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/exp23_faint_ds2_astrosky_arrang45_atmotest_amp5.0E-05_sky-1.0_seed00_peak5.0E-03_smooth_withptsrc_label_compare.png" style="width: 800px;" />
<p>We also explored two different sets of source brightnesses, 0.1-1 and 1-10
Jy/beam, uniformly distributed.  We picked a high source density, 500 in a
512x512 pixel map, to get decent source extraction statistics - the crowding is
still fairly low and does not significantly affect the extracted source
properties (only a few source overlap with others).  The bright sources are
obviously better-recovered than the faint, with good recovery for all of the
backgrounds explored.  The faint sources, on the other hand, were fairly
sensitive to the background.</p>
<p>The background levels used were $\sim1,2,10$ Jy/beam at the peak for the
$\alpha=2$ maps (they were lower for the other power-laws, so those will be
ignored from now on).  As described in the paper, the faint source recovery was
good for the low peak backgrounds, but recovery was essentially nonexistent for
the 10 Jy/beam background - point sources were not detected at all.</p>
<p>Despite the relative simplicity of this experiment, the data took 51 GB of
storage and took about half a day to run.</p>
<p>In principle, one would like to examine a range of different source
distributions (power-law flux distribution, upper/lower limits, sizes) on a
range of different power-spectrum backgrounds - for the purpose of the v2
paper, this approach would be thoroughly excessive.  However, I expect Tim will
be taking this sort of approach for the next paper.</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/bgps-point-source-recovery.html" rel="bookmark" title="Permalink to BGPS Point Source Recovery">
                    BGPS Point Source Recovery</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2013-05-16T12:21:00-06:00"> 2013/05/16 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-keflavichgmailcom.html">Adam (keflavich@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>In the last couple drafts of the BGPS paper (e.g. <a class="reference external" href="https://github.com/keflavich/bgpsv2/blob/master/v2_draft0515.pdf?raw=true">the May 15, 2013 draft</a>),
we've included a single simulation demonstrating the flux recovery of the
Bolocat:</p>
<img alt="" src="https://raw.github.com/keflavich/bgpsv2/master/figures/in_vs_out_bolocat_FLUX_40.png?login=keflavich&amp;token=8ff3096beef7bf15627a7a6b7363cb49" style="width: 800px;" />
<img alt="" src="https://raw.github.com/keflavich/bgpsv2/master/figures/in_vs_out_bolocat_FLUX_120.png?login=keflavich&amp;token=2c6e9896c5df6824e9881c94d6af542f" style="width: 800px;" />
<p>These figures are regarded as very important, as they demonstrate the
capability of recovering accurate flux density measurements from a realistic
sky using bolocat.</p>
<p>However, the above figures show a simulation only for one set of parameters,
with <span class="math">\(\alpha=1\)</span> in the power-law flux distribution, which unfortunately
is not realistic according to &quot;Figure 8&quot;:</p>
<img alt="" src="https://raw.github.com/keflavich/bgpsv2/master/figures/l030_higal_bgps_powerspec_compare.png?login=keflavich&amp;token=fa363ee3e28903c751c2a3c9f2b318a0" style="width: 800px;" />
<p>So I've started up a new experiment, experiment #23, to examine this problem.</p>
<p>The problem has a few layers:</p>
<ol class="arabic simple">
<li>The reason I used <span class="math">\(\alpha=1\)</span> is that it looks much like a realistic
BGPS map after processing, in the sense that most of the field is empty
but there are a few hundred sources in the map.  However, <span class="math">\(\alpha=1\)</span>
is not a realistic representation of the measured power spectra.</li>
<li><span class="math">\(\alpha=2\)</span> maps with the previous normalization had a peak value of
18 Jy, which resulted in heavily signal-dominated output maps that did not
resemble BGPS maps.</li>
<li>The normalization is tricky.  One of the key goals of the simulations was to
test the effect of different atmospheric to astrophysical signal ratios on
the angular transfer function; in order to accomplish this, it was necessary
to scale the atmospheric power based on the astrophysical power at its peak
in fourier space.  i.e., in real timestreams, we can measure the astrophysical
to atmospheric power ratio, but we have to perform that measurement somewhere
that the angular transfer function is known to be reliable.  This is done at
about 1 Hz.</li>
<li>The normalization is important because of the noise level.  In the
simulations, we use a fixed noise level of about 30 mJy in the timestreams
to match our best observations (though it is not difficult to scale this to
other levels).  This fixed noise level means that, for some normalizations,
all pixels are statistically significant.  Also, even though the noise level
is fixed, it will be higher because of intrinsic noise in a power-law
distributed map.</li>
<li>The normalizations used in experiment #21, the angular transfer function
measurement, were selected such that there would be high signal-to-noise at
all angular scales.  This means that white noise would not be dominant on
any angular scale, since white noise is equivalent to <span class="math">\(\alpha=0\)</span>.  So
it wasn't crazy to use these ridiculously high-flux maps, but it is not
feasible to use the same maps for analysis of point sources.  In maps for
which we're interested in small-angular-scale features (&lt;100&quot;), we want the
maps to be primarily noise-dominated with a handful of bright features
either caused by adding point sources directly or from the local peaks in
the power-law distributed flux.</li>
</ol>
<p>Some notes along the way:</p>
<blockquote>
<ul class="simple">
<li>Using a power-law background, the point-source sensitivity is much worse
than without a power-law background.   This is intuitive: a 100 mJy source
on a 200 mJy background (which may easily include power fluctuations on the
smallest scales of comparable magnitude) is not going to be recovered.</li>
<li>Doubly important: a 1 Jy source should have <em>peak</em> amplitude 1 Jy, but the
current method of adding point sources adds them as delta functions that are
later convolved, conserving the <em>total flux</em> rather than the <em>peak flux</em>.
This needs to be changed! (has been now)</li>
</ul>
</blockquote>
<p>Here are some examples of what the before/after look like with point sources added.
The first has bright sources, the second faint sources:</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/BGPS_exp23_bright.png" style="width: 800px;" />
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/BGPS_exp23_missingsrcs.png" style="width: 800px;" />
<p>With these new figures, the 40&quot; apertures work fine, but the 120&quot; apertures are
still utterly junk.  This does not make sense.</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/in_vs_out_bolocat_FLUX_40_testexp23.png" style="width: 800px;" />
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/in_vs_out_bolocat_FLUX_80_testexp23.png" style="width: 800px;" />
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/in_vs_out_bolocat_FLUX_120_testexp23.png" style="width: 800px;" />
<p>A careful analysis of a single source shows that something is wrong.  Here are some annular extractions
followed by the image:</p>
<pre class="literal-block">
Input Map:
reg sum npix    mean    median  min         max     var         stddev      rms
--- --- ----    ----    ------  ---         ---     ---         ------      ---
1   26.3323 22  1.19692 1.18083 1.10787     1.28825 0.00208826  0.0456975   1.1978
2   77.8553 74  1.0521  1.047   1.00426     1.123   0.000929507 0.0304878   1.05254
3   124.868 122 1.02351 1.02869 0.996566    1.04427 0.000260295 0.0161337   1.02363

Output Map:
reg sum         npix    mean        median      min         max         var         stddev      rms
--- ---         ----    ----        ------      ---         ---         ---         ------      ---
1   3.89157     23      0.169199    0.175204    0.086872    0.255151    0.00206254  0.0454152   0.175188
2   2.06843     74      0.0279517   0.0275116   -0.0695484  0.155258    0.00210834  0.0459167   0.0537554
3   0.502601    123     0.00408619  0.00629906  -0.121023   0.0834974   0.00143969  0.0379432   0.0381626

Backgrounds:
Input Map:
reg  sum      npix  mean      median    min       max      var          stddev     rms
---  ---      ----  ----      ------    ---       ---      ---          ------     ---
1    297.054  291   1.0208    1.02293   0.98094   1.05234  0.000313419  0.0177037  1.02096
3    2538.6   2618  0.969671  0.972413  0.859551  1.12495  0.0015557    0.0394423  0.970473

Output Map:
reg  sum      npix  mean        median      min        max       var         stddev     rms
---  ---      ----  ----        ------      ---        ---       ---         ------     ---
1    1.49461  291   0.00513613  0.00729431  -0.121023  0.133141  0.001586    0.0398247  0.0401545
3    5.83372  2618  0.00222831  0.00194597  -0.195075  0.181155  0.00211747  0.046016   0.0460699

Bolocat for this source:
In [200]: fields
Out[200]: ['FLUX_40', 'FLUX_40_NOBG', 'BG_40', 'FLUX_120', 'FLUX_120_NOBG', 'BG_120']

In [198]: [inp[61][f] for f in fields]
Out[198]: [0.1896538, 1.3536235, 0.38071653, 0.83893013, 10.77737, 0.42352486]

In [199]: [m20[61][f] for f in fields]
Out[199]: [0.18015364, 0.18674377, -0.016305592, 0.2868295, 0.29759517, -0.00027596406]
</pre>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/annulus_exam.png" style="width: 800px;" />
<p>With background apertures:</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/annulus_exam_bgapers.png" style="width: 800px;" />
<p>However, note that the background are computed using the <tt class="docutils literal">mmm.pro</tt>
sky-background estimation procedure over a range <span class="math">\(2r\)</span> to <span class="math">\(4r\)</span>
(i.e., 40-80&quot; and 120-240&quot; radius for the 40&quot; and 120&quot; diameter apertures).</p>
<p>The numbers shown by ds9 disagree fairly severely with those from bolocat.
In particular, it appears that the background estimate returned by <tt class="docutils literal">mmm.pro</tt>
is off by a factor of 2, in this case giving 0.42 instead of 0.97.  Turns out
this was due to an indexing error that did not affect the pipeline results in
any way.</p>
<p>Out of date analysis:
Bolocat's flux total in the 120&quot; aperture is 10.77 Jy/beam, background is 0.42
Jy/beam.  There are 218 pixels.  The resulting flux should be
(10.77-0.42*218/23.8), but this gives 6.9 instead of the expected 0.84.  Why?</p>
<p>If we do the same with the ds9 numbers, we get a total of 9.62 Jy/beam,
background 0.97 Jy/beam average, so: (9.62 - 0.97*218/23.8) = 0.74.
This is consistent with bolocat, and very very wrong.</p>
<p>If we take our background to be 1.02 instead of 0.97, we get 0.28 Jy/beam,
which is exactly the right answer according to the pipeline.  1.02 comes from
taking a much more local background subtraction from r=40 to r=80 arcsec,
which isn't really acceptable.  If we go from r=60 to r=120, the disagreement remains
fairly bad, with f=0.38 Jy/beam, but certainly a lot better.</p>
<pre class="literal-block">
Bolocat after the correction:
In [297]: [m20[61][f] for f in fields]
Out[297]: [0.18015364, 0.18674377, 0.00578439, 0.25477698, 0.29759517, 0.0041758944]

In [298]: [inp[61][f] for f in fields]
Out[298]: [0.1896538, 1.3536235, 1.0216572, 0.40137589, 10.77737, 1.0119308]
</pre>
<p>This may mean that we'll need to re-do aperture extraction with a tighter
background region everywhere.  I made the change to <tt class="docutils literal">object_photometry</tt>.</p>
<p>However, even with the change, even in the best case, <tt class="docutils literal">FLUX_120</tt> appears to
be totally unreliable.  <tt class="docutils literal">FLUX_80</tt> is acceptable with the change, but only for
bright sources (for faint sources, &lt;1 Jy, there is no recovery at all - I think this
must be an issue of the source brightness still not being calculated correctly):</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/in_vs_out_bolocat_FLUX_80_bright_1.0E-05.png" style="width: 800px;" />
<p>I'll have to continue this analysis tomorrow once the full suite of simulations
has completed, but I strongly suspect that we'll have to recommend strictly
against using <tt class="docutils literal">FLUX_120</tt> if the background is expected to be <span class="math">\(\alpha=2\)</span>
distributed.</p>
<div class="section" id="day-2">
<h2>Day 2</h2>
<p>The simulations have partly completed.  After correcting the error with
convolved point sources vs.  delta functions, I reset the flux distributions to
be 0.05 to 1.0 Jy for the &quot;faint&quot; distribution and 0.1 to 50.0 Jy for the
&quot;bright&quot; distribution (both with power-law distributions <span class="math">\(\alpha=2\)</span>).</p>
<p>The results can be summarized:</p>
<blockquote>
<ol class="arabic simple">
<li>In the presence of complex background, i.e power-law distributed flux density
with amplitude comparable to the detected source brightness, only the smallest
aperture (40&quot;) is reliable (i.e., recovers a flux in the input and
processed map).</li>
<li>The recovered flux density has a very high dispersion in the presence of
high-amplitude power-law flux.  &quot;Very high&quot; = <span class="math">\(\sigma \gtrsim 1\)</span>
around a mean of 1.</li>
<li>There is no evident dependence of the maps on the atmospheric properties.
Therefore, there's no sense in varying the atmospheric properties in the
simulations.</li>
</ol>
</blockquote>
<p>I decided the simulations needed changing again.  First, there was excessive
sampling in astro/atmo parameter space; this is not needed (see point 3).  More
important is the power-law distribution map's peak flux.  Also, it is more
important to get decent sampling of bright-ish sources than to have a
&quot;physically accurate&quot; point source distribution; the distribution of sources
does not affect the recovery, but it does affect the signal-to-noise of the
recovery <em>measurement</em>.  Please don't ask me to defend this statement; it would
require another 10 hours of computer time + me time that I really don't want to
allocate, but I'm confident that it is true.</p>
<p>The essential conclusion is that, for <span class="math">\(\alpha=2\)</span>, point source recovery
is only possible if the point source is brighter than the background, which is
a very intuitive result.  Background annulus subtraction isn't very effective
at pulling out sources.</p>
<p>Conclusions:</p>
<blockquote>
<ol class="arabic simple">
<li>These experiments show that source recovery is very poor in the presence of a
bright power-law background: it is not possible to reliably extract point
sources from a map filled with power-law distributed emission brighter than or
comparable to the point sources.</li>
<li>The 120&quot; apertures aren't really good for anything.</li>
<li>There is so much source-extraction parameter space out there that any
further study would really deserve its own paper.</li>
</ol>
</blockquote>
<p>Additional plots of interest:</p>
<p>40&quot; aperture in the presence of a bright background with faint sources:</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/in_vs_out_bolocat_FLUX_40_faint_5.0E-03.png" style="width: 800px;" />
<p>Versus the same with a faint background:</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/in_vs_out_bolocat_FLUX_40_faint_1.0E-03.png" style="width: 800px;" />
<p>Compare these to the 120&quot; equivalents (bright then faint background):</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/in_vs_out_bolocat_FLUX_120_faint_p5.0E-03.png" style="width: 800px;" />
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/in_vs_out_bolocat_FLUX_120_faint_p1.0E-03.png" style="width: 800px;" />
<p>It's fairly easy to see why there are issues with the bright background and the
120&quot; apertures.  In this image, bright background on the left, faint background
on the right, with faint sources (0.1-1 Jy).</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/faint_vs_bright_background.png" style="width: 800px;" />
<p>It's more helpful to look at that previous image with the source contours
superposed.  These images really give a nice feel for what it means to have
point sources subsumed in <span class="math">\(\alpha=2\)</span> background.</p>
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/exp23_faint_ds2_astrosky_arrang45_atmotest_amp5.0E-05_sky-2.0_seed00_peak5.0E-03_smooth_withptsrc_label_compare.png" style="width: 800px;" />
<img alt="" src="https://keflavich.github.io/blog/bgps/images/bgps-point-source-recovery/exp23_faint_ds2_astrosky_arrang45_atmotest_amp3.2E-05_sky-2.0_seed00_peak1.0E-03_smooth_withptsrc_label_compare.png" style="width: 800px;" />
</div>
<script type='text/javascript'>if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script> </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/catalog-vs-image-shift-a-possible-solution-to-the-atlasgal-issue.html" rel="bookmark" title="Permalink to Catalog vs Image shift? A possible solution to the ATLASGAL issue">
                    Catalog vs Image shift?  A possible solution to the ATLASGAL issue</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2012-12-26T23:02:00-07:00"> 2012/12/26 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>In the <a class="reference external" href="http://bolocam.blogspot.com/2012/12/pointing-cross-correlation-yet-again.html">previous post</a>, I came up with a final plot showing the
pointing offset was, on average, not significant, even in the ATLASGAL
overlap zone.
So why did the ATLASGAL group infer a net pointing offset?
The problem is probably one or two fields with a slight pointing offset,
but a huge number of source. &nbsp;l=1 has an offset of the right sign and is
the single most source-rich degree in the survey, with 368 sources.</p>
<img alt="" src="http://2.bp.blogspot.com/-ONF7C_v8rNk/UNpmXIEe6HI/AAAAAAAAHUI/kdf3pmUKyE0/s320/l001_catalog_image_compare.png" />
<p>This figure shows the v1 vs v2 source locations in grey, their average
and standard deviation in green, and the cross-correlation offset in
red. &nbsp;The plot is somewhat difficult to interpret, but it appears that
the v1 point sources are systematically more shifted to negative
longitudes than v2, and the point sources more than the maps themselves.
&nbsp;There may have been some reason sources were systematically selected at
more negative longitudes in the v1 catalog; around Sgr B2 there's a lot
of structure that had to be decomposed somehow but was not necessarily
&quot;source&quot;.
One thing to note is the reversal in left-right (in pixel space) vs the
positive/negativeness in longitude. &nbsp;The above plot is correct (negative
longitudes, as shown on the plot, are &quot;right&quot; in images), but most of my
other plots have the X-axis flipped.
In the end, after spending two weeks hammering my head against this, I
find no clear evidence for an offset &nbsp;between the BGPS and Herschel or
v1/v2 data overall or in the ATLASGAL fields. &nbsp;In any individual field,
that statement is not necessarily true.
Despite the strong statistical evidence, it is really hard to be really
sure about sub-pixel offsets, since the &quot;model&quot; image is never perfect.
&nbsp;I think we can safely state the ~1/2 pixel offsets (~3&quot;) but I just
don't feel confident about numbers below that range for ALL fields.</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/idea-multispectral-eigenimage-decomposition.html" rel="bookmark" title="Permalink to Idea: Multispectral Eigenimage decomposition...">
                    Idea: Multispectral Eigenimage decomposition...</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2012-12-22T02:53:00-07:00"> 2012/12/22 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>Can use BGPS + HiGal to look for correlated (thermal) components and
decorrelated (free-free) components. &nbsp;Obviously needs to be tried in GC
first.
Also, need to figure out a method to mitigate negative bowls in
unsharp-masking for herschel-bolocam comparison</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/pointing-cross-correlation-yet-again.html" rel="bookmark" title="Permalink to Pointing & Cross-Correlation yet again">
                    Pointing &amp; Cross-Correlation yet again</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2012-12-15T03:21:00-07:00"> 2012/12/15 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>Prompted in part by a <a class="reference external" href="http://arxiv.org/abs/1211.0741">recent ATLASGAL paper</a>&nbsp;identifying pointing
offsets of about 3&quot; in the BGPS, we revisit the BGPS pointing.
The ATLASGAL team compared the source locations in their catalog to
source locations in the Bolocam catalog by doing &quot;nearest-match&quot;
searches within a 40&quot; radius (see their Figure 8, reproduced here)</p>
<img alt="" src="http://1.bp.blogspot.com/-UJVCzHbaDCI/UMYpeAoulVI/AAAAAAAAHR4/cy5SIqL_HFQ/s320/ATLASGALvsBolocam.png" />
<p>Their comparison was over the range -10 &lt; l &lt; 21, so it only covered a
small fraction of the BGPS. &nbsp;It covered 13 fields with independent
pointing solutions, so it's possible that they have actually discovered
an offset only in some of our fields.</p>
<p>The catalog comparison, while interesting, is potentially quite flawed.
&nbsp;There's no guarantee that a source extraction algorithm will measure
source centers accurately when a &quot;source&quot; is just a local overdensity on
a complex background. &nbsp;Using source comparison will also lead to a bias
towards the most source-rich fields, e.g. l000 and l001, so an offset in
one of those fields would drastically affect the catalog offset.</p>
<p>There is a better way to compare pointing between two images that are
expected to be (nearly) identical. &nbsp;It is well-known that
cross-correlation is an effective technique for determining the offsets
between two identical images; I'll briefly summarize some of the
literature here.</p>
<p><a class="reference external" href="http://adsabs.harvard.edu/abs/2005A%26A...443..357G">Gratadour et al 2005</a>&nbsp;used a maximum likelihood estimator approach to
determine the &quot;best-fit&quot; offset between two images. &nbsp;This approach is
comparable to <a class="reference external" href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=5&amp;cad=rja&amp;ved=0CF0QFjAE&amp;url=http%3A%2F%2Fwww.optics.rochester.edu%2Fworkgroups%2Ffienup%2FPUBLICATIONS%2FMGS_OL08_EffRegistration.pdf&amp;ei=rC3GUJC9CcSA2AX3wYCIAg&amp;usg=AFQjCNHdUm0v8qYzNbvrqFRqByR_3svlSA&amp;sig2=GQztgkfvoQzAzQ7kzCJU2w">Guizar et al (2008)</a>, who <a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/18401-efficient-subpixel-image-registration-by-cross-correlation">implemented</a> a fast solution
for (highly) sub-pixel image registration in matlab. &nbsp;In order for the
image registration to be fast, it must operate in fourier space, but to
get sub-pixel registration in fourier space, you need to either pad
(which is slow, and increases memory use drastically) or fit some
functional form around the peak of the cross-correlation image. &nbsp;The
alternative approach implemented by Guizar utilizes the <a class="reference external" href="http://en.wikipedia.org/wiki/Fourier_transform#Basic_properties">Fourier scaling
theorem</a>&nbsp;to create a zoomed-in image of the peak pixel, which allows
you to get much higher precision for a much lower computational cost.
My innovation is to use the minimum $\chi^2$ estimator to determine the
goodness of fit and therefore error bars on the best-fit offset.</p>
<p>Because the $\chi^2$ value for each offset is simply determined by
sums and multiplication ($\chi^2 = \sum
\frac{x_i-\mu_x}{\sigma_{x_i}^2}$), we can compute each term that
goes in to the $\chi^2$ value independently with fourier transforms,
then create goodness-of-fit contours around the $\chi^2$ minimum. &nbsp;The
statistical requirement for this approach to make sense is that the
errors on the data are gaussian distributed, which is an assumption we
inevitably make for astronomical images. &nbsp;I believe there is also a
requirement that the errors are independent, which may be more difficult
to satisfy, but in the Bolocam images it is satisfied, especially when
multiple independent observations are combined.</p>
<p>Strictly, this approach can only be used when the model data have the
same multiplicative scale as the fitted data. &nbsp;The peak will never be
wrong using this method, but the errors could be incorrect if the model
and data are multiplicatively offset. &nbsp;In principle, this can be
resolved in the future using a <a class="reference external" href="http://en.wikipedia.org/wiki/Mellin_transform">Mellin transform</a>&nbsp;[see <a class="reference external" href="http://ecocodespace.wordpress.com/category/matlab/image-matching/fourier-mellin-transform/">this site</a>&nbsp;or
<a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/authors/7667">this</a> for
a matlab approach and <a class="reference external" href="http://www.fresnel.fr/perso/derrode/publi/Cviu01.pdf">this</a> for an academic paper
on it].</p>
<p>This is the approach I have implemented
at&nbsp; <a class="reference external" href="http://image-registration.rtfd.org/">image-registration.rtfd.org</a>. &nbsp;I used simulated test cases to
demonstrate that it is, indeed, effective and accurate. &nbsp;I used this
method to measure the offsets between the v2 data and the v1 data (which
should, in principle, be the same as the offsets between ATLASGAL and
v1) and the v2 vs Herschel Hi-Gal data (which should be zero).
There are actually a few methods implemented in image-registration, and
I compared those. &nbsp;There's a &quot;dft&quot; and a &quot;$\chi^2$&quot; approach, which are
the same (except $\chi^2$ includes realistic errors), a method where a
2D gaussian is fit to the peak of the cross-correlation image, and a
method where a 2nd-order Taylor expansion is performed around the peak
of the cross-correlation image. &nbsp;The latter two are <em>biased</em>. &nbsp;An
example comparison plot looks like this:</p>
<img alt="" src="http://1.bp.blogspot.com/-LtA6owJr_vc/UMZBLK394HI/AAAAAAAAHSI/tR4F0BnFSVs/s320/l000_catalog_image_compare_chi2contours.png" />
<p>The grey dots are catalog centroid positions offsets measured between v1
and v2. &nbsp;The green cross represents the mean and standard deviation of
the grey points. &nbsp;The other data points, as labeled, show the offsets
between the l000 images in v1 and v2 as measured by the method shown.
They all have errorbars plotted, but the errorbars are generally smaller
than the points. &nbsp;The dark spot seen behind the purple point shows the
$\chi^2$ contours out to 8-$\sigma$: the error in the offset is tiny,
sub-arcsecond. &nbsp;In this case, the offsets nearly agree:</p>
<p>l000 catalog dx: &nbsp;-0.31 +/- 0.68 &nbsp; dy: 1.48 +/- 0.64</p>
<p>l000 $\chi^2$ dx: &nbsp; 1.74 +/- 0.03 &nbsp;dy: 1.41 +/- 0.03</p>
<p>This field agreed nicely between v1 and v2.</p>
<p>The comparison to Hi-Gal is perhaps more important; HiGal's pointing is
calibrated based on multi-wavelength observations, some of which include
actual stars. &nbsp;It's a space-based mission, so its pointing is more
stable. &nbsp;And finally, being a space mission, there's a large dedicated
team instead of a single, part-time individual working on the data.
Our offsets from Hi-Gal are pretty small in general, though not
trivially small.</p>
<img alt="" src="http://1.bp.blogspot.com/-JyMtqE536LY/UMaEqOYBRxI/AAAAAAAAHSY/85nEo6rEc9k/s320/Offsets_XYplot.png" />
<p>And it turns out, the region that overlaps with ATLASGAL had more
serious pointing errors than the rest of the survey:</p>
<img alt="" src="http://2.bp.blogspot.com/-iXI7TUl1y9I/UMaHHXwN2oI/AAAAAAAAHSg/z3g51NHD0zk/s320/Offsets_XYplot_ATLASGALoverlap.png" />
<p>(note: both of the above plots are missing L=359 because I forgot it.
&nbsp;Fixing that now...)</p>
<p>The clearest problem field is l=15, with a longitude offset of -6&quot;
between v2 and HiGal.... that's not the question, though. &nbsp;Somehow I've
lost the code that did the v1-HiGal offsets; I'll have to re-write that
tomorrow and let it run...</p>
<p>Update 12/13: &nbsp;I've spent the last couple days clearing up some issues
with the offsets. &nbsp;The error bars should be MUCH smaller than in the
above plots. &nbsp;The means are pretty similar, though.
Short story: the offsets between v1 and Hi-Gal are greater in the
ATLASGAL overlap regions than elsewhere, and in the right general
direction, but not quite as serious as they claimed. &nbsp;In v2, the
ATLASGAL overlap fields and the rest of the survey have the same mean
offsets, and those offsets are small (-0.5&quot; in l, -1&quot; in b).
The problem now is the table. &nbsp;If everything made sense,
(v1-v2)+(v2-higal)+(higal-v1) = 0. &nbsp;But that clearly isn't the case,
which implies an error in the method, which sucks since I'm claiming
this method is superior to alternatives. &nbsp;It's possible that I'm
actually underestimating the errors against Hi-Gal - that can be fixed
relatively easily - but the magnitude of the error won't affect the
centroid measurements. &nbsp;So I probably need to investigate one case very
carefully. &nbsp;l050 is a big problem case, with vector sums &gt;1 pixel in
both directions. &nbsp;That will be my next line of investigation.
The approach will be:
-crop identical fields within l050 from v1, v2, herschel
-perform pointing comparison between them
-check that vector sum &lt; sum of errors
I think - and hope - the trouble is just that I'm using inconsistent
sub-fields to compare Herschel with the two different Bolocam versions,
which is possible because of the way I selected these sub-fields. &nbsp;I'll
do more careful cropping, and probably re-do this analysis
degree-by-degree (with $512^2$ fields, in the hope that it speeds up the
FTs).
Update 12/14:
I've now cropped identical sections in each of the survey, 1 square
degree (512 pixels) each - which is great for speed. &nbsp;As a sidenote, a
little line profiling revealed that the make_cross_plots
&nbsp;code was the slow point in the process, and it is dominated by savefig
calls, not ffts.
I've run a careful examination of self consistency on the l=0 field,
with positive results: the offsets agree to well within the errorbars
(though there is some residual error at the 0.5&quot; level).</p>
<img alt="" src="http://1.bp.blogspot.com/--3Q9h0Q1jA4/UMuUjQ33dCI/AAAAAAAAHS4/zSD3H26r5dA/s320/circular_selfconsistency.png" />
<p>However, a similar inspection of l=50 resulted in a major failure:</p>
<img alt="" src="http://2.bp.blogspot.com/-wlwvC26eTEk/UMuYZHU179I/AAAAAAAAHTI/Csf3mBSdbGI/s320/circular_selfconsistency.png" />
<p>In this case, the problem is caused by W51 being exactly on the field
edge, leading to huge cross-correlation power at dx=0, but spread over a
large y range. &nbsp;My first thought is to try to downweight the edges,
which can be achieved by &quot;zero-padding&quot; the noise image, but with high
values instead of zero... or alternatively, by setting the edge region
to zero smoothly.</p>
<p>OK, first thought: Bad idea. &nbsp;Increasing the noise along the edges
drastically increases the small-shift autocorrelation for the noise,
which in turn ends up ruling out the small shifts as a fit possibility.
&nbsp;I don't think this really makes sense mathematically, but each step
does. &nbsp;Why would increasing the noise along the edges make the $\chi^2$
fit worse?</p>
<p>This revealed a serious bug in the code that, luckily, only affected
non-uniform error maps. &nbsp;Basically, I had decomposed the $\chi^2$
equation wrong (which is as bad as it sounds).</p>
<p>That total mess has been resolved now. &nbsp;The image edges are downweighted
with a gaussian of 12 pixels, error=100 outside and weight=0 outside
(with weight^2 inside... best to just view the source if you really want
to know the details). &nbsp;The new versions of the above diagrams:</p>
<img alt="" src="http://4.bp.blogspot.com/-mjPyO7LkbGc/UMuxVgSxwZI/AAAAAAAAHTY/ilRnJRaAiOQ/s320/circular_selfconsistency.png" />
<img alt="" src="http://3.bp.blogspot.com/-rMiHxucSQuo/UMuxZSH63fI/AAAAAAAAHTg/W_IzmhcFCzo/s320/circular_selfconsistency.png" />
<p>Less than spectacular for l=50, but acceptable given the errors, which
are indeed significantly larger, as you might expect given the lower
total signal in l=50. Now I need to re-run the fits on every field.</p>
<p>OK, cool, last thing accomplished today (...by 8pm): offset comparison
by square degree for all fields. &nbsp;Again, I don't reproduce the magnitude
of the ATLASGAL-measured offsets, but the ATLASGAL fields are, on
average, more offset in longitude (to the negative) than the overall
average.</p>
<p>Curiously, for both v1 and v2, there appears to be a -1.5 deg shift in
latitude from Hi-Gal.</p>
<p>The vector sums are mostly sub-arcsecond, with most exceptions at l&gt;50.
&nbsp;l=59,64, and 65 are particularly bad - but l=50 isn't so bad. &nbsp;So I
should do the &quot;deep&quot; examination of one or two of those fields... who
knows what new errors I'll turn up?</p>
<p>Here's the new v1-ATLASGAL offset plot:</p>
<img alt="" src="http://3.bp.blogspot.com/-iv_FsACT958/UMvsyr90haI/AAAAAAAAHTw/g56hcK6hMCw/s320/Offsets_XYplot_v1-Hi-Gal_ATLASGALoverlap.png" />
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/cross-correlation-offsets-revisited.html" rel="bookmark" title="Permalink to Cross-Correlation Offsets Revisited">
                    Cross-Correlation Offsets Revisited</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2012-09-08T08:06:00-06:00"> 2012/09/08 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>Since last time (<a class="reference external" href="http://bolocam.blogspot.com/2009/03/43-relative-alignment-and-mosaicing.html">Taylor Expansion &amp; Cross
Correlation</a><a class="reference external" href="http://bolocam.blogspot.com/2012/03/new-coalignment-code.html">,</a><a class="reference external" href="http://bolocam.blogspot.com/2012/03/new-coalignment-code.html">Coalignment Code</a>), I have attempted to re-do the
cross-correlation with an added component: error estimates.
It turns out, there is a better method than the Taylor-expansion around
the cross-correlation peak. &nbsp;Fourier upsampling can be used to
efficiently determine precise sub-pixel offsets (<a class="reference external" href="http://www.mathworks.com/matlabcentral/fileexchange/18401-efficient-subpixel-image-registration-by-cross-correlation/content/html/efficient_subpixel_registration.html">matlab version</a>,
<a class="reference external" href="http://people.web.psi.ch/guizar_m/main/">Manuel Guizar, author</a>, <a class="reference external" href="http://www.opticsinfobase.org/view_article.cfm?gotourl=http%3A%2F%2Fwww%2Eopticsinfobase%2Eorg%2FDirectPDFAccess%2F6C566DF3-B5C5-B342-97F01180999C7632_148843%2Fol-33-2-156%2Epdf%3Fda%3D1%26id%3D148843%26seq%3D0%26mobile%3Dno&amp;org=University%20of%20Colorado%20at%20Boulder%20Library">refereed article</a>).
However, in the published methods just cited, there is no way to
determine the error - those algorithms are designed to measure offsets
between identical images corrupted by noise but still strongly dominated
by signal.
We're more interested in the case where individual pixels may well be
noise-dominated, but the overall signal in the map is still large.
So, I've developed a python translation of the above codes and then
some.
<a class="reference external" href="https://github.com/keflavich/image_registration">Image Registration on github</a>
The docstrings are pretty solid, but there is no overall documentation.
However, there's a pretty good demo of the simulation AND fitting code
here:
<a class="reference external" href="https://github.com/keflavich/image_registration/blob/master/doc/CrossCorrelationSimulation.pdf?raw=true">Tests and Examples</a>
The results for the Bolocam data are here (only applied to v2-Herschel
offsets):</p>
<img alt="" src="http://2.bp.blogspot.com/-PMJx-wX23w8/UErt7G3PqfI/AAAAAAAAHOQ/-5xD6ReBRGs/s320/Offsets_XYplot.png" />
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/how-does-bolocam-data-improve-greybody-fits.html" rel="bookmark" title="Permalink to How does Bolocam data improve greybody fits?">
                    How does Bolocam data improve greybody fits?</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2012-06-23T09:11:00-06:00"> 2012/06/23 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <img alt="" src="http://3.bp.blogspot.com/-c_JUkbALzlE/T-WIDgFQgpI/AAAAAAAAHM0/wQIBvsgQtQU/s320/longwav500_sn10_Herschelsn50_bb_test.png" />
<img alt="" src="http://1.bp.blogspot.com/-CZHBZFtEpC8/T-WIExxu5uI/AAAAAAAAHM8/wxR_0xFujm8/s320/longwav500_sn20_Herschelsn50_bb_test.png" />
<img alt="" src="http://3.bp.blogspot.com/-58ayoSrqcjU/T-WIF4NEwHI/AAAAAAAAHNA/ivNPdPGm5iY/s320/longwav500_sn5_Herschelsn50_bb_test.png" />
<p>Long wavelength data can be very useful for constraining the value of
beta in a greybody fit.</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/bolocat-v1-vs-v2.html" rel="bookmark" title="Permalink to Bolocat V1 vs V2">
                    Bolocat V1 vs V2</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2012-05-24T17:59:00-06:00"> 2012/05/24 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>I've done some very extensive comparison of v1 and v2. The plots below
are included in the current BGPS draft, but I'll go into more excessive
detail here. ALL plots below show Version 1 fluxes versus Version 2
fluxes using Bolocat V1 apertures. This means there are only two
possible effects in play:</p>
<ol class="arabic simple">
<li>Different fluxes in the v1 and v2 maps</li>
<li>Pointing (spatial) offsets between the v1 and v2 maps
[see&nbsp;<a class="reference external" href="http://bolocam.blogspot.com/2012/05/bgps-v2-pointing.html">http://bolocam.blogspot.com/2012/05/bgps-v2-pointing.html</a>]</li>
</ol>
<p>Therefore, the plots below are just different ways of visualizing the
same information. This holds true despite the fact that different
&quot;correction factors&quot; appear in different plots.</p>
<img alt="" src="http://3.bp.blogspot.com/-gGL8rEcNr20/T75tzRC4dJI/AAAAAAAAHHM/A8KeWkBtfmc/s320/total_ratiohistograms.png" />
<p>Ratios of v2 fluxes to v1 fluxes in the listed apertures. The curves
represent best-fit gaussian distributions to the data after excluding
outliers using a <a class="reference external" href="http://scikit-learn.org/dev/modules/generated/sklearn.covariance.MinCovDet.html">minimum covariance determinant</a> method</p>
<p>v1 vs v2 with a background subtracted around the source equal to the source
area (this was not reported in Bolocat v1, but is a tool Erik implemented so I
used it)</p>
<p>v1 vs v2 in 40&quot; apertures, as stated. &nbsp;There are y=x and y=1.5x lines plotted:
these are NOT fits to the data! &nbsp;The green line is a Total Least Squares linear
fit to the data weighted by the measured errors.</p>
<p>Source Mask &quot;aperture&quot;:</p>
<img alt="" src="http://1.bp.blogspot.com/-YS2Jtvz4Yy0/T75pixKkYsI/AAAAAAAAHFs/iEJHrsKsBk0/s320/total_v1v2_sourcemask_bg_fit_compare.png" />
<img alt="" src="http://1.bp.blogspot.com/-g-ZbEUUWEpY/T75pjj26FeI/AAAAAAAAHGE/rtdSRgoMQpo/s320/total_v1v2_sourcemask_fit_compare.png" />
<p>Same as above, but the best fit slope is steeper. The best explanation
for the steeper slope (i.e., v2 &gt; 1.5(v1)) is that more extended flux is
recovered in v2 around bright sources, therefore in the larger source
masks, there is greater flux than would be recovered if a simple 1.5x
corrective factor was applied.
80&quot; apertures</p>
<img alt="" src="http://2.bp.blogspot.com/-WKtlvnFbUF4/T75piyh8tVI/AAAAAAAAHF4/FROq508X6pU/s320/total_v1v2_80arcsec_fit_compare.png" />
<img alt="" src="http://1.bp.blogspot.com/-EHGNHIarslc/T75yqG_AmFI/AAAAAAAAHJg/ToAicG9ynmk/s320/total_v1v2_80_nobgarcsec_fit_compare.png" />
<p>Same for 120&quot; apertures:</p>
<img alt="" src="http://1.bp.blogspot.com/-ymBFW1Y5OhY/T75piwFYrJI/AAAAAAAAHFw/07ujRFCd_Ts/s320/total_v1v2_120arcsec_fit_compare.png" />
<img alt="" src="http://3.bp.blogspot.com/-PMkvtoJKNVs/T75yqPe16PI/AAAAAAAAHJk/QF041ok8yQ0/s320/total_v1v2_120_nobgarcsec_fit_compare.png" />
<p>For all 3 of the 40, 80 and 120&quot; apertures both, the 1.5x correction
factor is nearly perfect (agrees to &lt;5%). &nbsp;The background subtraction
seems to have different effects depending on aperture size. &nbsp;I welcome
Erik to comment on this, but I do not think it is particularly
important.
The figures below require some explanation. &nbsp;NONE of the circular
apertures use background subtraction in this comparison (i.e., compare
to the RIGHT column above).
These figures are histograms of the flux ratio within a given aperture
as a function of flux in the v1 aperture. &nbsp;From bottom to top, the flux
in the v1 aperture goes from 0.1 to 10 Jy. &nbsp;The X-axis shows the ratio
of the v2 flux to the v1 flux. &nbsp;The black dots with error bars represent
the best-fit gaussian distribution to each flux bin. &nbsp;The colorbar shows
the log of the number of sources; the most in any bin is about
10<sup>2.5</sup> ~ 300.
In short, there is some sign that the ratio of v2/v1 flux varies with v1
flux. &nbsp;This effect could be seen in the figures above since a linear fit
is imperfect. &nbsp;The effect is not very strong. &nbsp;Again, I believe the
explanation here is the changed spatial transfer function in v2.</p>
<img alt="" src="http://3.bp.blogspot.com/-bfrjMd2veR0/T75pzxm5_xI/AAAAAAAAHGs/SQ1LDR8_EoM/s320/ratio_twodhist_40.png" />
<img alt="" src="http://4.bp.blogspot.com/-unXyfhsIL1g/T75pkN6kWkI/AAAAAAAAHGQ/axiiWsEMO0M/s320/ratio_twodhist_80.png" />
<img alt="" src="http://2.bp.blogspot.com/-kJEMLqkaQak/T75pkNu78XI/AAAAAAAAHGM/Dh2T4m0cD-8/s320/ratio_twodhist_120.png" />
<img alt="" src="http://4.bp.blogspot.com/-ExDpIxfHO74/T75pkjjeKAI/AAAAAAAAHGk/pU3mE5uzcgM/s320/ratio_twodhist_sourcemask_nobg.png" />
<img alt="" src="http://3.bp.blogspot.com/-Pru74WRl-Hg/T75pkOL1YWI/AAAAAAAAHGU/qtrMl-w59SA/s320/ratio_twodhist_sourcemask.png" />
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/bgps-v2-pointing.html" rel="bookmark" title="Permalink to BGPS V2 pointing">
                    BGPS V2 pointing</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2012-05-23T23:59:00-06:00"> 2012/05/23 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>BGPS V2.0 pointing offsets relative to V1 and Herschel:</p>
<img alt="" src="http://4.bp.blogspot.com/-41YC6GZJR-0/T715bELMplI/AAAAAAAAHE0/Fzk41wW8ysM/s320/Offsets_CDF.png" />
<p>Cumulative Distribution Function of the total offsets.</p>
<img alt="" src="http://2.bp.blogspot.com/-9zPWRdGI0jY/T715bmcgVnI/AAAAAAAAHFA/K0XKvlJdO_8/s320/Offsets_Histogram.png" />
<p>Histograms of the total offsets.</p>
<img alt="" src="http://2.bp.blogspot.com/-3hkzLY1D4KY/T715b0VfMxI/AAAAAAAAHFM/DDBXKCGu8ng/s320/Offsets_XYplot.png" />
<p>X-offsets vs Y-offsets (X and Y are GLON and GLAT). The ellipses are
centered at the mean of the X/Y offsets and have major and minor axes
corresponding to the standard deviations.</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
    <li><article class="hentry">
        <header> 
            <h2 class="entry-title">
                <a href="https://keflavich.github.io/blog/getting-rid-of-haloes.html" rel="bookmark" title="Permalink to Getting rid of haloes">
                    Getting rid of haloes</a>
            </h2> 
        </header>
        <footer class="post-info">
            <abbr class="published" title="2012-03-31T00:28:00-06:00"> 2012/03/31 </abbr>
            <!--<address class="vcard author"><a class="url fn" href="https://keflavich.github.io/blog/author/adam-adamgginsburggmailcom.html">Adam (adam.g.ginsburg@gmail.com)</a></address>-->
        </footer><!-- /.post-info -->
        <div class="entry-content"> <p>Haloes are when images look like this:</p>
<img alt="" src="http://1.bp.blogspot.com/-Hwwiewo9FyU/T3Yhs6TpYcI/AAAAAAAAG0k/uKSTBCn95FY/s320/Screen%2Bshot%2B2012-03-30%2Bat%2B3.09.54%2BPM.png" />
<p>instead of this, as they should:</p>
<img alt="" src="http://4.bp.blogspot.com/-t5jVccq9Dtc/T3Yhs-hcY5I/AAAAAAAAG0s/EZ4x0zdSgxw/s320/Screen%2Bshot%2B2012-03-30%2Bat%2B3.09.58%2BPM.png" />
<p>Things to try:</p>
<ol class="arabic simple">
<li>Pass <tt class="docutils literal">/return_deconv</tt> to deconv_map</li>
<li>Pass <tt class="docutils literal">/linear</tt> to deconv_map</li>
<li>Disable deconvolve - deconvolve=0</li>
</ol>
<p>In l123 &amp; l169, at least, <tt class="docutils literal">/return_deconv</tt> worked</p>
 </div>
        <!-- /.entry-content   not article.summary--> 
    </article></li>
    <hr width=100%>
</ul><!-- /#posts-list -->
<p class="paginator">
    Page 1 / 20
        <a href="https://keflavich.github.io/blog/category/bgps2.html">&raquo;</a>
</p>
</section><!-- /#content -->
  </div>

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37306139-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-37306139-1');
    ga('send', 'pageview');
</script>
<script type="text/javascript">
  var disqus_shortname = 'adamginsburgsblog';
  (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
   })();
</script>
</body>
</html>
